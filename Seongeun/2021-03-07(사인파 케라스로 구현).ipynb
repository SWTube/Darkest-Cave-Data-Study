{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사인파 케라스로 구현\n",
    " - 저번에 텐서플로우로 하다가 실패해서 케라스로 다시 구현해봅니다. 텐서플로 버전 계속 고처보려했는데 못 고쳐서 이거나 해봤습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sin(x, T=100):\n",
    "    return np.sin(2.0 * np.pi * x / T)\n",
    "\n",
    "def toy_problem(T=100, ampl=0.05):\n",
    "    x = np.arange(0, 2 * T + 1)\n",
    "    noise = ampl * np.random.uniform(low=-1.0, high=1.0, size=len(x))\n",
    "    return sin(x) + noise\n",
    "\n",
    "T = 100\n",
    "f = toy_problem(T) # t = 0, ... , 200일 때의 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_sequences = 2 * T # 시계열 전체의 길이\n",
    "maxlen = 25 # 하나의 시계열 데이터의 길이\n",
    "\n",
    "data = []\n",
    "target = []\n",
    "for i in range(0, length_of_sequences - maxlen + 1): # 과거의 데이터 셋을 t - maxlen + 1 라 생각\n",
    "    data.append(f[i:i + maxlen])\n",
    "    target.append(f[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 차원 맞추기\n",
    "\n",
    "X = np.array(data).reshape(len(data), maxlen, 1) # 데이터 수, maxlen, 입력차원(1)\n",
    "Y = np.array(target).reshape(len(data), 1) # 출력차원은 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# 학습데이터 준비\n",
    "\n",
    "N_train = int(len(data) * 0.9)\n",
    "N_validation = len(data) - N_train\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, dtype=None):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:2618: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(20, input_shape=(25, 1), kernel_initializer=<function ...)`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=<function ...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "n_in = len(X[0][0]) # 1\n",
    "n_hidden = 20\n",
    "n_out = len(Y[0]) # 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(n_hidden, init=weight_variable, input_shape=(maxlen, n_out)))\n",
    "model.add(Dense(n_out, init=weight_variable))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 158 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "158/158 [==============================] - 1s 4ms/step - loss: 0.5002 - val_loss: 0.3583\n",
      "Epoch 2/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.3994 - val_loss: 0.2597\n",
      "Epoch 3/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.2420 - val_loss: 0.1302\n",
      "Epoch 4/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.1095 - val_loss: 0.0695\n",
      "Epoch 5/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0567 - val_loss: 0.0499\n",
      "Epoch 6/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0484 - val_loss: 0.0458\n",
      "Epoch 7/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0427 - val_loss: 0.0273\n",
      "Epoch 8/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0387 - val_loss: 0.0253\n",
      "Epoch 9/500\n",
      "158/158 [==============================] - 0s 766us/step - loss: 0.0341 - val_loss: 0.0220\n",
      "Epoch 10/500\n",
      "158/158 [==============================] - 0s 665us/step - loss: 0.0302 - val_loss: 0.0202\n",
      "Epoch 11/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0254 - val_loss: 0.0134\n",
      "Epoch 12/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0215 - val_loss: 0.0092\n",
      "Epoch 13/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0158 - val_loss: 0.0061\n",
      "Epoch 14/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 15/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0133 - val_loss: 0.0047\n",
      "Epoch 16/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 17/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 18/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 19/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 20/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 21/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 22/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 23/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 24/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 25/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 26/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 27/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 28/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 29/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 30/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 31/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 32/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 33/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 34/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 35/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 36/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 37/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 38/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 39/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 40/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 41/500\n",
      "158/158 [==============================] - 0s 487us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 42/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 43/500\n",
      "158/158 [==============================] - 0s 544us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 44/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 45/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 46/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 47/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 48/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 49/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 50/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 51/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 52/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 53/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 54/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 55/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 56/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 57/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 58/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 59/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 60/500\n",
      "158/158 [==============================] - 0s 329us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 61/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 62/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 63/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 64/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 65/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 66/500\n",
      "158/158 [==============================] - 0s 449us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 67/500\n",
      "158/158 [==============================] - 0s 525us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 68/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 69/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 70/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 71/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 72/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 73/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 74/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 75/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 76/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 77/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 78/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 354us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 80/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 81/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 82/500\n",
      "158/158 [==============================] - 0s 335us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 83/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 84/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 85/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 86/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 87/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 88/500\n",
      "158/158 [==============================] - 0s 335us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 89/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 90/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 91/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 92/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 93/500\n",
      "158/158 [==============================] - 0s 335us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 94/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 95/500\n",
      "158/158 [==============================] - 0s 570us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 96/500\n",
      "158/158 [==============================] - 0s 563us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 97/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 98/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 99/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 100/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 101/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 102/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 103/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 104/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 105/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 106/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 107/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 108/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 109/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 110/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 111/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 112/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 113/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 114/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 115/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 116/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 117/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 118/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 119/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 120/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 121/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 122/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 123/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 124/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 125/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 126/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 127/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 128/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 129/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 130/500\n",
      "158/158 [==============================] - 0s 329us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 131/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 132/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 133/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 134/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 135/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 136/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 137/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 138/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 139/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 140/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 141/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 142/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 143/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 144/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 145/500\n",
      "158/158 [==============================] - 0s 481us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 146/500\n",
      "158/158 [==============================] - 0s 614us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 147/500\n",
      "158/158 [==============================] - 0s 595us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 148/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 149/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 150/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 151/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 152/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 153/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 154/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 155/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 156/500\n",
      "158/158 [==============================] - 0s 449us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 367us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 158/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 159/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 160/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 161/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 162/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 163/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 164/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 165/500\n",
      "158/158 [==============================] - 0s 335us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 166/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 167/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 168/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 169/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 170/500\n",
      "158/158 [==============================] - 0s 329us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 171/500\n",
      "158/158 [==============================] - 0s 329us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 172/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 173/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 174/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 175/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 176/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 177/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 178/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 179/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 180/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 181/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 182/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 183/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 184/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 185/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 186/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 187/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 188/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 189/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 190/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 191/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 192/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 193/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 194/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 195/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 196/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 197/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 198/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 199/500\n",
      "158/158 [==============================] - 0s 589us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 200/500\n",
      "158/158 [==============================] - 0s 557us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 201/500\n",
      "158/158 [==============================] - 0s 538us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 202/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 203/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 204/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 205/500\n",
      "158/158 [==============================] - 0s 335us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 206/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 207/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 208/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 209/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 210/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 211/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 212/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 213/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 214/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 215/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 216/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 217/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 218/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 219/500\n",
      "158/158 [==============================] - 0s 342us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 220/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 221/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 222/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 223/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 224/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 225/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 226/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 227/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 228/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 229/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 230/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 231/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 232/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 233/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 234/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 386us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 236/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 237/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 238/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 239/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 240/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 241/500\n",
      "158/158 [==============================] - 0s 335us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 242/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 243/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 244/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 245/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 246/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 247/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 248/500\n",
      "158/158 [==============================] - 0s 513us/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 249/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 250/500\n",
      "158/158 [==============================] - 0s 595us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 251/500\n",
      "158/158 [==============================] - 0s 677us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 252/500\n",
      "158/158 [==============================] - 0s 589us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 253/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 254/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 255/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 256/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 257/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 258/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 259/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 260/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 261/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 262/500\n",
      "158/158 [==============================] - 0s 335us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 263/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 264/500\n",
      "158/158 [==============================] - 0s 601us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 265/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 266/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 267/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 268/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 269/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 270/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 271/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 272/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 273/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 274/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 275/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 276/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 277/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 278/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 279/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 280/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 281/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 282/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 283/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 284/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 285/500\n",
      "158/158 [==============================] - 0s 696us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 286/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 287/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 288/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 289/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 290/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 291/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 292/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 293/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 294/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 295/500\n",
      "158/158 [==============================] - 0s 525us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 296/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 297/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 298/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 299/500\n",
      "158/158 [==============================] - 0s 747us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 300/500\n",
      "158/158 [==============================] - 0s 696us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 301/500\n",
      "158/158 [==============================] - 0s 576us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 302/500\n",
      "158/158 [==============================] - 0s 538us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 303/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 304/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 305/500\n",
      "158/158 [==============================] - 0s 570us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 306/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 307/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 308/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 309/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 310/500\n",
      "158/158 [==============================] - 0s 595us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 311/500\n",
      "158/158 [==============================] - 0s 532us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 312/500\n",
      "158/158 [==============================] - 0s 481us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 430us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 314/500\n",
      "158/158 [==============================] - 0s 677us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 315/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 316/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 317/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 318/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 319/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 320/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 321/500\n",
      "158/158 [==============================] - 0s 348us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 322/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 323/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 324/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 325/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 326/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 327/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 328/500\n",
      "158/158 [==============================] - 0s 481us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 329/500\n",
      "158/158 [==============================] - 0s 481us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 330/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 331/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 332/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 333/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 334/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 335/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 336/500\n",
      "158/158 [==============================] - 0s 544us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 337/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 338/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 9.9247e-04 - val_loss: 0.0024\n",
      "Epoch 339/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 340/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 341/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 342/500\n",
      "158/158 [==============================] - 0s 589us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 343/500\n",
      "158/158 [==============================] - 0s 715us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 344/500\n",
      "158/158 [==============================] - 0s 589us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 345/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 346/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 347/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 348/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 349/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 350/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 351/500\n",
      "158/158 [==============================] - 0s 481us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 352/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 353/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 354/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 355/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 356/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 357/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 358/500\n",
      "158/158 [==============================] - 0s 487us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 359/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 360/500\n",
      "158/158 [==============================] - 0s 494us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 361/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 362/500\n",
      "158/158 [==============================] - 0s 494us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 363/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 364/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 365/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 366/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 367/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 368/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 369/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 370/500\n",
      "158/158 [==============================] - 0s 544us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 371/500\n",
      "158/158 [==============================] - 0s 449us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 372/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 373/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 374/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 375/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 376/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 377/500\n",
      "158/158 [==============================] - 0s 582us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 378/500\n",
      "158/158 [==============================] - 0s 525us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 379/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 380/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 381/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 382/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 383/500\n",
      "158/158 [==============================] - 0s 513us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 384/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 385/500\n",
      "158/158 [==============================] - 0s 513us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 386/500\n",
      "158/158 [==============================] - 0s 696us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 387/500\n",
      "158/158 [==============================] - 0s 646us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 388/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 389/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 390/500\n",
      "158/158 [==============================] - 0s 582us/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 519us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 392/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 393/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 394/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 395/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 396/500\n",
      "158/158 [==============================] - 0s 513us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 397/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 398/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 399/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 400/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 401/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 402/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 403/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 404/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 405/500\n",
      "158/158 [==============================] - 0s 481us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 406/500\n",
      "158/158 [==============================] - 0s 380us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 407/500\n",
      "158/158 [==============================] - 0s 449us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 408/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 409/500\n",
      "158/158 [==============================] - 0s 494us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 410/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 411/500\n",
      "158/158 [==============================] - 0s 551us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 412/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 413/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 414/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 415/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 416/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 417/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 418/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 419/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 420/500\n",
      "158/158 [==============================] - 0s 500us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 421/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 422/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 423/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 424/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 425/500\n",
      "158/158 [==============================] - 0s 551us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 426/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 427/500\n",
      "158/158 [==============================] - 0s 487us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 428/500\n",
      "158/158 [==============================] - 0s 519us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 429/500\n",
      "158/158 [==============================] - 0s 513us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 430/500\n",
      "158/158 [==============================] - 0s 652us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 431/500\n",
      "158/158 [==============================] - 0s 690us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 432/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 433/500\n",
      "158/158 [==============================] - 0s 449us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 434/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 435/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 436/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 437/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 438/500\n",
      "158/158 [==============================] - 0s 354us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 439/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 440/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 441/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 442/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 443/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 444/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 445/500\n",
      "158/158 [==============================] - 0s 639us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 446/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 447/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 448/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 449/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 450/500\n",
      "158/158 [==============================] - 0s 481us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 451/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 452/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 453/500\n",
      "158/158 [==============================] - 0s 494us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 454/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 455/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 456/500\n",
      "158/158 [==============================] - 0s 513us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 457/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 458/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 459/500\n",
      "158/158 [==============================] - 0s 411us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 460/500\n",
      "158/158 [==============================] - 0s 532us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 461/500\n",
      "158/158 [==============================] - 0s 487us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 462/500\n",
      "158/158 [==============================] - 0s 430us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 463/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 464/500\n",
      "158/158 [==============================] - 0s 449us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 465/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 466/500\n",
      "158/158 [==============================] - 0s 519us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 467/500\n",
      "158/158 [==============================] - 0s 468us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 468/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 367us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 470/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 471/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 472/500\n",
      "158/158 [==============================] - 0s 525us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 473/500\n",
      "158/158 [==============================] - 0s 506us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 474/500\n",
      "158/158 [==============================] - 0s 759us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 475/500\n",
      "158/158 [==============================] - 0s 563us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 476/500\n",
      "158/158 [==============================] - 0s 456us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 477/500\n",
      "158/158 [==============================] - 0s 475us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 478/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 479/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 480/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 481/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 482/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 483/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 484/500\n",
      "158/158 [==============================] - 0s 405us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 485/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 486/500\n",
      "158/158 [==============================] - 0s 525us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 487/500\n",
      "158/158 [==============================] - 0s 519us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 488/500\n",
      "158/158 [==============================] - 0s 361us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 489/500\n",
      "158/158 [==============================] - 0s 481us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 490/500\n",
      "158/158 [==============================] - 0s 399us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 491/500\n",
      "158/158 [==============================] - 0s 386us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 492/500\n",
      "158/158 [==============================] - 0s 443us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 493/500\n",
      "158/158 [==============================] - 0s 437us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 494/500\n",
      "158/158 [==============================] - 0s 367us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 495/500\n",
      "158/158 [==============================] - 0s 373us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 496/500\n",
      "158/158 [==============================] - 0s 570us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 497/500\n",
      "158/158 [==============================] - 0s 424us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 498/500\n",
      "158/158 [==============================] - 0s 418us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 499/500\n",
      "158/158 [==============================] - 0s 392us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 500/500\n",
      "158/158 [==============================] - 0s 462us/step - loss: 0.0012 - val_loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1278d788>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 10\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size = batch_size, epochs=epochs, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated = maxlen\n",
    "Z = X[:1]\n",
    "\n",
    "original = [f[i] for i in range(maxlen)]\n",
    "predicted = [None for i in range(maxlen)]\n",
    "\n",
    "for i in range(length_of_sequences - maxlen + 1):\n",
    "    z_ =  Z[-1:]\n",
    "    y_ = model.predict(z_)\n",
    "    sequence_ = np.concatenate(\n",
    "        (z_.reshape(maxlen, n_in)[1:], y_),\n",
    "        axis=0).reshape(1, maxlen, n_in)\n",
    "    Z = np.append(Z, sequence_, axis=0)\n",
    "    predicted.append(y_.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD3CAYAAAAQYlNPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd1ycx7X3v0MTRTSBBEIVqws1JEQRxagiqxfbcRwnju0bO3ESJ++9vo5fO69j35vkxinOTa6vW2ynuMVxbKsjqrAlhARIQh1JoI4KIED0tjvvH7BrVuyiwu4+u8t8P5/9iJ2ZZ/eH2GfPzDkz5wgpJQqFQqEYuLhpLUChUCgU2qIMgUKhUAxwlCFQKBSKAY4yBAqFQjHAUYZAoVAoBjgeWgu4E0JDQ+XYsWO1lqFQKBROxb59+6qllENvbHdKQzB27FiKi4u1lqFQKBROhRDinLl25RpSKBSKAY4yBAqFQjHAUYZAoVAoBjjKECgUCsUARxkChUKhGOAoQ6BQKBQDHKtsHxVChAM/B2ZKKeea6XcDfgk0AmOAd6SUe7r7FgHrgEpASilfsoYmhUKhUNwa1jpHkARsBGZZ6L8fCJBSPiuEGALsEUJMAQYBbwBRUso2IcSnQoiFUsocK+lyeHQ6HadPn8bf35/w8HCt5ShcjJqaGjo6OggLCwO6Pm/u7u4aq1I4GlZxDUkp/wk09DFkOVDQPbYGaAWigATgnJSyrXtcfvfYXgghHhdCFAshiquqqqwhWzP0ej0tLS0AuLm5cfDgQerq6gDo7Oxk7969NDU1aSlR4SIcOnSIw4cPG5/n5eVRUFCgoSKFI2KvGMEwTA1FfXebpfZeSCnfklLGSCljhg7tdULaaZBSsmvXLr788kv0ej1CCFauXMmkSZMAaGho4NKlS8oQKO6Izs5O9u3bR0dHBwAxMTHMmzcP6PrsjRgxgtGjRxvHq8JUCrBfiolKwL/H84DuNmmh3WURQjBlyhRaWlq4dOkS//znP0lISKC6upopU6YQGRnJ8uXL8fLyAqC+vp6AgACNVSucgYqKCl5//XU2b96Mp6cnI0aM4MEHH2Tt2rVA12dv8uTJxvHnzp3j6tWrxMTE4Oam9o0MZGz21xdC+AkhDFP3rXS5geiOEXgDR+lyF40RQgzqHpfYPdblaG5upqKiAoChQ4cyevRofv3rX/Pv//7vvPHGG6xYsYJx48aRkpLCkSNHALh+/TpZWVmcOXNGS+kKB6etrY3nnnuO8ePH84tf/AIpJSEhIRw8eJAHHniAhIQEzp8/3+u6lpYWWltb0ev1GqhWOBRSyn4/gLuBd4AK4KeAD/B94I3ufjfgZeBn3ePie1y7GHiTrl1HP7uV95szZ450NgoLC+Xnn38u29rapJRSHjt2TALysccekzU1NTI/P1++8sorcujQodLDw0N+8sknUq/XyyNHjsjW1laN1SsclfLychkdHS0Bee+998ry8nJjn06nkx9//LH09/eXw4YNkydOnOh1vV6vt6dchcYAxdLcd7i5Rkd/OKMh6OzslDU1NfLMmTNSSinXrFkjAZMbV0opa2pqZGJionRzc5OffPKJsV2v18v29nZ7SlY4OCUlJTIsLEwGBwfLl156SZ48edLsuGPHjsnQ0FA5ceJEWVNT06u/ra1N5ufny8rKSltLVmiMJUMgpBMGi2JiYqSzpKG+cOECFRUVSCm5cuUK9913H++88w4zZ87k2rVrLFy4sNc1TU1NLFmyhIMHD1JUVMSUKVPYu3cvzc3NpKamIoTQ4DdROBI7d+5k5cqV+Pv7k5WVxcSJExFCWPxs7Ny5k4ULF7J06VI2btxoMq6zs5OcnBwmTpxIZGSkvX4FhQYIIfZJKWN6dZizDo7+cJYVQXt7u0xOTpZ0BcUlIENCQuS1a9dueu3Fixfl0KFD5dSpU2VLS4s8f/68PHnypFrKK2RGRob09vaWkyZNkjt27JAdHR23dN0rr7wiAfnee+/16tPpdNaWqXBAUCsCbdiyZQt5eXksXLgQDw8Ppk2bxvDhw2/p2u3bt3PPPffws5/9jBdffNG2QhVOQVFREampqUyYMIH333+f48ePM2/ePEaMGHHTa3U6HcnJyZSWllJaWsqwYb13aldVVeHu7s6QIUNsIV+hMZZWBMoQODgPPvggn376KYcOHWLSpElcuXKFqqoqpk+frrU0hZ25dOkS0dHR+Pr6UlBQQHh4OHV1dQQGBt6yu7C0tJTp06fzyCOP8NZbb5n06fV60tPTCQgIIDk52Ra/gkJjLBkCtXnYBkgpyc/PZ8OGDWzbtq1f2/NeeeUVfHx8+NGPfgRAZWUlFRUVdHZ2WkuuwgnQ6XQ89NBDNDY2sm3bNkJDQwEICgq6rZjR5MmT+eEPf8jbb79NSUmJSZ+bmxtJSUkkJCRYVbvC8VGGwMrodDqampq4fv06r7zyCo888ki/grvh4eG88MILZGRksH37dqZOncqSJUvw8HDKctOKO+SVV15hx44dvPrqq4waNYotW7YYz6XcLi+88AIhISH827/9W6++wMBAPDw8kFKq8wUDCXOBA0d/OHKwOCcnR3p7exuDw+vXr+/3a7a2tspx48bJqVOnGgODOp1OtrS09Pu1FY7PxYsXpZ+fn1y9erXU6/WysbFRFhYWyubm5jt+zf/+7/+WgMzOzu7V197eLrOysuSpU6f6I1vhgGAhWKxWBFbm73//O0IInn76aQCr+FoHDRrEyy+/zLFjx/jwww+RUpKXl0dRUVG/X1vh+PzkJz+hs7OT3//+9wgh8PPzY+7cufj4+Nzxaz7xxBOMGjWK559/HnlDnNDDwwN/f38GDRpk4WqFy2HOOjj6w1FXBDqdToaGhsp58+bJuro6+f3vf19euXLFKq+t1+tldHS0HDdunGxvb5dnz56VFy9etMprKxyXAwcOSEA+//zzUkopz507JxsbG63y2n/6058kILdu3WqV11M4PqgVge05cOAA1dXVPPDAAwQGBvLqq68a88D3FyEEL730EuXl5fztb39jzJgxt7RlUOHc/OIXvyAgIICnn37amFm0tLTUKq/98MMPM3r0aGN+ohvR6/VcunTJbJ/CtVCGwIrs3bsXgNWrV9vk9VesWMGcOXP41a9+hU6no7Ozk7KyMpWy2kU5fvw4n376KT/84Q8JCgrCw8ODpUuXMnXqVKu8vqenJ8888wy7d+/myy+/7NVfUVFBfn4+V69etcr7KRwXZQisRGNjI6Ghofzyl79k1KhRNnkPIQTPPvssZWVlfP7557S3t1NSUnLHu0cUjs1vfvMbfHx8+PGPf2xs8/Hx6Vds4EYeffRRwsLC+OUvf9mrb8SIESQmJlptVatwXJQhsBI1NTV4eHjw4x//2Ka5gNauXcuECRN4+eWX8fHxIS0tjYkTJ9rs/RTaUF1dzYcffsjDDz9MaGgo586do6CgwFhwxlr4+Pjw1FNPkZmZydGjR0363NzciIiIULmtBgDKEFiJYcOGMWjQINrb2236Pu7u7jz99NMUFxezc+dO/P39b36Rwul45513aGtr4/vf/z4AHR0dtLa22uT8yOOPP463tzd//OMfzfaXlZVx4sQJq7+vwnFQhsAKSCk5ePAgK1asIDc31+bv99BDDxEcHMyrr74KdN2ou3btsvn7KuyDTqfjtddeY/78+URFRQEwfvx4m2WeDQ0N5Zvf/CZ/+9vfqK6u7tV/7do1KisrVdDYhVGGwArs2rWLzz//HIA5c+bY/P18fX157LHH+Oyzz7h48aIx/bBKO+EaZGRkcP78eZ588kkAWltbAWzqonnqqadobW3lz3/+c6++mJgYkpOTlYvIhbGKIRBCLBJCvCaEeFEI8TMz/e8IIfJ6PGqEEGO7+872aP/AGnrsiZSSoKAgysrKCA0NtVmg+Ea+973vodfrefPNNxk3bhyJiYkq7YSL8O677xIaGsqqVavo7OwkPT29l//e2kybNo2kpCTeeuutXjN/d3d3AJVywoXptyEQQvgCbwD/R0r5IjBDCHFjtZVMKWWqlDIVWAXkSSnPdvf9xdAnpfxGf/XYGyEEI0eOZMeOHXadNd11113cc889vPPOO8aVQFtbm7pZnZzq6mo2bdrEQw89hJeXFwBRUVG3nLq8PzzxxBOUlZWxY8eOXn1Xrlxh8+bNNDY22lyHwv5YY0WQAJyTUrZ1P88HlvccIKX8uMfTx4B3ezxPEUI8I4T4TyHEPCvosRtFRUVkZmby2WefUVtbywsvvGDX9//Od77D5cuX2b59O7W1tWzevJnLly/bVYPCunz44Yd0dHTw6KOPAl3pHiZOnGiX+gD33nsvwcHBvPnmm736AgICCAsLU3ECV8XccePbeQBfBzb0eP4vwPsWxroB2+mug9DdFtv9ry9QCoy3cO3jQDFQPHr0aOueu75DwsLC5KJFi2RFRYU8fvy43d+/vb1dhoWFydWrV0udTicPHz4s6+vr7a5DYT1mzpwpDSlUWltb5aVLl+xaPeypp56SXl5et1RFT+F8YMMUE5VAzz2MAd1t5lgNbOkWZDBEhd3/NgMlQKK5C6WUb0kpY6SUMUOHDrWC7P5RU1PD1atXmTFjBmFhYUyePNnuGjw9Pfn2t7/Nli1buHr1KtOmTVPbSZ2YAwcOcPDgQeNq4MKFC+zatYuGhga7aXj44Ydpb2/n448/Ntvf0tJCS0uL3fQo7IM1DEEBMEYIYUhVmAhsFUIMEUIE3DD228BfDE+EEAuFEEt79I8Hyq2gyeYYMn8uX77cGEzTgkceeQSdTsdHH32ElJK6ujquXbummR7FnfPnP/+ZQYMG8fWvfx3oigOlpKQQGBhoNw3R0dFMmzaNv/71r736dDod6enpVst1pHAc+m0Iumfy3wP+KIT4OXBISpkDPAs8aRgnhJgFnJRS9ow2VQLfEUI8J4R4FfhUSukUG+Lz8vKArhtHSyZNmsTcuXN5//33ASgoKODIkSOaalLcPm1tbXzwwQesXbuW4OBgoOtkr73TOwghePjhh9m7d2+vQ2Tu7u7ExMQwfvx4u2pS2AFz/iJHfzhCGurk5GQ5cuRIqdfrtZYi//CHP0hAHjlyRNbU1MjW1latJSlukw0bNkhApqenSymlPH36tDx16pQmn69Lly5JIYR84YUX7P7eCtuCSkNtXV577TXefPNNhzhk88ADD+Du7s57771HcHCwKijihHzyySeEhISwcGHXzuvLly9TUVGhyedr+PDhpKam8vHHH5vdJVRTU8PZs2ftrkthO5QhuEOmTZvGsmXLtJYBdOU5Wrx4MZ988glSSiorKzl06JDWshS3SGtrK5s2bWLt2rV4enoCMG/ePBITze6bsAtf+9rXOHHiBAcPHuzVd+bMGQ4ePKjOrLgQyhDcAf/4xz/43e9+51C7J9avX8/p06c5ePAgtbW1nD171uYJ8BTWISMjg4aGBu6//36Tdi1Piq9fvx53d3ezu4eioqJYtmwZbm7q68NVUH/J20RKyYYNG3j22Wcdwi1kYNWqVbi5ufHZZ58xfvx4Vq5caTyZqnBs/vGPfxASEsL8+fMB+OKLLzh16pSmmkJDQ1m0aBH/+Mc/ermHvL29jSsXhWugDMFtIoTg0qVLzJ49G29vb63lGBk2bBjJycl89tlnuLu7O5SRUlimpaWFTZs2sW7dOjw8POjs7MTLy8sh8katW7eO06dPc+zYsV59VVVVFBQUKPeQi6AMwW3S0dFBUVER8fHxWkvpxfr16zl69CgnTpygqqqK7OxsY+ZKhWOSkZFBY2Mj9913H9DlDkpISCAyMlJjZV2lUQE2btzYq6+9vZ2amhqam5vtLUthA5QhuA06Ozt57bXXaG5uJi4uTms5vVizZg0An3/+OV5eXri5uSlD4OAYdgsZ3ELWrkDWHyIiIpg7dy6bNm0y27ds2TIGDx6sgTKFtVGG4Dbo6Ogwntp1xBXBqFGjiI2N5dNPPyUwMJAFCxYQFBSktSyFBW50CzU3N7Nx40bOnz+vtTQjq1evZu/evb2SGRpqYBj2oSucG2UIbgMfHx/+4z/+g4sXLzrE0t0c69ato7i42PhlotfrlR/XQcnOzqaxsZF7770X6PpynTRpkl0yjd4qq1atAmDLli29+urq6ti+fTs1NTX2lqWwMsoQ3CKyuxxlR0cHI0aMcNhg7Lp164Au91BjYyObNm3iwoULGqtSmGPLli34+/uTmpoKdE00pk+f7lDulmnTphEZGWk2TuDr64ufn58GqhTWRhmCW+Djjz/mvvvuIyEhgaeeekprOX0yYcIEpk2bxueff46fnx9jxoxRGUkdECklW7ZsIS0tDS8vL9rb26mtrXU4N4sQglWrVpGdnU1TU5NJn5eXFykpKYSEhGikTmEtlCG4BZ588kny8vJITEzkmWee0VrOTVm+fDn5+fk0NjYSHR3tUK4GRRclJSVcunSJ5cu7ajhdvnyZ7Oxs6urqNFbWm9WrV9PW1kZWVpbZfp1O51BBbsXtowzBTbh+/To1NTU8++yzZGVlOWxsoCdpaWl0dnaSm5sLqBzyjsiWLVsQQnDPPfcAEB4eTmxsrEMG95OSkggKCjLrHmpra2Pjxo2cOXNGA2UKa6EMwU24fPkyvr6+DBkyxGmCromJifj5+ZGRkYFOp2Pbtm2cPHlSa1mKHmzbto25c+ca00wPGjSIMWPGOGTsydPTk2XLlrF169Ze98CgQYOYPHkyoaGhGqlTWANlCG7C5MmTOXDgAH5+fk5zeMbLy4sFCxawfft23NzciI2N5a677tJalqKb2tpaCgsLWbq0qyZTfX0958+fR6fTaazMMmlpaVRVVXH48OFefVOnTlXuRydHGYJbIDIykpSUFIfazXEzli5dypkzZygrK2PUqFEqYOxA5ObmotfrWbJkCdBVkrKwsNChV5yG9NiW4gQNDQ00Njaa7VM4PsoQ3IT/+Z//4V//9V8ZPny41lJui7S0NKArhYEhNXV1dbXGqhQAmZmZBAQEEBsbC3TNqJcsWeLQidxGjBjBlClTyM7O7tWn1+vJzs5WJSydGKsYAiHEIiHEa0KIF4UQPzPT/20hxB4hRF7345s9+h4SQvxOCPFrIcQT1tBjTbZs2UJOTo5DL9vNMW7cOMaNG0dGRgZCCPbt26duVAdASklmZibz5883fvELIQgIuLG8t+OxePFivvzyS9ra2kza3dzciI+PZ8qUKRopU/SXfhsCIYQv8Abwf6SULwIzhBALzQx9QEqZ2v14r/vakcDTwNNSymeAfxFCTOivJmtSVlbmtG6VpUuXsmPHDtra2pg3b55D5kcaaJSXl3P27FmjW+jSpUscPXrUod1CBhYtWkRLSwu7d+/u1Td8+HB1uMyJscaKIAE4J6U0TBPygeVmxv1ACPG0EOIFIYQhspQG7JNfnaIpAO6xgiarIKXkypUrxMbG4u7urrWc2yYtLY2mpiby8/MJDAx0aNfDQCEzMxPAaAiqq6s5d+6cQ+4WupHU1FTc3d3Nuoega4fdlStX7KxKYQ2sYQiGAQ09ntd3t/XkC+BlKeVvgWLgk9u4FgAhxONCiGIhRHFVVZUVZN+cqqoqmpubmThxol3ez9oY3A8ZGRkAnD17lvLyco1VDWwyMzOJjIxk3LhxAMyYMYO0tDSnMAT+/v7Ex8dbNASGFOgK58MahqAS6Ok7CehuMyKlPCOlNHx75wJ3CyHcb+XaHq/xlpQyRkoZM3ToUCvIvjnHjh1j7NixxpvW2Rg8eDCJiYnGWWhFRYVDZbYcaHR0dLBjxw4WL15s8sXvTKvNRYsWUVxcTG1tba++hIQEkpKSNFCl6C/WMAQFwBghxKDu54nAViHEECFEAIAQ4r+EEIaSSxOAM1JKHZABzBFf3RUJQLoVNPWbzs5OQkJCeOONNxymSP2dMH/+fGMd47i4OGOCM4X9KSwspL6+3ugWOn78OIWFhQ6XX6gvFi9ejF6vZ8eOHb36/Pz8nMqoKb6i34ZAStkMfA/4oxDi58AhKWUO8CzwZPewK8DrQojngOeAb3ZfexH4LfB7IcTvgLellNoWa+1m0aJFVFVVGW9aZ+Xuu+9GSkl+fj4eHh5O4YJwVTIzM3Fzc2PBggXAVynCnelvEhsby+DBgy26h8rKyjSvt6y4faxSGFVKmQVk3dD2TI+f/9DHte8D71tDh7W4dOkSX3zxBXl5ecab1lmJjY3Fy8uLL774ghUrVnD8+HHa2tqYNWuW1tIGHJmZmcTGxhIcHAxAVFSUxopuH09PT1JTUy0eLLt69Sp6vZ4JExxq85/iJqgDZWbYu3cvACNHjnSqZbs5fHx8iIuL44svvgCgtbVVJaDTgLq6OgoLC1m8eDGAU3+u5s+fT1lZWa+qZdAVJ0hOTtZAlaI/KENghj179uDp6UlUVJRTLdstcffdd7N//34aGhqIjo4mISFBa0kDjhvTShQXFxuNs7Nh+KLftWtXrz43N/WV4oyov5oZ9uzZw+zZs0lMTNRailVISUlBp9OZHARy5hmpM5KZmYm/v7/xUN+QIUOw1+43azNr1ix8fX3NGgKAI0eOsH//fjurUvQHZQjMEBkZycqVK7WWYTXmzZuHh4eHcQZaUlLCzp07NVY1cJBSkpGRwYIFC4yH+saNG8fUqVM1VnZneHp6Eh8fb9EQ6HQ6p0vJMtBRhsAMP/jBD4iPj9dahtXw8/MjJiaGL7/8Eug6XxAQEKBWBXbCkFbCEB9obW11ipQSfZGUlERJSQn19fW9+mbOnMncuXM1UKW4U5QhuAGdTkdoaCgRERFaS7EqKSkpFBYW0tzczPjx45k1a5ZLxD+cAcMOm57xgZycHC0l9Zvk5GT0ej179uyxOEZNNJwHZQhu4KmnnuKee+5xuUyKd999Nx0dHSY3bnt7u4aKBg6ZmZmMHTuW8ePHA3DXXXcxadIkjVX1j7i4ONzd3S26h/bt2+e0wfCBiDIEN3DkyBECAwO1lmF1EhMTcXNzM96cRUVFTj8rdQY6OjrIzc1lyZIlxhVYREQEo0eP1lhZ//D392fWrFkWY01BQUEMHTpUrQqcBGUIbuDw4cMuaQgCAwOZNWuW0RCMGDGCCRMmqBvVxhjSShjiA3V1dU5T8vRmJCcns3fvXrMry3HjxrnM9uuBgDIEPaiqqqK2ttZYOcrVSE5OprCwkM7OTiIiIhg/fry6UW1MVlaWSVqJkpIS8vPzNVZlHZKSkmhpaeHAgQNm+6WUtLa22lmV4k5QhqAHx44dA3DZDIrx8fG0tLRw6NAhoCux3vXr1zVW5dpkZmYyd+5cY3H36Ohol0nvYbhPLMUJdu/erbYpOwnKEPRg0KBBfO9732PmzJlaS7EJhhPFhoBxYWGhxZtY0X9qamrYu3evsX40dLnonPUg2Y2EhYUxYcIEi1/2Y8eOVTmHnARlCHrQ2dnJypUrCQ8P11qKTRg9ejTh4eEUFBQAMGnSJGJiYlScwEZkZmai1+u5556uonuVlZVcvXpVY1XWJSkpiV27dpn9DI0YMYKxY8faX5SLUlNTw2OPPcaRI0es/trKEPRgyJAhLrsagK4i6QkJCcYVQUhICGFhYSpOYCPS09MZMmSI8XDV8ePHjW45VyEhIYFr165ZrHzX1tZGXV2dnVW5JpmZmbz77rs0NjZa/bWVIaDr5Od3v/tdYmNjeeGFF7SWY1Pi4+MpKyvDUO6zvr5e1Zm1AXq9noyMDJYsWWIs1jJv3jyXOrEOGHMnGTL23sjevXspLCy0pySXJT09nZCQEJuc2laGAHjzzTf505/+xNSpU/nWt76ltRybYvgiMty4x44do6ioSLmHrExJSQlXr141uoWgK0ePv79/H1c5H1FRUfj5+Vk8YTx16lTmzJljZ1Wuh16vZ/v27aSlpdmkCpwyBHQVdR8xYgQ///nPSUlJ0VqOTYmJicHd3d0YJ4iKimLhwoXKPWRl0tO7Kq4aAsUXL16krKzM5Qyuu7s7c+fOtbgiCA0NJSQkxM6qXI/9+/dTWVlpMrGwJlapUCaEWASso6vwvJRSvnRD/0+AcLpKVs4BXpBSlnb3nQXOdg+tkFJ+wxqaboezZ88yadIkl0k73Re+vr7MnDnTOINztRmqo5Cens6cOXMICwsDugxBQ0ODMc2EKxEXF8crr7xCa2sr3t7evfprampoa2tj+PDhGqhzDdLT0xFCmOxAsyb9NgRCCF/gDSBKStkmhPhUCLGwu26xgcHAv0oppRDia8BvAEOe579IKV/sr47+kJGRQVNTE35+flrKsBsJCQn89a9/RafT4e7uzuXLl2lpaeGuu+7SWppLUFtbS0FBAc8995yxLT4+no6ODg1V2Y64uDg6OjooKSkxGwM5evQoTU1NyhD0g23btjF37lybbT22hmsoATgnpWzrfp4PLO85QEr5/+RXa2I3oGfYO0UI8YwQ4j+FEPMsvYkQ4nEhRLEQotgQ6LQW169fd5lj/7dCfHw8jY2NHD16FIALFy5QWlrqcm4LrcjKyjLZNmrAUIvA1bhZwHjWrFnMnz/fnpJciurqavbu3WsztxBYxxAMAxp6PK/vbuuFEMILeBj4aY/mZ6WUvwb+C3hXCGF27SylfEtKGSOljLGmVbx48SIvvviixQ+xK3LjwbKZM2eydOlSFSewEunp6QQFBRlTlZw+fZoDBw64rKGNiIhg5MiRFgPG/v7+DBo0yM6qXIfMzEyklCxbtsxm72ENQ1AJ9HQ0B3S3mdBtBF4HnpdSGjcdSykLu/9tBkoAuzrqjxw5wl//+lfGjBljz7fVlLvuuovQ0FBjwHjQoEGq1qyVkFKyfft2lixZgodHl+e1qamJuro6lza0cXFxfU6mLly4wJkzZ+yoyHVIT08nNDSUmJgYm72HNe7+AmCMEMJg8hOBrUKIIUKIAAAhhA/wJvCKlHKfEGJ9d/tCIcTSHq81HjB/MsVGnD17FujKljhQMBwsMxgC6DpLYXAVKe6cgwcPcuXKFZNl/PTp00lNTdVOlB2Ii4vjzJkzWHLbnj9/ntOnT9tZlfNj2Da6dOlSm07W+h0sllI2CyG+B/xRCFEFHJJS5gghfg3UAL8CPgCmAZHdsyI/4FO6Vg4vCiFmA+ZU1ikAACAASURBVBHAp1JKuya/2b9/Px4eHi6bVsIScXFxbN68mbq6OoKCgqitrbXJicWBhmHb6NKlS03aXXk1AKZxghUrVvTqj42NNa6QFLdOcXEx1dXVNo0PgJW2j0ops4CsG9qe6fHzOgvXHQbWW0PDnXLhwgXCwsJsckjDkTHcuEVFRSxevJg5c+a4/JeVPUhPTyc6Oto4sThx4gRXr14lKSnJpd1vc+bMwd3d3aIhcNVAua2x9bZRA677ybxFWlpanL5s4J1gOKZu8OsqI9B/6urq2L17t8nszd3dHU9PT5c2AgB+fn5Mnz69zzhBaWmpMdW74tbYtm0bcXFxNj+UN+DXajt27KClpUVrGXYnMDCQyZMnm+SBOXz4MG1tbTYNSrky2dnZ6HQ6E0Mwfvx4lzxEZo64uDg++ugj9Hq9WcN3/fp19Hq9Bsqck6qqKoqKinjppZduPrifuPY05Sbs3buXvLw8s6chBwKGnR6uuq3R3qSnpxMYGGg8VKXX6wfU/21cXBz19fWcPHnSbH9sbKxx67Li5mRkZCCltHl8AAawIaisrGT16tV8/vnnLr9st0RcXByVlZWcO3cO6NrdolYDd4aUkvT0dJNto6WlpWzbtg2dTqexOvtgODdhKduocj/eHunp6QwbNozZs2fb/L0G5jcg8OKLL1JbW8tjjz2mtRTNMNy4N/p1B9Is1locPHiQy5cvmxz6CQoKYuTIkQNmI8LkyZMZPHhwn3GC4uJiizWOFV+h0+nIyMggLS3NLhPVAWkI2tra+Oijj7jvvvtcuhDNzZgxYwbe3t4mM7iCggJ2796toSrnxNy20YiIiAH1+TJkIu2r/oCHh4faRnoLFBcXc+3aNbu4hWCAGoItW7ZQV1fHhAkTBsyy3Ryenp7Mnj3bZAYXEhJCaGiohqqck23btjF79mzjttH29naXTTLXF7GxsRw8eJDW1laz/bNmzWL69Ol2VuV8pKen4+bmxpIlS+zyfgPSELz//vuEh4ezZs2aAbNst0RcXBz79u0zfmlNnDhxQG6n7Q+GbKM9Z2/l5eVs3LhxwBmDnplI+0LtHuqb9PR0YmNj7VbLYUAagrfeeot//vOfA2rZbonY2FhaW1tNCmJLKWlra+vjKkVPsrKy0Ol0JvGB8PBwZs6cOeAOUt0sYAxdW7aLi4vtJcnpMGwbtZdbCAaoIQgICFDl87oxl0I4JyeHoqIirSQ5Henp6QQHBxv/LwGCg4OZMGGChqq0YcSIEYwYMaLPgPHw4cOV+7EPDNlGlSGwIWVlZfz0pz/lvffeo729XWs5mjN27FiGDh1qcuNOmDCBsWPHaifKidDr9aSnp5vUkm1ubqaurm7A7r6KjY3tc0UwefJkVQSpD9LT0xk6dKhdJ6sDzhAUFhby29/+ljFjxuDl5aW1HM0RQvRKITxmzBhGjhypoSrnwVyR+nPnzpGVlTVgJxqxsbGUlZVRU1NjcYxOp7MYUB7I6PV6u24bNTDgDMHly5cBTJbxA53Y2FhKS0u5fv26sa2lpYWGhoY+rlJA124hMN02OnbsWObNmzdgi7EY7i1LqwJDzYZDhw7ZU5ZTYK9sozcy4AzB+fPn8fHxYfDgwVpLcRji4uKQUpoE8PLy8tSNegukp6cTExPDsGFfFeXz8fFhxIgRGqrSFkMm275OGEdFRQ2oYlC3iiHbqL22jRoYcIagvLycgIAAOjs7tZbiMNyYiRQgOjqaqKgorSQ5BTU1NezZs8dkt1BDQwMXLlwY0J+vgIAApk6d2mecYOzYsYSFhdlRlXNg2DZq72D6gDMEDQ0NjBkzZsAu280RHBzMxIkTTQxBeHg4QUFBGqpyfDIzM3sVqa+oqGDPnj0D+qAidLkb+0poKKWksbFRuR97UF1dTWFhod3dQmClNNRCiEXAOroqjkkp5Us39HsDvwUqgAnAr6SUJ7v7HgKiAR1QLqV80xqaLJGRkaE+fGaIi4szblsTQiClpKqqCnd3d7sdanE2tm3bRkhIiHFFBV0H8sLDwwf8RCM2NpY///nPnD17lsjISLNjcnJyiIiIMPn/G8hosW3UQL9XBEIIX+AN4P9IKV8EZgghFt4w7MfAeSnlfwG/B97pvnYk8DTwdHdFs38RQths83VDQwOXL19WM10zxMXFcfXqVS5cuAB0+XH37dtHaWmpxsock567O3qeTndzc1OfL24eMDbsVpsyZYo9ZTk09ihSbwlruIYSgHNSSsNR1Hxg+Q1jltNV5N5QnnJmd2H7NGCf/Gr9WADYzByePn2aH/zgByZF2xVdmDtYlpCQoGZrFjh06BCVlZUmJQSvX7/OsWPH1KlsYNq0aXh7e/d5sCw8PFxt2uhGq22jBqzxjsOAnr6W+u62WxlzK9cCIIR4XAhRLIQorqqquiOhPj4+bNu2zZh/X/EVM2bMYNCgQSYzuKCgIHXWwgLZ2dkALFz41eL32rVrHD16VCtJDoWnpydz5szpM2AspeTSpUt9njcYKOzbt4+qqiqTbcg3cvnyZfbt22eT8ynWMASVgH+P5wHdbbcy5lauBUBK+ZaUMkZKGTN06NA7EnrlyhWg64i7whQvLy+io6NNZnBSSsrLy41nLxRfkZ2dzdSpU022id51112sWbNmwMcHDMTGxrJ///4+E+8VFRVRXl5uR1WOSVZWFkCf20abmpq4cuWKTfJXWcMQFABjhBCGT38isFUIMaTb/QOwlS4XEkKI6cBBKWU9kAHMEV+VLkoA0q2gySyXLl0ClCGwhCETqWHroxCCEydOGOMGii7a2tr48ssvWbRoUa++gZZkri9iY2NpaWkxSWjYEyEEqampdqnA5ejk5OQwY8YMk/MoNzJ+/HiWLVtmk0pv/TYEUspm4HvAH4UQPwcOSSlzgGeBJ7uH/YEuY/FT4N+Ax7qvvUjXbqLfCyF+B7wtpTzVX02WMMxsIyIibPUWTk1cXBzNzc0mN+7ChQtVnOAGdu/eTUtLi4khqK2tZe/evTQ1NWmozLG4WcAYIDAwcMCngm9paSE/P9/EzWgJW5X7tMr2USllFpB1Q9szPX5uAb5v4dr3gfetoeNm1NXV4ePjo3Z1WKBnCuFZs2YBKDeHGbKzs3F3d+fuu+82tjU3N1NZWamqb/XAkNCwoKCAJ554wuwYnU5HWVkZwcHBfc6GXZmCggLa2tpYsGCBxTEVFRWcOnWKuLg4fHx8rK5hQB0oe+mll7h+/boqom2Bu+66i9DQUJM4gV6vp6SkhPPnz2uozLHIzs4mPj6egIAAY9uIESNYsWKFMpw9EEKQmJhIfn6+xTFubm6UlpYa43cDkZycHNzd3UlJSelznJTSZp+vAWUIQPlw+0IIYTwRasDNzY2rV69SX1+voTLHoba2luLiYrPxATXB6E1SUhJlZWUWv+iFECxbtowZM2bYWZnjkJOTQ2xsrMnE4kZGjBjB/Pnzbba1dMAZAkXfxMfHc+zYMerq6oxtS5YsYdq0aRqqchx27NiBXq83MQTXrl0jOzvbJHuroovk5GQAdu3aZXHMQJ6cXb9+naKioj7dQlJKm9e2UIZAYUJKSgpSSpPlvJrpfkV2djaDBw82SWOu1+vx8PDA29tbQ2WOSXR0ND4+Pn0ago6ODoqLi427+gYSX375JXq9vs9AcUVFBVu2bLFpahxlCBQmxMbG4unpyZdffmls0+l07Ny5k9OnT2uozDHIzs7m7rvvNpnFDh06lNTUVBUfMIOnpyfx8fF9GgIPDw8qKysH5I6rnJwcvL29SUhIsDjG29ubsLAw/Pz8bKZDGQKFCT4+PsTGxpoYAnd3d7ssTx2dc+fOcerUKRYvXmxsU/8vNyc5OZkDBw5YnNEKIbjnnnsGZI3n3NxcEhMT+1xNhoaGEhsba9PUE8oQKHqRkpJCcXGxyQwtJSWFcePGaahKewxpJXrGB2pqatiwYQPV1dVayXJ4kpKS0Ov17Nmzx+KYgeh+rKys5PDhw326hXQ6nV1KnipDoOhFSkoKnZ2dZm/cgTz7zc7OJjw8nKlTpxrbPDw8GD16tEqe1gfx8fG4ubn16R5qa2tjx44dA2qbcm5uLkCfhuDKlSts3LjR5vmYlCFQ9GLevHm4ubmZuIc6OjrYtm0bZWVlGirTDr1eT3Z2NosWLTKZvQYGBjJnzhwVKO4Df39/Zs2axc6dOy2O8fLyws3NbUCtDHJzcwkICOgzxUZAQABRUVEEBgbaVIsyBIpeBAQEEB0dbWIIPD09GTZsmE0DVo7MoUOHqK6uNokP6PV6WlpaNFTlPCQnJ7Nnzx6LCeiEENx9992MGjXKzsq0Iycnh9TU1D5Po/v7+zN16lSbp+FQhkBhlpSUFPbs2WOSWz8mJmbA5mkyl3a6traWLVu2DMhtj7dLUlISLS0tHDhwoM9xUkr0er2dVGnH2bNnOX36dJ9uoc7OTmpqauzy/6EMgcIsKSkptLa2UlxcbNLe2dnZZ1phVyUnJ4dJkyaZpJ329fVl5syZqpTnLZCYmAjQp3uoubmZzZs3D4hst4b4QF8HyaqqqsjJybHLRgRlCBRmSUpKAjBxD7W2trJhwwbOnj2rkSptaG9vZ+fOnb1mbz4+PkycOFGdH7gFhg8fzvjx48nLy7M4xsfHh4iICHx9fe0nTCNycnIICwsjKirK4piQkBDi4+MZMmSIzfUoQ6AwS2hoKFFRUSaGwNvbm6ioKEJDQzVUZn+KiopoamoyMQR6vZ7Kykp0Op2GypyLRYsWkZeX12ecICYmhjstPOUsSCnJzc1lwYIFfQbHvby8GDVqlF0y2ipDoLBIcnIy+fn5xkI1AFOmTCE4OFhDVfYnNzfXGMw0UFtbyxdffKGqt90GixcvprGxsc/zBNC1Auv5mXM1jh8/zpUrV/p0C3V0dHDu3Dm71b9WhkBhkYULF9LQ0NCrfGV9fT2tra0aKrMvubm5zJo1yyQWEBgYSGJi4oDNoX8nLFiwADc3N2NZRnPU19ezceNGKioq7KjMvuTk5AB9nx+orq6msLDQbokMlSFQWGThwoW4ubmRkZFhbGtpaSEjI2NABPSg6/fdvXt3r9mbh4cHEREReHl5aaTM+QgKCiI2NrZPQ+Dv78+0adNcetWZm5tLZGQkkZGRFseEh4ezePFiu21E6Jch6K5L/JYQ4lkhxDtCiDAzY+YKIT4QQjwthPiTEOI7PfreEELk9XhM748ehXUJDg4mNjbWxBD4+voSFxdnsnvGldm9ezft7e0mhkCn01FeXq7OENwBixcvprCw0CTNeU+EEEyZMqXP3PzOjE6nIy8vr0+3EHT9PwQFBdmtjGd/VwS/BLKllL8CNtBVf/hGhgN/kFL+lq4axr8WQhiijVeklKk9Hof7qUdhZdLS0igqKuLatWvGttGjRw+InR3QNXtzd3c35tWHrvjA/v37qa2t1VCZc7J48WL0ej07duywOEav11NTU2OXHDv2Zv/+/dTV1fXpFmpvb+fw4cM0NjbaTVd/DcFyoKD75/zu5yZIKTdJKXtWr+4EDNsG/IUQzwshfiKE+IEQQhV8dTDS0tKQUhoPVEHXWYKLFy/S3NysoTL7kJubS2xsLP7+/sa2kJAQ7rnnHhUfuAPi4+MZPHjwTeMEOTk5LhmIv5XzA3V1dZw4ccKucbibGgIhRIYQosTMYxUwDDDklq0Hgm/yZf4D4JdSSkME5APgZSnly8Bo4P/2oeNxIUSxEKK4qqrqVn43hRWYO3cuQUFBJu6htrY2CgoKXDqgB11fSOaqRwkhGDx4sCpUfwd4enqSmprapyEIDAwkPj6e8PBwOyqzDzk5OURFRREW1suLbmTYsGGsXr3aLucHDNzUEEgp06SUs8w8NgGVgGGqFADUSinN7vsSQjwI+Ekpf9/jtff3GJ8LWDSTUsq3pJQxUsoYV99n7Eh4eHiwaNEiMjIyjJlH/fz8WLBggcunpd65cyc6nc7EEHR2dlJSUqLKUvaDxYsXU1ZWxpkzZ8z2CyEYNWqUyx3Ua2trY9euXX26hQx4enratP7AjfT3nbYChtI6id3PEUK4CSFGGwYJIf4FGCal/LkQYroQYmJ3+296vNYEYGCmtnRw0tLSuHTpEkePHjW2hYSE2PWDqgW5ubkMGjTIpHpUQ0MDp0+fVoHifrBkyRKAPlcF7e3tnD171qW2Ke/Zs4eWlpY+DUFrayu7d++2e/ypv3fyc8BiIcRPgXXA093tM/jKKKwGfgesEULkAR8ChsxlQ4UQvxJCvADEAz/tpx6FDUhLSwMwcQ+1trZSWlpq14CWvcnNzWXevHn4+PgY24KDg1m9erWKD/SDSZMmMXLkSJPP0400NTVRVFREZWWlHZXZlpycHNzc3EhJSbE4pqmpiZqaGrvX/RDOWGgkJiZG3pgMTWFbpk6dyqhRo4w3b1NTE9u2bWPu3LmMHTtWW3E2oLq6mqFDh/Lzn/+c559/Xms5LscTTzzBhx9+SHV1tVkXkJSS69evExgY6DI1ChITE+ns7DQ5oGkOw3eyLX5vIcQ+KWXMje2uvbZXWI20tDS++OIL404hPz8/Vq1a5ZJGADAmR+sZH+jo6GDnzp2ozQr9Z+XKlTQ2NprksuqJYR+9qxiBhoYGCgsLbyk+IISw+++tDIHilli+fDltbW0m20hdLZjXk9zcXAYPHkxMzFeTp5aWFpqbmwd0uU5rsXDhQnx8fNi8ebPFMU1NTRw5csQl4jE7d+6ks7Ozz22jzc3NZGRkaOIOU4ZAcUukpKQQEBDApk2bjG2NjY0UFhZSX1+voTLbkJubS0pKCp6ensa2gIAA0tLSVHzACvj4+LBo0SI2b95s0bC2t7dTWlpq8RSyM5GTk8OgQYOMdRnM0dHRgY+PjyYTLGUIFLeEl5cX99xzD5s3bzamXhZCcPnyZZqamjRWZ10qKio4ceLETdMAKPrHihUrOHv2rMlutJ4EBQWxevVqhg8fbmdl1sfcxoMbCQwMJCUlxeb1ic2hDIHillm9ejWVlZUUFnYdFDfECVzhRu2JIf1BT0PQ3t7Otm3bXP4QnT1ZsWIFgEX3kBDCZEXmrFRXV1NSUtLnxELrEp3KEChumaVLl+Lh4WHiHnKVYF5PcnNzCQ4OZubMmca2jo4OgoKC8Pb21lCZaxEREcGcOXP6jBPU1dWxe/dup44TGCYWfQWKm5qa2LBhg2YTDWUIFLdMcHAwKSkpbNy40dhWW1tLTk6Oy5y0lVKSk5PD/PnzTQ7M+fn5MW/ePFWf2MqsXLmSPXv2WNyJJaWkpqbGqfNaZWdn4+/vb7Lx4EaEEIwdO1azrKvKEChui9WrV3P8+HFOnToFfLVzyFUK2p85c4bz58/3Wsa7csUsLVm5ciVSSrZt22a2PygoiOXLlzu1Ac7KymL+/Pl9urn8/PyYPXu2SXJDe6IMgeK2WLlyJfCVX9fX15eFCxe6TB1jc9khm5ub2bBhA+fPn9dKlssSHR1NRESEibuxJ1rsqbcm5eXlnDlzhsWLF1scI6XUfMOFMgSK2yIyMpLp06ebuIeg68PsCvvrc3JyGD58OJMnTza2CSGYNGmSS1fN0gohBKtWrSIjI8NiHKCmpoaMjAyndD8a8ikZ8iuZo7a2lm3btnHx4kV7yeqFMgSK22b16tXs2rXLWKymtraWTZs2OX1eGJ1OR1ZWFosXLzaZhfr4+DB9+nTNlu2uztq1a2lqajI5rNgTb29vvL29jduWnYmsrCxGjx7NhAkTLI7x9fVl1qxZaJlVWRkCxW2zatUq9Hq90a87ePBgl6jfe+DAAa5du2ZMsgddK526ujqXWO04KqmpqQQEBLBhwwaz/b6+vtx99912zc9vDTo7O8nJyek1sbgRb29vJkyYoOlJfWUIFLfNnDlzGD58uNE95Onpydy5c53edWJIqLdo0SJjW11dHVlZWVy4cEErWS6Pl5cXy5cvZ9OmTX3O+nU6naZ77W+X4uJirl+/3md8oLOzkytXrmi+GUEZAsVt4+bmxqpVq9i+fbtJvvjW1lbNP9D9ITMzk9mzZ5ukkPDz8yMmJqbPilKK/rN27Vqqq6vJz88323/t2jU2btxIdXW1nZXdOVlZWQgh+jw/UFVVxc6dO01qgmuBMgSKO2LVqlU0NTUZD8vU1dWxefNmLl26pLGyO6O+vp7du3f3Cup5eXkRGRnp0gn2HIGlS5fi5eVl0T0UEBDgdH+HrKwsZs+e3eeOumHDhpGcnKz5rjtlCBR3xIIFC/Dz8zO6hwIDA5kxY4bT+XEN7Nixg87OTpP4QGdnJxcuXHCZMxKOjL+/P4sWLWLDhg1m4zGenp5ER0drkofnTmhoaKCgoKBPtxCAu7s74eHhuLu720mZeZQhUNwR3t7eLF26lE2bNqHX641bLAcPHqy1tDsiMzPTeHrYQHV1NXv27NF82T5QWLt2LWfOnOHQoUMWxzQ2NjqF+zEvL4/Ozs4+DUFraysnT550iHKc/TIEQoghQoi3hBDPCiHeEUKYdaQKIc4KIfK6Hx/0aB/bfd3/FUK8KYRwzm+RAcratWu5fPmyseKSXq+nqqrKKfPCZGRkMH/+fJOdT8OGDWP+/PmabusbSKxcuRIhhEX3UG1tLenp6U7hfszMzMTHx8dkYnEj1dXVHDx40PkNAfBLIFtK+StgA/BbC+P+IqVM7X58o0f7G8CbUsr/Ao4AP+mnHoUdWb58OR4eHnz22WdA1wwnLy/P6XbYlJeXU15e3is+4ObmRmhoqObL9oFCWFgY8+bNs2gIgoKCiI6O1tyffjOklGzdupWFCxf2maRw5MiRLFu2zCHcXf01BMuBgu6f87ufmyNFCPGMEOI/hRDzAIQQnsB8oOgWrkcI8bgQolgIUaxKBToGQUFBLFiwgM8//xwpJb6+viQlJREZGam1tNsiMzMTwCQ+0NTUxLFjx5xydePMrF27lpKSEs6cOdOrTwjB+PHj8fX11UDZrVNaWsqZM2dYvtzi15kRPz8/h0ihcVNDIITIEEKUmHmsAoYBDd1D64FgIYSHmZd5Vkr5a+C/gHeFEOOBUKBFfhUZqu9+PbNIKd+SUsZIKWPUUt1xWLduHeXl5Rw5cgSA4cOHO10O+e3btzNmzBiT05/Xrl3j6NGjTnma1ZlZs2YNQK8UJgZ0Oh2XL1+msbHRnrJui61btwKwbNkyi2NqamrYt2+fQ7iF4BYMgZQyTUo5y8xjE1AJGM7dBwC1UspekRwpZWH3v81ACZAIVAM+4itzGND9egonYvXq1Qgh+Pzzz4GuG/X06dNOE2BtaWkhOzubFStWmMzMRo8ezapVq5w2+O2sjBs3junTp1t0D3V2drJr1y7OnTtnZ2W3ztatW5k+fTqjR4+2OKahoYGLFy86jNuxv66hrUBC98+J3c8RQrgJIUZ3/7xQCLG0xzXjgXIpZQewA5h74/UK5yE8PJyEhASjIRBCcOjQIU0TaN0OO3bsoLm52ZhVtSfOtGfdlVizZg07d+40W6Ng0KBBLFiwwCQpoCNx/fp1du3adVO30JgxY1i1apXDrJ77awieAxYLIX4KrAOe7m6fwVdf6pXAd4QQzwkhXgU+lVLu6u77LvDd7uunAy/3U49CA3r6dd3c3FiyZAkzZszQWtYtsXnzZgYPHkxqaqqx7erVq+zdu9dhlu0DjTVr1qDX69myZYvZ/pCQEIeZSd9IVlYWnZ2dtxQfcITYgIF+GQIpZY2U8jtSyp9LKR+RUl7tbi+RUk7v/vmwlHK9lPKXUsofdO8QMlx/Vkr5aPf1j0spHdfxp7DI2rVrAYzLeV9fX4f6kFtCSsmWLVtYsmSJyey/paWF6upqh5mtDTSio6MZPXq0cZV5I3q9npMnT3LlyhU7K7s5W7duJTg4mPj4eItjzpw5Q15enkMdVFQHyhT9xuDXNdy4UkoOHTpkdueHI1FSUsLFixeNRdQNjB07lmXLljnsrNPVEUKwZs0aMjMzzQaFhRCcOHGCy5cva6DOMoaMvGlpaXh4mNsz04Wbmxvu7u59jrE3yhAorMK6devYtWsXlZWVCCGorq52+EIimzdvRghhsow3bGJzhhWNK7NmzRra2tqMW3t7IoQgLS2N6OhoDZRZZt++fVRWVt5SfCA5OdmhPmPKECiswtq1a5FSGksOzp8/n1mzZmmsqm82b95MXFycSbbRkydPkp2drbaNakxycjJDhgyx6B5yxNoXW7duRQjB0qVLLY7p7Ox0yNoWyhAorMKMGTOIjIw02T0EOOSHHuDSpUsUFxf32i3k4+ODv7+/cgtpjIeHB6tWrWLTpk20tbWZHVNSUsLx48ftrMwyn332GYmJiX2efD506BDbt293uPtCGQKFVRBCsHbtWrKzs6mvrwdg//79xjxEjobh0M+NhmD06NHExcVpIUlxAw888AD19fVs377dbH9LS4vD7Ow6deoUhw8fZv369X2OCwsLIzIy0qHcQqAMgcKKrF+/nvb2duOpUG9vb4dNB7Bp0ybGjBnDtGnTjG2tra1OVQHL1VmwYAGhoaH8/e9/N9sfHx/vMHGCTz/9FOiKlfXFiBEjHPIMhDIECquRkJDA2LFj+eCDrgSzU6dOdcjzBHV1dWRmZrJ+/XqTmVlRUZGx0I5Cezw9Pbn33nvZtGkTTU1NvfoNfztHMN6fffYZc+fO7fM0cV1dHe3t7XZUdesoQ6CwGkIIHnzwQbKzs7l69aqx3VGW7wY2bdpEe3s79913n0n7XXfdZZJvSKE9DzzwAM3NzRYPlx08eJCcnBw7qzLl/PnzFBUV9ekWklJSUFDgsK5SZQgUVuXBBx9Ep9Pxj3/8A4DDhw+zfft2h5i1Gfjkk0/MxgJGjBjR54xOYX+SkpKIiIiw6B4KCgoiPDxc08+XIQ37zdxCsbGxTJ061R6SbhtlCBRWJSoqipkzZ/Lhhx8CXdlIo6KiHMYQ1NXVkZGRwX333WfiFrp69arDrVwUXaUc77//erDdOgAAFW1JREFUftLT082eSxkzZgzTp0/HzU27r7JPP/2U6dOn97maFEIQEhJCSEiIHZXdOsoQKKzOgw8+yJ49eygvLyc0NJQJEyY4zCnKjRs30tHRYeIW0ul05Ofnc+zYMQ2VKSzxwAMP0NbWZjE1tZTSuFPN3ly5coX8/Pyb7hYqKyujoaGhzzFaogyBwup8/etfB+Cjjz4Cvsoh7wh7pw1uodjYWGObm5sbCxYsUPEBByU2NpaxY8caP083curUKTIyMjQpImQoytSXIWhtbeXAgQMOXWJTGQKF1Rk1ahQpKSl88MEHSCmpqKhg165dmtcoqK2tJTMzk/vvv9/ELSSEICgoCH9//z6uVmiFYRNCZmYmFRUVvfojIiKIiYnRZNX597//nUmTJhEVFWVxjLe3NytXrnToyn3KEChswje+8Q1KS0vZt28fERERJCUlMWTIEE01mXMLdXZ2cvDgQYeueKWARx99FL1ez1//+tdefYMHDyYyMtLu2WLPnDnDl19+yTe/+c2bHhDz9vZ2yLQYBpQhUNiEr33ta/j6+vL666/j4eHB8OHDNQ3oAXz88ceMGTOGuXPnGttqa2spKyujublZQ2WKmzFu3DhSU1N59913zW480Ol0nD9/3q5/x/fffx+Ahx56yOKY+vp69uzZ4/ATDWUIFDYhMDCQhx56iA8//JCamhp0Oh0nT540W3XKHlRUVJCZmck3vvENk9nb0KFDWblyJaoOtuPz2GOPUV5eTl5eXq++trY29u7dy4ULF+yiRUrJe++9R2pqKmPGjLE4rrGxkcrKSofZLGEJZQgUNuP73/8+ra2t/OUvf0EIQWlpqWY55P/2t7+h1+t55JFHevV5eXk5XO4XRW/Wr1/PkCFDePXVV3v1+fr6smjRIiZOnGgXLXv37uXUqVN861vf6nNcREQEK1euxNvb2y667pR+GQIhxBAhxFtCiGeFEO8IIcLMjEkVQhwVQuR1P44JIV7s7nujR3ueEGJ6f/QoHIsZM2aQlJTEa6+9BkBaWpomKSeklLz77rukpKQwfvx4Y/vp06fZtWsXnZ2ddtekuH18fHx4/PHH2bhxI2fPnu3VHxwcbDeD/re//Q0fH58+dwsZXFjOMMno74rgl0C2lPJXwAbgt2bGXAIeklKmSilTgQLgz919Vwzt3Y/D/dSjcDCefPJJysvLyczM1KwYfH5+PmVlZTz66KMm7VJKpJQOv2xXfMWTTz6JEIL//d//Ndt/4sQJTpw4YVMNbW1t/P3vf2ft2rUEBARYHHfgwAHy8vIcYtv0zeivIVhO1xc7QH73cxOklCellAcAulcMg6SU57q7/YUQzwshfiKE+IEQwuIdKYR4XAhRLIQo1srPrLh91q9fz7Bhw4yrguPHj1NQUHCTq6zLu+++y+DBg7n33ntN2seNG0dycrJdtSj6x6hRo1i/fj1vv/222UR0165do6amxqYatm7dSm1t7U3dQsHBwQwdOtQpVgTGWZGlB5ABlJh5rALagKDucR6ABDz6eK2XgKQez2cbxgO/Bv7fzfRIKZkzZ45UOA/PP/+8FELI06dPy+PHj8uCggKp1+vt8t719fXSz89PPvbYYybtra2tdtOgsC67du2SgHz99dd79el0Opu//4oVK2R4eLjs6Oiw+XtZG6BYmvlOvemKQEqZJqWcZeaxCagEDKdwAoBaKaVZh6sQYhAQI6Xc1eO19/cYnwssuBXjpXAuvvvd7+Lu7s4f/vAHJk+eTHx8vN1mSZ988glNTU0mbiEpJTk5Oezbt88uGhTWZd68ecyZM4c//vGPvdwuhi3Ktsptde7cObZu3cpjjz3Wp0vx2rVrDpNf61bor2toK5DQ/XNi93OEEG5CiBvTOD4ImJwRF0L8psfTCUBZP/UoHJCRI0fy9a9/nbffftu4bG9pabGL7/Sdd95h0qRJJCQkGNuklEyaNImRI0fa/P0V1kcIwY9+9COOHz9utrj9hQsX2Lx5s02SCP7pT39CCMHjjz9ucUxLSwu5ubmUlpZa/f1tRX8NwXPAYiHET4F1wNPd7TPoNgo9uA/4+Ia2oUKIXwkhXgDigZ/2U4/CQXn66adpamri9ddfp6qqiq1bt5rULLAF+/btY/fu3TzxxBMmKxA3NzfGjRtHeHi4Td9fYTvuv/9+hg8fzm9+85tefYGBgURERFh9Rt7e3s7bb7/NsmXL+kxXPmjQIObNm9fn+QKHw5y/yNEfKkbgnCxdulSGhYXJxsZGefjwYdnU1GTT93v44Yeln5+frKurM7a1tLTI8+fP28WXrLAtv/nNbyQgCwsL7fJ+77//vgTktm3b7PJ+toA7jREoFNbi3//937l69Soffvgh06ZNs2k948rKSj766CO+/e1vExgYaGw/f/48e/bsMbvjROFcPP744wQFBfHyyy+b7W9qajJbw+BOkFLyyiuvMHnyZNLS0iyO+//tnXtwVFWexz8/EhLIQCRswBhTBdGE+IAFYih1xxo2KI81gVHJzsCyD2UtWUGwVGBwpkQeoqCZZVfckQGlXKdmfCwku0ik0AUqYbLggGRJgoMDiGSLhFcIRcIjhPRv/+ib0A3dgby6O+nfp6or95x77r3f/O4593fveZ44cYJDhw51qfYBsJHFRgDJzMwkPT2d3NxcXC4XNTU1nTYlwDvvvMPly5d57rnnvOJTU1MZM2aMzTTaDYiNjWXWrFnk5eVdN3ZAVdm+fTulpaUdcq2ioiL27t3Liy++2OKcWceOHePbb7/tGl1GPRDtAoMdriUjI0P37NkTbBlGG/j444+ZOnUq69evJzExkerqarKysjq04NTW1jJo0CBGjx5Nfn5+h53XCD1OnjzJoEGDmDZtGu+99951+/r06dMhX57Z2dl89dVXVFRU0Lt37xbT1tfXB23w5I0Qka9VNePaePsiMAJKTk4OQ4YMYcmSJQwbNozx48d3+NvT2rVrqampYcGCBc1xqkpxcTEVFRUdei0juAwcOJDp06fz4YcfXrdWwcCBAzvECZSUlFBQUMDzzz/fohNoqg4KVSfQEuYIjIASGRnJK6+8QmlpKV988UXzHPId9WV68eJFcnNzyczM9Fqc/vLly9TX13eJ4f5G65g7dy4ul4vly5dft+/8+fPs2rWrXdNTv/baa9xyyy3Mnj3bb5q6ujo2bdrU6T3hOgtzBEbAmTJlCkOGDGHhwoVcuHCBwsJCjhw50iHnfvfdd6mqqmLRokVe8dHR0WRmZrbY7c/omiQnJ/P000+zevVqDh3yHookIpw4cYKzZ8+26dxlZWXk5eUxZ84cr04H16KqxMfHtzj3UChjbQRGUNiwYQM5OTmsWrWKESNGkJSUxODBg9t1zrq6OpKTkxk5cqTXQKPa2lp69eoV8BWsjMBRVVVFSkoK2dnZfPKJ93ClxsZGIiIi2nTe7OxsiouLOXz4cNBX2OsIrI3ACCmeeOIJxowZw8KFC7nrrrva7QQA3nrrLU6fPs3SpUub41SVXbt2UVRU1O7zG6HLbbfdxrx58/j000/ZsmWL174mJ9DaVcIKCwspKCjg5ZdfbtEJHD16lPr6+taLDiHsi8AIGvv372fEiBFMnDiR9evXc/z4cQYMGNCmN/eKigrS0tJ47LHH+Ogjr5lMOHPmDA0NDdx663XLZRjdiEuXLpGenk5tbS3l5eVeVTmHDx+mpKSEcePG3VT1TWNjIw888ABVVVUcPHjQbyPxxYsXKSgoIC0tjWHDQn85FfsiMEKOe++9l+XLl5Ofn09ubi7FxcVtbiuYP38+IuJzcFH//v3NCYQBvXr14oMPPqCyspKnnnrKa1BXUlJSqwYxrl27lj179vDmm2+22FOod+/ejBs3jrS0tHbrDyq+hhuH+s+mmOg+NDY2anZ2tkZEROi6devaNPXDZ599poAuXrzYK76srEzLyspsuukwY+XKlQroSy+91KZ7f+LECY2Li9PMzMwWj+9O01AH/aHelp85gu7FuXPn9P7779eoqCjdtGmTNjQ03HQBPnv2rN5+++06dOhQra+vb453uVy6e/du3b17d2fJNkIUl8uls2bNUkBfeOEFr5eL6upqLSws9Mor1x47adIkjY6O1m+++cbvNS5duqQbN27UgwcPdrj+zsSfI7A1+oyg07dvXz7//HPGjh3LpEmTmDlzJjNnzuTuu+9u8ThVZfr06VRVVZGfn09UVFTzPhEhIyPDxg2EISLC22+/TWRkJCtXruTUqVOsW7euue2ptraWCxcueOWXJtasWcPGjRtZuXJli/kvIiKCxMRE4uPjO+3/CCi+vEOo/+yLoHtSW1urjz76qAI6Z86cG1YTLVu2TAHNzc1tjnO5XHrgwAGtq6vrbLlGiONyufT1119XQCdMmNA8C62/fLVt2zbt2bOnjh07tsW815WrGrGqIaMr0NDQoDNmzFBAs7KytKqqyme6FStWKKBTp071Kph1dXWal5en+/fvD5RkI8RZu3atRkZGampqqpaUlKjq1ReG48ePq6rqjh07NDY2Vu+55x49c+aM33NVVlbq1q1b9dKlSwHR3tGYIzC6DC6XS1etWqVRUVEaGxury5Yt08rKSm1sbNSysjLNyclRQKdMmeKzrreurq5Lv7UZHU9RUZEmJCRoRESEzp49W0tLS3XLli26efNmffXVVzUiIkJTUlL06NGjLZ7n2LFjum3bti7ZUKzaSY4Ad/fTGbjXLh7aQrpHgF8Bi4BXPeL7A2uABcD7wK03c11zBOFBUVGRjho1SgEFtGfPngpoTEyMLlmyRK9cuaKqbsexb98+PXLkSHAFGyFNdXW1zpgxQ3v06KGAikhz3po8ebLW1NT4PM7lcnnt68ovGf4cQbsGlInISMeQ/wlkq2q5jzQxQClwr6rWi8gG4FequlVEVgPbVPVTEZkI/ERV/+5G17UBZeHF3r172b59O+Xl5WRkZDB58mQSEhLcGVgEVaWoqIi+ffuSnp4ebLlGiHP8+HHy8/OprKwkJiaGxx9/nIqKCgYMGMDIkSOvS3/gwAHKy8sZP358l1/Hwt+Asnb1GlLVEufkLSV7EDiqqk1jsIuBLGCr83eZR/y/t0eP0T1JT08nISGBnTt3MmbMGOLi4vjuu+/Yt28fWVlZREVF8dBDD7V5PhkjvEhISODZZ59tDqsqERERzdNHX758mS+//JLhw4eTlJREcnIyUVFR9OnTJ1iSO50bOgIR2QL4Gpa5UFU33sQ1BgK1HuFzTty1+84BcSISqapXfOh4BngGsBkkw5DExEQmTZrU3AWwX79+pKSkcOXKFaKioswJGG1GREhNTW0ONzY2Eh8f39y9NDo6mjvuuCNY8gLCDR2BqvpfoPPmOAl4fk/FOnGe+8468TW+nICjYw3u9gQyMjKsc3gY4jkHUf/+/bvFbJBG6NG7d2+vtSzCgU6ba0hEkp3NncAgEWlatueHQIGzXYC76ujaeMMwDCNAtKuNQETigFnALcAzIvI7Vd0lIgOA34vInap6QUSeBd4WkVNAqapudU7xc2CFiAwB7gTmtkePYRiG0XpsGmrDMIwwwaahNgzDMHxijsAwDCPMMUdgGIYR5pgjMAzDCHPMERiGYYQ5XbLXkNMN9WgbD48HTnegnI7CdLUO09U6TFfrCFVd0D5tg1R1wLWRXdIRtAcR2eOr+1SwMV2tw3S1DtPVOkJVF3SONqsaMgzDCHPMERiGYYQ54egI1gRbgB9MV+swXa3DdLWOUNUFnaAt7NoIDMMwDG/C8YvAMAzD8MAcgWEYRpjTrmmouxoi8gjwBO4FcVRVFwdJx53Aa8BeIAmoVtUlIrII+EuPpMtU9csAa9sFXHKCjar6sIj0B5YD3wGpwM9V9UQANQ3GvbTp/zlRsbjXwf6eANtLRBJw37vhqjrKiesF5ALHcNtnuar+ydn3t8BIoBE4rKq/DqCunwEJwHHgPtyrCh5w9n2P234Ax1R1WgB1PQn8E1fz2fuq+htnXzDt9T7u6fCb+HMgXVW/D6C9/D0b/JZBEZmHu0zEAV/c5MqR3vha0b47/oAY4BAQ7YQ3AA8HScso4Mce4W9wF9RFIWCn6zQAq4GfONsTgd8EWNOfAY94hBcDDwXDXkCOY4M9HnELgPnO9jBgh7OdBPwvV9vidgOpAdS11OPaPwU+a+k+B1DXk8BgH2mDba+femzHAnlBsJe/Z4PPMgjcD3zubPcEDgL9WnvdcKoaehA4qqr1TrgYyAqGEFXdrar/5RHVAzgPICK/EJG5IvIzEYkJgrxhzrUXiUiTfbJwrzQHQbCbqlar6n8DOCvdZajq751wQO2lquvxXoMbPOyjqmXAcBGJBcYDX6tTSp00fxUoXar6ise1ewB1Hrt/JCLzRWSpiPxFZ2jyp8vhOee+LXTediH49vrEI/iPwDqPcKDs5e/Z4K8MZnM17zUAfwR+1NrrhlPV0EC8b/w5Jy6oiMjjwBZVPSAi/wF8r6rnRWQmsAp3hgwkK1T1DyISARSJSC3etjsHxIlIpPpZX7qT+RvgI2c7FOwF/vNWSOQ5EYkC/gH3aoJNLHDucwywV0SyVfVQgCQVAgWqekpEHsV9Hx8mdOzVA7dT+heP6IDb65png88yiNs+f/Q4rE02C6cvgpNAX49wrBMXNEQkE8gEXgBQ1f2qet7ZvQ0YE2hNqvoH528jsMPR52m7WKAmSE4A4K+BTyA07OXgL28FPc85TuBd4Beqergp3uM+X8BdHfPDQGlS1SOqesoJbgNGOy8eQbeXw4+BTR5fJgG317XPBvyXwQ6xWTg5gp3AIKdqAdw3siBYYpxql/HA80CCiDwoIm95JEnF3aYRSE13iYjnG3WThgLcVWsQRLs5heN/nE9ggm0vD5rtIyLDgH2qeg7YAtwnIuKkexDYHChRItIb+DXwz6r6tYhMduIfFpEJHklTgMO+ztFJut5w3mbBfd+OOC8eQbWXB08CHzQFAm0vX88G/JfBTVzNe5HAPUBRq6/p4fS6PSIyFncj0SmgQYPXa+g+3J/HTQsv/wD4NyANd6P2SdyNjgvV6X0SIF2Jjo69uN8segIvAv2AFbhnfL0T92dywHoNeej7CJitqqed8BsE2F4iMhr4e2AC7jftXzq7coEq3A+J19W711AG7l4wf9LO6wXjS9dvgaFApZPsB6o6ynFWi4CvgUTcvWDeCKCuZxxdR3Dft39V1V1O+qDZS1UvisgIYJqqzvNIG0h7+Xs2bMRPGXR6DcU5v83ahl5DYeUIDMMwjOsJp6ohwzAMwwfmCAzDMMIccwSGYRhhjjkCwzCMMMccgWEYRphjjsAwDCPMMUdgGIYR5vw/V6CHNkZLVvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.figure()\n",
    "plt.plot(toy_problem(T, ampl=0), linestyle='dotted', color='#aaaaaa')\n",
    "plt.plot(original, linestyle='dashed', color='black')\n",
    "plt.plot(predicted, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과\n",
    " - 매우 흡족스럽니다. 근데 얼리 스탑핑 기법을 적용하려 했는데 이것도 자꾸 오류나서 그냥 뺏습니다. 굳이 없어도 막 이상하지는 않은 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
