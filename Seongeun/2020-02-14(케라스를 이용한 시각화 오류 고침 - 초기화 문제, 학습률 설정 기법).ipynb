{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 케라스를 이용한 학습 시각화\n",
    " - 지난 번에는 케라스를 사용했을 경우 학습이 제대로 이뤄지지 않았던 것을 확인할 수 있었습니다. 그 이유를 생각해봤는데 기존 매개변수를 초기화하는 과정에서 텐서플로우의 경우에는 tf.truncated_normal(shape, stddev=0.01)를 이용해 오차역전법이 잘 작동하도록 조정하였는데 케라스에서느 아무것도 지정해준게 없었습니다. 따라서 케라스에서 모델을 만들 때도 절단정규분포를 이용하면 학습이 잘 될 것이라 생각합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras 모델을 만드는데 필요한 라이브러리들\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:85: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:85: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 셋, 데이터를 섞고 분류할 함수 불러오기\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 전처리\n",
    "n = len(mnist.data)\n",
    "N = 10000\n",
    "indices = np.random.permutation(range(n))[:N]\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]\n",
    "\n",
    "N_validation = 4000\n",
    "\n",
    "# train, test 분류\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "# train데이터에서 validation 분류\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size = N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = len(X[0])\n",
    "n_hiddens = [200, 200, 200]\n",
    "n_out = len(Y[0])\n",
    "activation = 'relu'\n",
    "p_keep = 0.5\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def weight_variable(shape, dtype=None):\n",
    "    return K.truncated_normal(shape, stddev=0.01)\n",
    "# numpy를 이용해도 됨.\n",
    "# return np.random.normal(scale=0.01, size=shape) 단, 이때는 절단정규분포가 아닌 일반적인 정규분포입니다.\n",
    "\n",
    "model = Sequential()\n",
    "for i, input_dim in enumerate(([n_in] + n_hiddens)[:-1]):\n",
    "    model.add(Dense(n_hiddens[i], input_dim=input_dim, kernel_initializer=weight_variable))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(p_keep))\n",
    "    \n",
    "model.add(Dense(n_out, kernel_initializer=weight_variable))\n",
    "# 직접 함수로 절단정규분포를 정의할 수 있지만 처음부터 from keras.initializer import TruncatedNodrmal로 함수를 가져올 수 있습니다.\n",
    "# model.add(Dense(n_out,, kernel_initializer=TruncatedNormal(stddev=0.01)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 4000 samples, validate on 4000 samples\n",
      "Epoch 1/50\n",
      "4000/4000 [==============================] - 1s 322us/step - loss: 2.3010 - accuracy: 0.0990 - val_loss: 2.2944 - val_accuracy: 0.1303\n",
      "Epoch 2/50\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 2.2907 - accuracy: 0.1353 - val_loss: 2.2789 - val_accuracy: 0.1203\n",
      "Epoch 3/50\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 2.2666 - accuracy: 0.1417 - val_loss: 2.2362 - val_accuracy: 0.1040\n",
      "Epoch 4/50\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 2.2024 - accuracy: 0.1523 - val_loss: 2.1096 - val_accuracy: 0.2800\n",
      "Epoch 5/50\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 2.0425 - accuracy: 0.2835 - val_loss: 1.8176 - val_accuracy: 0.4810\n",
      "Epoch 6/50\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 1.6882 - accuracy: 0.4308 - val_loss: 1.2725 - val_accuracy: 0.5782\n",
      "Epoch 7/50\n",
      "4000/4000 [==============================] - 1s 169us/step - loss: 1.3541 - accuracy: 0.5132 - val_loss: 0.9907 - val_accuracy: 0.6777\n",
      "Epoch 8/50\n",
      "4000/4000 [==============================] - 1s 158us/step - loss: 1.1379 - accuracy: 0.5893 - val_loss: 0.8469 - val_accuracy: 0.7452\n",
      "Epoch 9/50\n",
      "4000/4000 [==============================] - 1s 162us/step - loss: 1.0244 - accuracy: 0.6457 - val_loss: 0.7823 - val_accuracy: 0.7377\n",
      "Epoch 10/50\n",
      "4000/4000 [==============================] - 1s 146us/step - loss: 0.9203 - accuracy: 0.6845 - val_loss: 0.6840 - val_accuracy: 0.7920\n",
      "Epoch 11/50\n",
      "4000/4000 [==============================] - 1s 141us/step - loss: 0.8255 - accuracy: 0.7195 - val_loss: 0.6196 - val_accuracy: 0.8115\n",
      "Epoch 12/50\n",
      "4000/4000 [==============================] - 1s 159us/step - loss: 0.7457 - accuracy: 0.7580 - val_loss: 0.5550 - val_accuracy: 0.8395\n",
      "Epoch 13/50\n",
      "4000/4000 [==============================] - 0s 117us/step - loss: 0.6954 - accuracy: 0.7675 - val_loss: 0.5163 - val_accuracy: 0.8530\n",
      "Epoch 14/50\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 0.6375 - accuracy: 0.7922 - val_loss: 0.4657 - val_accuracy: 0.8665\n",
      "Epoch 15/50\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 0.5925 - accuracy: 0.8167 - val_loss: 0.4547 - val_accuracy: 0.8655\n",
      "Epoch 16/50\n",
      "4000/4000 [==============================] - 1s 161us/step - loss: 0.5515 - accuracy: 0.8267 - val_loss: 0.4362 - val_accuracy: 0.8708\n",
      "Epoch 17/50\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.5191 - accuracy: 0.8365 - val_loss: 0.4131 - val_accuracy: 0.8765\n",
      "Epoch 18/50\n",
      "4000/4000 [==============================] - 0s 121us/step - loss: 0.4936 - accuracy: 0.8443 - val_loss: 0.4008 - val_accuracy: 0.8815\n",
      "Epoch 19/50\n",
      "4000/4000 [==============================] - 0s 85us/step - loss: 0.4675 - accuracy: 0.8620 - val_loss: 0.3645 - val_accuracy: 0.8928\n",
      "Epoch 20/50\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 0.4222 - accuracy: 0.8680 - val_loss: 0.3501 - val_accuracy: 0.8960\n",
      "Epoch 21/50\n",
      "4000/4000 [==============================] - 0s 59us/step - loss: 0.4116 - accuracy: 0.8710 - val_loss: 0.3523 - val_accuracy: 0.9007\n",
      "Epoch 22/50\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.4094 - accuracy: 0.8800 - val_loss: 0.3440 - val_accuracy: 0.9047\n",
      "Epoch 23/50\n",
      "4000/4000 [==============================] - 0s 58us/step - loss: 0.3727 - accuracy: 0.8923 - val_loss: 0.3323 - val_accuracy: 0.9050\n",
      "Epoch 24/50\n",
      "4000/4000 [==============================] - 0s 58us/step - loss: 0.3536 - accuracy: 0.8967 - val_loss: 0.3180 - val_accuracy: 0.9103\n",
      "Epoch 25/50\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 0.3466 - accuracy: 0.8957 - val_loss: 0.3123 - val_accuracy: 0.9135\n",
      "Epoch 26/50\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.3163 - accuracy: 0.9075 - val_loss: 0.3015 - val_accuracy: 0.9130\n",
      "Epoch 27/50\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.3182 - accuracy: 0.9047 - val_loss: 0.2974 - val_accuracy: 0.9160\n",
      "Epoch 28/50\n",
      "4000/4000 [==============================] - 0s 60us/step - loss: 0.2957 - accuracy: 0.9118 - val_loss: 0.2967 - val_accuracy: 0.9140\n",
      "Epoch 29/50\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.2940 - accuracy: 0.9130 - val_loss: 0.3021 - val_accuracy: 0.9145\n",
      "Epoch 30/50\n",
      "4000/4000 [==============================] - 0s 86us/step - loss: 0.2845 - accuracy: 0.9143 - val_loss: 0.2819 - val_accuracy: 0.9210\n",
      "Epoch 31/50\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 0.2726 - accuracy: 0.9237 - val_loss: 0.2787 - val_accuracy: 0.9222\n",
      "Epoch 32/50\n",
      "4000/4000 [==============================] - 0s 58us/step - loss: 0.2508 - accuracy: 0.9240 - val_loss: 0.2734 - val_accuracy: 0.9252\n",
      "Epoch 33/50\n",
      "4000/4000 [==============================] - 0s 55us/step - loss: 0.2474 - accuracy: 0.9270 - val_loss: 0.2829 - val_accuracy: 0.9210\n",
      "Epoch 34/50\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 0.2425 - accuracy: 0.9285 - val_loss: 0.2704 - val_accuracy: 0.9243\n",
      "Epoch 35/50\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.2358 - accuracy: 0.9273 - val_loss: 0.2592 - val_accuracy: 0.9277\n",
      "Epoch 36/50\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.2168 - accuracy: 0.9385 - val_loss: 0.2681 - val_accuracy: 0.9255\n",
      "Epoch 37/50\n",
      "4000/4000 [==============================] - 0s 58us/step - loss: 0.2127 - accuracy: 0.9390 - val_loss: 0.2709 - val_accuracy: 0.9250\n",
      "Epoch 38/50\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 0.2102 - accuracy: 0.9383 - val_loss: 0.2590 - val_accuracy: 0.9290\n",
      "Epoch 39/50\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1837 - accuracy: 0.9423 - val_loss: 0.2753 - val_accuracy: 0.9258\n",
      "Epoch 40/50\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.1925 - accuracy: 0.9383 - val_loss: 0.2588 - val_accuracy: 0.9300\n",
      "Epoch 41/50\n",
      "4000/4000 [==============================] - 0s 59us/step - loss: 0.1793 - accuracy: 0.9490 - val_loss: 0.2687 - val_accuracy: 0.9287\n",
      "Epoch 42/50\n",
      "4000/4000 [==============================] - 0s 60us/step - loss: 0.1771 - accuracy: 0.9485 - val_loss: 0.2822 - val_accuracy: 0.9268\n",
      "Epoch 43/50\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1729 - accuracy: 0.9473 - val_loss: 0.2690 - val_accuracy: 0.9258\n",
      "Epoch 44/50\n",
      "4000/4000 [==============================] - 0s 95us/step - loss: 0.1655 - accuracy: 0.9490 - val_loss: 0.2763 - val_accuracy: 0.9298\n",
      "Epoch 45/50\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 0.1701 - accuracy: 0.9482 - val_loss: 0.2600 - val_accuracy: 0.9295\n",
      "Epoch 46/50\n",
      "4000/4000 [==============================] - 0s 57us/step - loss: 0.1578 - accuracy: 0.9523 - val_loss: 0.2601 - val_accuracy: 0.9293\n",
      "Epoch 47/50\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1549 - accuracy: 0.9530 - val_loss: 0.2579 - val_accuracy: 0.9330\n",
      "Epoch 48/50\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1505 - accuracy: 0.9567 - val_loss: 0.2663 - val_accuracy: 0.9310\n",
      "Epoch 49/50\n",
      "4000/4000 [==============================] - 0s 59us/step - loss: 0.1403 - accuracy: 0.9600 - val_loss: 0.2848 - val_accuracy: 0.9320\n",
      "Epoch 50/50\n",
      "4000/4000 [==============================] - 0s 61us/step - loss: 0.1283 - accuracy: 0.9615 - val_loss: 0.2663 - val_accuracy: 0.9317\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "hist = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 141us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22123635470867156, 0.9419999718666077]\n"
     ]
    }
   ],
   "source": [
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_acc = hist.history['val_accuracy']\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure()\n",
    "plt.plot(range(epochs), val_acc, label='acc', color='black')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과\n",
    " - 그래프와 수치를 보면 제대로 학습이 이뤄진 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정규화\n",
    " - 이제 MNIST외의 데이터를 사용해보겠습니다. MNIST외의 데이터를 똑같이 처리하기 위해서는 그 데이터를 어느정도 정돈해놔야 합니다. 정돈의 가장 일반적인 방법은 데이터의 값이 일정한 범위 내에 들어가도록 전처리를 해주어야 합니다. 가장 단순한 방법은 범위를 0에서 1로 설정하는 것입니다.\n",
    " - 일단은 MNIST를 위 방법으로 정규화해보겠습니다. MNIST데이터는 0~255의 RGB값을 취하므로 이를 감안하고 정규화를 진행하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0\n",
    "X = X.mean(axis=1).reshape(len(X), 1) # 데이터분포의 평균은 0이 되는게 왠만하면 바람직합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웨이트 초기화\n",
    " - 데이터의 값이 한쪽으로 치우치지 않으면 웨이트 값이 양수와 음수 반반을 가지게 됩니다. 그래서 웨이트 값을 처음에 0으로 초기화시켜둔다면 문제를 해결할 수 있습니다. 하지만 웨이트를 0으로 초기화하면 오차역전법을 활용한 학습이 제대로 이뤄지지 않는다는 사실을 아까 학습에서 확인할 수 있습니다.\n",
    " - 따라서 생각해볼 수 있는 방법은 0에 가까운 난수로 웨이트를 초기화하는 방법입니다. 그래서 지금까지 절단정규분포를 이용한 것이지요. 하지만 그럼에도 초깃갑이 너무 작으면 웨이트가 계수로 곱해지는 경사값도 너무 작아져 학습을 진행할 수 없게 된다는 문제가 발생합니다. 때문에 표준편차를 기존의 0.01에서 1.0으로 늘리는 방법을 생각해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeCun et al, 1988 문헌\n",
    " - 정규분포 또는 균등분포를 적용해 초기화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 균등분포\n",
    "# np.random.uniform(low=-np.sqrt(1.0/n), high=np.sqrt(1.0/n), size=shape)\n",
    "# kernel_initializer='lecun_uniform'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glorot and Bengio 2010 문헌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 균등분포\n",
    "# np.random.uniform(low=-np.sqrt(6.0/(n_in + n_out)), high=np.sqrt(6.0/(n_in + n_out)), size=shape)\n",
    "# 정규분포\n",
    "# np.sqrt(2.0/(n_in + n_out)) * np.random.normal(size=shape)\n",
    "\n",
    "# 텐서플로\n",
    "# tf.contrib.layers.xavier_initializer(uniform=True)\n",
    "# 케라스\n",
    "# init = 'glorot_uniform', init = 'glorot_normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# He et al 2015 문헌\n",
    " - ReLU를 사용할 경우 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(2.0/n) * np.random.normal(size=shape)\n",
    "\n",
    "# 케라스\n",
    "# init = 'he_normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습률 설정 기법\n",
    " - 지금까지 lr=0.001같이 학습률을 일정 상수로 정해 학습을 진행했습니다. 하지만 최적해를 찾기 위해서 학습률을 어떻게 설정해야할지가 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모멘텀\n",
    " - 학습률을 처음에는 크게 그리고 점점 작게하는 방법\n",
    " - 텐서플로에서는 tf.train.MomentumOptimizer() 즉, GradientDescentOptimizer를 MomentumOptimizer로 바꾸면 됩니다.\n",
    " - def training(loss):\n",
    "    - optimizer = tf.train.MomentumOptimizer(0.01, 0.9)\n",
    "    - train_step = optimizer.minimize(loss)\n",
    "    - return train_step\n",
    " - 케라스에서는 SGD에서 인수로 momentum=을 이용하여 지정합니다.\n",
    " - model.complie(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네스테로프 모멘텀\n",
    " - 기존의 모멘텀에서 매개변수가 어떻게 변해야할지를 고려해 학습률을 정하는 기법입니다.\n",
    " - 텐서플로는 optimizer = tf.train.MomentumOptimizer(0.01, 0.9, use_nesterov=True)\n",
    " - 케라스에선 optimizer = SGD(lr=0.01, mome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
