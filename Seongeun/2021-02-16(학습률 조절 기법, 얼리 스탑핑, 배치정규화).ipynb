{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adagrad\n",
    " - 모멘텀은 학습률을 고정하고 매개변수의 값을 변경할 때, 그 변경값을 조정하였지만 Adagrad는 학습률 자체를 변경하는 기법입니다.\n",
    " - 모멘텀과 비교하여 하이퍼 매개변수(매개변수의 변경값을 조정하기 위한 변수)가 적고 경사를 바탕으로 학습률 자체를 조정하는 방법으로 모멘텀보다 다루기 쉬운 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사코드\n",
    "# G[i][i] += g[i] * g[i]\n",
    "# theta[i] -= (learning_rate / sqrt(G[i][i] + epsilon)) * g[i]\n",
    "\n",
    "# 텐서플로\n",
    "# optimizer = tf.train.AdagradOptimizer(0.01)\n",
    "\n",
    "# 케라스\n",
    "# from keras.optimizers import Adagrad\n",
    "# optimizer = Adagrad(lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adadelta\n",
    " - Adagrad를 사용하면 학습률을 자동으로 조정할 수 있지만 학습이 진행될 수록 값이 급격히 감소하여 학습이 진행되지 않는다는 단점이 있습니다. 그 이유는 위의 식을 보면 아시겠지만 G에 제곱값을 더해가기 때문입니다.\n",
    " - 이를 해결하기 위한 방법으로 스텝을 거듭할 수록 계속 제곱값을 누적하는 것이 아니라 스텝 수를 제한하는 방법을 사용합니다.\n",
    " - 단순히 스텝을 제한하는건 비효율적인 방법이므로 모든 경사의 제곱합을 감쇠평균시켜서 재귀식으로 계산합니다.\n",
    " - 이때 사용하는 제곱평균제곱근을 RMS(root mean square)라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로\n",
    "# optimizer = tf.train.AdadeltaOptimizer(learning_rate=1.0, rho=0.95)\n",
    "\n",
    "# 케라스\n",
    "# from keras.optimizers import Adadelta\n",
    "# optimizer=Adadelta(rho=0.95) # 케라스에서는 학습률이 기본값으로 1.0입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSprop\n",
    " - Adadelta와 마찬가지로 학습률이 급격히 줄어드는 것을 방지하기 위한 기법입니다.\n",
    " - 학습률은 일반적으로 0.001과 같은 작은 값으로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로\n",
    "# optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "\n",
    "# 케라스\n",
    "# from keras.optimizers import RMSprop\n",
    "# optimizer=RMSprop(lr=0.001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam\n",
    " - 경사의 이동평균을 지수함수적으로 감쇠시킨 항을 추가하여 사용하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사코드\n",
    "# 초기화\n",
    "# m = 0\n",
    "# v = 0\n",
    "\n",
    "# 반복\n",
    "# learning_rate_t = learning_rate * sqrt(1 - beta2 ** t) / (1 - beta1 ** t)\n",
    "# m = beta1 * m + (1 - beta1) * g\n",
    "# v = beta2 * v + (1 - beta2) * g * g\n",
    "# theta -= learning_rate_t * m / (sqrt(v) + epsilon)\n",
    "\n",
    "# 텐서플로\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)\n",
    "\n",
    "# 케라스\n",
    "# from keras.optimizers import Adam\n",
    "# optimizer=Adam(lr=0.001, beta_!=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼리 스탑핑(조기 종료)\n",
    " - 지금까지 epochs를 일정수로 결정하여 학습을 진행했습니다. 학습횟수가 많아지만 오차는 줄어들지만 지나치면 오버피팅이 발생합니다. 이를 해결하기 위해 얼리 스탑핑을 사용합니다.\n",
    " - 쉽게 말해 이전 에폭 때와 비교해서 오차가 증가했다면 학습을 끝내는 기법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 - 텐서플로는 얼리 스탑핑을 자신이 직접 구현해야 합니다.\n",
    "# class EarlyStopping():\n",
    "#  def __init__(self, patience=0, verbose=0):\n",
    "#   self._step = 0\n",
    "#   self._loss = float('inf')\n",
    "#   self.patience = patience\n",
    "#   self.verbose = verbose\n",
    "\n",
    "#  def validate(self, loss):\n",
    "#   if self._loss < loss:\n",
    "#    self._step += 1\n",
    "#    if self._step > self.patience:\n",
    "#     if self.verbose:\n",
    "#      print('early stopping')\n",
    "#     return True\n",
    "#   else:\n",
    "#     self._step = 0\n",
    "#     self._loss = loss\n",
    "\n",
    "#   return false\n",
    "\n",
    "# early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "# for epoch in range(epochs):\n",
    "#  for i in range(n_batches):\n",
    "#   sess.run(train_step, feed_dict={})\n",
    "#  val_loss = loss.eval(session=sess, feed_dict={})\n",
    "\n",
    "#  if early_stopping.validate(val_loss):\n",
    "#   break\n",
    "\n",
    "# 케라스\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "# hist = model.fit(X_train, Y_train, epochs=epochs, batch_size-batch_size, \n",
    "#                  validation_data=(X_validation, Y_validaion), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치정규화\n",
    " - 데이터 셋을 정규화하면 학습 초기에는 잘 진행되지만 결국 네트워크 내부에서 분산이 편중되어 정리한 효과가 한정적입니다.\n",
    " - 배치 정규화는 학습에 사용하는 각 미니배치별로 정규화해 학습 과정 전체에서 효과가 있습니다.\n",
    " - 장점은 학습률을 크게 설정해도 학습이 잘 진행되고 트롭아웃을 사용하지 않아도 일반화 성능이 높다는 점입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로\n",
    "# tf.nn.batch_normalization()\n",
    "\n",
    "# 케라스\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# nmodel = Sequential()\n",
    "# for i, input_dim in enumerate(([n_in] + n_hiddens)[:-1]):\n",
    "#  model.add(Dense(n_hiddens[i], input_dim=input_dim, init=weight_variable))\n",
    "#  model.add(BatchNormalization())\n",
    "#  model.add(Activation(activation))\n",
    "\n",
    "# model.add(Dense(n_out, init=weight_variable))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
