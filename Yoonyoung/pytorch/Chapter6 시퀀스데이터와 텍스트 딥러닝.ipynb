{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter6 시퀀스데이터와 텍스트 딥러닝.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPH8KxrP++OqnPYA/y4ue6X"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hUq6hXjIwk_Z"},"source":["**텍스트를 문자로 변환**"]},{"cell_type":"code","metadata":{"id":"hIj1vl0_wBpx"},"source":["thor_review = \"the action scenes were top notch in this movie. Thor has never been this epic in the MCU. He does some pretty epic sh*t in this movie and he is definitely not under-powered anymore. Thor in unleashed in this, I love that.\"\r\n","\r\n","print(list(thor_review))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lhzLcvxhwi6O"},"source":["**텍스트를 단어로 변환**"]},{"cell_type":"code","metadata":{"id":"VJXvsVOgwsXn"},"source":["print(thor_review.split())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qIUVCEpywzl1"},"source":["**N-그램 표현**\r\n","\r\n","nltk패키지를 사용해서 2개 혹은 3개의 단어를 함께 묶어서 다룰 수 있다."]},{"cell_type":"code","metadata":{"id":"2-AGr_M6w_Bd"},"source":["from nltk import ngrams\r\n","\r\n","print(list(ngrams(thor_review.split(),2)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jsAXMqQ3xIBt"},"source":["ngrams 함수는 첫번째 전달 인자로 단어 리스트, 두번째 전달 인자로 그룹화할 단어 수를 받는다."]},{"cell_type":"code","metadata":{"id":"mB49NssPxN_C"},"source":["print(list(ngrams(thor_review.split(),3)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AdonrR88xUa3"},"source":["N-그램의 문제점은 텍스트의 순서 정보를 상실한다는 점이다.  보통 얕은 머신 러닝 모델에서 주로 사용된다. RNN이나 Conv1D에서는 사용되지 않는다."]},{"cell_type":"markdown","metadata":{"id":"6WyCwsV0xg_t"},"source":["### 벡터화\r\n","\r\n","**원-핫 인코딩**\r\n","각 토큰은 길이가 N인 벡터로 표현된다. 여기서 N은 어휘의 크기이다. "]},{"cell_type":"code","metadata":{"id":"F1Ej4fd4x5Fl"},"source":["import numpy as np\r\n","\r\n","class Dictionary(object):\r\n","    def __init__(self):\r\n","        self.word2idx = {}\r\n","        self.idx2word = []\r\n","        self.length = 0\r\n","    def add_word(self, word):\r\n","        if word not in self.idx2word:\r\n","            self.idx2word.append(word)\r\n","            self.word2idx[word] = self.length + 1\r\n","            self.length += 1\r\n","        return self.word2idx[word]\r\n","    \r\n","    def __len__(self):\r\n","        return len(self.idx2word)\r\n","    \r\n","    def onehot_encoded(self, word):\r\n","        vec = np.zeros(self.length)\r\n","        vec[self.word2idx[word]] = 1\r\n","        return vec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qR5Gu509yoly"},"source":["> **__init__**에서는 word2idx 딕셔너리 객체를 만든다. 이 객체는 고유 단어를 idx와 함께 저장한다. **Idx2word** 리스트 객체는 고유 단어를 저장하고 **length** 변수는 문서에서 고유 단어의 총 개수를 저장한다.\r\n","\r\n","> **add_word** 함수는 단어를 인수로 입력받는다. 입력된 단어가 기존에 idx2word에 없는 새로운 단어라면 추가한다.\r\n","\r\n","> **onehot_encoded** 함수는 단어를 전달 인자로 바당 길이가 N인 벡터를 반환한다. 예를 들어 한 단어가 word2idx에서 idx가 2라면 길이가 N이고 엔덱스가 2인 요소의 값이 1이며 나머지는 인 0 0 1 0 0 0 0 0 0 0 와 같은 벡터가 반환된다."]},{"cell_type":"code","metadata":{"id":"ckJWx4TezYDG"},"source":["dic = Dictionary()\r\n","\r\n","for tok in thor_review.split():\r\n","    dic.add_word(tok)\r\n","\r\n","print(dic.word2idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qO5b9KNhzmSB"},"source":["dic.onehot_encoded('were')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1XRFTugRzr8i"},"source":["원-핫 인코딩 표현의 문제점 중 하나는 데이터에 대부분이 0 값이고, 어휘의 고유 단어수가 증가함에 따라 벡터의 크기가 급격하게 커진다는 것이다. 그래서 별로 쓰이지 않는다."]},{"cell_type":"markdown","metadata":{"id":"kY7-ZZUTzz1f"},"source":["**워드 임베딩**\r\n","\r\n","워드 임베딩이 가장 많이 사용되는 방식이다. 워드 임베딩은 부동 소수점 형태의 수로 채워진 밀집 벡터 형태를 갖는다. 의미가 유사한 단어는 비슷한 벡터를 갖도록 조정된다. "]},{"cell_type":"markdown","metadata":{"id":"TPnVcb860isg"},"source":["## **감성 분류기로 워드 임베딩 학습시키기**\r\n","\r\n","### IMDB 다운로드와 텍스트 토큰화"]},{"cell_type":"code","metadata":{"id":"WTy6uSiO0vFD"},"source":["pip install torchtext"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_oqlIOaQ1Ab3"},"source":["from torchtext import data\r\n","TEXT = data.Field(lower=True, batch_first=True, fix_length=40)\r\n","LABEL = data.Field(sequential=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AuoewE0E2MUr"},"source":["TEXT는 모두 소문자로, 텍스트 토큰화를 수행하며, 공백을 없애고, 최대 길이를 20으로 제한했다. Field 생성자는 tokenize라는 인자를 갖는다. tokenize 인자의 기본값은 str.split이다. "]},{"cell_type":"code","metadata":{"id":"YuEjNpBf2hoA"},"source":["from torchtext import datasets\r\n","\r\n","train, test = datasets.IMDB.splits(TEXT, LABEL)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uhi67DVs3CCy"},"source":["위 코드는 datasets의 IMDB 클래스는 데이터셋을 다운로드하고, 토큰화를 수행한 후, 데이터 셋을 학습과 테스트로 분할하는데 필요한 작업을 추상화한다. train.fields는 딕셔너리 객체를 포함한다. 이 딕셔너리 객체에서 TEXT가  키고, LABEL이 값이다."]},{"cell_type":"code","metadata":{"id":"1J2Qb4Yc27Mb"},"source":["print('train.fields', train.fields)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqM8a8Dh3UgP"},"source":["print(vars(train[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TN0PKs8_3bUP"},"source":["### **어휘구축**\r\n","\r\n","데이터가 로드되면 build_vocab을 호출하고 데이터의 어휘 생성에 필요한 인수를 전달할 수 있다."]},{"cell_type":"code","metadata":{"id":"usSkEJaq4Dht"},"source":["pip install glove-python"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPaqn3ag3nE9"},"source":["from torchtext.vocab import GloVe \r\n","TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300),\r\n","                  max_size = 10000, min_freq = 10)\r\n","LABEL.build_vocab(train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ebHmrKac79xL"},"source":["어휘 객체를 생성하는 부분에 train 객체를 전달하고, 사전에 학습된 임베딩을 이요해서 벡터를 초기화하도록 했다. build_vocab 메서드는 사전에 학습된 임베딩 데이터를 다운로드한다. 사전에 학습된 가중치를 이용하면 더 효과적이다.\r\n","\r\n","max_size 는 어휘 객체의 크기를 제한하고 min_freq은 어휘에 추가될 단어의 최소 출현 빈도를 설정한다.\r\n","\r\n","위코드는 출현 빈도가 10번 이상인 단어로 최대 크기가 1만개인 어휘 객체가 만들어진다."]},{"cell_type":"code","metadata":{"id":"1CXoiVzm-USw"},"source":["print(TEXT.vocab.freqs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgj-dFvN-edB"},"source":["print(TEXT.vocab.vectors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_Vr0Jbd-iLG"},"source":["print(TEXT.vocab.stoi)\r\n","#단어와 단어의 인덱스를 관리하는 딕셔너리 객체에 접근"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-fpD8rvg-sVW"},"source":["### 벡터 배치 생성\r\n","\r\n","Torchtext는 모든 텍스트를 배치 처리하는 것을 지원하고, 단어를 인덱스 번호로 대체하는 BucketIterator를 제공한다. \r\n","\r\n","BucketIterater 인스턴스를 만드는 생성자는 batch_size, device(GPU, CPU 지정), shuffle(데이터를 섞을 것인지)"]},{"cell_type":"code","metadata":{"id":"4xKx0rMm_DpY"},"source":["train_iter, test_iter = data.BucketIterator.splits((train, test), \r\n","                                                   batch_size=128,  shuffle=True)\r\n","# device = -1은 cpu, 기본값은 GPU이다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_4BzyMU_a0F"},"source":["batch = next(iter(train_iter))\r\n","batch.text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DiWc7ETo_iUn"},"source":["batch.label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KnlT7QhF_mqh"},"source":["### 임베딩으로 네트워크 모델 만들기"]},{"cell_type":"code","metadata":{"id":"8hME-M9u_sGE"},"source":["import torch \r\n","from torch import nn\r\n","from torch.nn import functional as F\r\n","\r\n","class EmbNet(nn.Module):\r\n","    def __init__(self, emb_size, hidden_size1, hidden_size2 = 200):\r\n","        super().__init__()\r\n","        self.embedding = nn.Embedding(emb_size, hidden_size1) \r\n","        #nn.Embedding 클래스 객체를 2개의 전달 인자로 초기화. 첫번째는 어휘의 크기, 두번째는 인자의 각 단어를 표현할 차원의 크기\r\n","        #프로그램을 빨리 실행하려면 임베딩크기가 작은 것이 좋지만, 시스템용으로 빌드할 때는 크기가 커야한다.\r\n","        self.fc = nn.Linear(hidden_size2, 3)\r\n","        #마지막에는 워드 임베딩을 3개 카테고리(양성, 음성, 판단 보류)에 대응시키는 선형 레이어가 사용된다.\r\n","    \r\n","    def forward(self, x): #입력 데이터가 처리되는 방법(예를 들어 배치 32 최대단어 20인 문장은 입력 데이터의 형상은 32*20이 된다. )\r\n","        embeds = self.embedding(x).view(x.size(0), -1) \r\n","        #입력된 단어를 임베딩 벡터로 변환하는 룩업 테이블 역할.\r\n","        #워드 임베딩이 10차원으로 만들어진다면 데이터 형상이 32*20*10으로 나타나기 때문에 문장별로 평평하게 만들기 위해 view()를 사용한다. \r\n","        #view에 전달되는첫번째 인자는 해당 크기를 그대로 유지 예를 계속 든다면 x.size(0), 즉 32를 유지하고 나머지는 합쳐 출력 데이터 형상이 32*200이 된다.\r\n","        out = self.fc(embeds)\r\n","        #DenseLayer는 워드 임베딩 레이어의 출력을 받아 3개의 카테고리에 대응을 시킨다.\r\n","        return F.log_softmax(out, dim=-1)\r\n","\r\n","model = EmbNet(len(TEXT.vocab.stoi), 300, 12000)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6GzJ-o0YBy7q"},"source":["### 모델 학습시키기"]},{"cell_type":"code","metadata":{"id":"_DmOLo6oB2gQ"},"source":["def fit(epoch, model, data_loader, phase='training', volatile=False):\r\n","    if phase == 'training':\r\n","        model.train()\r\n","    if phase == 'validation':\r\n","        model.eval()\r\n","        volatile=True\r\n","    running_loss = 0.0\r\n","    running_correct = 0\r\n","    for batch_idx, batch in enumerate(data_loader):\r\n","        text, target = batch.text, batch.label\r\n","        if phase == 'training':\r\n","            optimizer.zero_grad()\r\n","        output = model(text)\r\n","        loss = F.null_loss(output, target)\r\n","\r\n","        running_loss += F.null_loss(output, target, size_average=False).data[0]\r\n","        preds = output.data.max(dim=1, keepdim=True)[1]\r\n","        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\r\n","        if phase == \"target\":\r\n","            loss.backward()\r\n","            optimizer.step()\r\n","    \r\n","    loss = running_loss / len(data_loader.dataset)\r\n","    accuracy = 100. * running_correct / len(data_loader.dataset)\r\n","\r\n","    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\r\n","    return loss, accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6S1lNdvN269_"},"source":["model.embedding.weight.data = TEXT.vocab.vectors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LSn7GR4BDgLg"},"source":["train_losses, train_accuracy = [], []\r\n","val_losses, val_accuracy = [], []\r\n","\r\n","train_iter.repeat = False\r\n","test_iter.repeat = False\r\n","\r\n","\r\n","for epoch in range(1,10):\r\n","    epoch_loss, epoch_accuracy = fit(epoch, model, train_iter, phase=\"training\")\r\n","    val_epoch_loss, val_epoch_accuracy = fit(epoch, model, test_iter, phase='validation')\r\n","    train_losses.append(epoch_loss)\r\n","    train_accuracy.append(epoch_accuracy)\r\n","    val_losses.append(val_epoch_loss)\r\n","    val_accuracy.append(val_epoch_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aQlZRMS-EQjp"},"source":["## 사전 학습 워드 임베딩\r\n","\r\n","### 임베딩 다운로드"]},{"cell_type":"code","metadata":{"id":"3gZ0cNSaEPr8"},"source":["from torchtext.vocab import GloVe\r\n","TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\r\n","LABEL.build_vocab(train,)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sB4hIhjSE01C"},"source":["### 모델에 임베딩 로딩하기\r\n","vectors 변수는 사전 학습된 임베딩을 포함하고 형상이(vocab_size, 차원)인 텐서를 반환한다.\r\n","\r\n","임베딩 레이어의 가중치에 이 임베딩 가중치를 저장한다.\r\n","\r\n","아래 코드를 통해 embeddings 레이어의 가중치에 사전 학습된 임베딩의 가중치를 할당할 수 있다."]},{"cell_type":"code","metadata":{"id":"BAJh91QI1hEr"},"source":["model.embedding.weight.data = TEXT.vocab.vectors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHZzx6M_4anj"},"source":["class EmbNet(nn.Module):\r\n","    def __init__(self, emb_size, hidden_size1, hidden_size2 = 200):\r\n","        super().__init__()\r\n","        self.embedding = nn.Embedding(emb_size, hidden_size1)\r\n","        self.fc1 = nn.Linear(hidden_size2, 3)\r\n","\r\n","    def forward(self, x):\r\n","        embeds = self.embedding(x).view(x.size(0),-1)\r\n","        out = self.fc1(embeds)\r\n","        return F.log_softmax(out, dim = -1)\r\n","\r\n","model = EmbNet(len(TEXT.vocab.stoi),300,12000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKtBmRlr4eQk"},"source":["### 임베딩 레이어 가중치 고정\r\n","\r\n","임베딩 가중치를 변경하지 못도록 할 때\r\n","> requires_grad 속성을 False로 설정해 이 가중치에 대한 기울기 변화를 추적할 필요가 없음을 알린다.\r\n","\r\n","> 임베딩 레이어 파라미터가 옵티마이저로 전달되지 못하게 한다. 옵티마이저는 전달되는 모든 파라미터는 기울기를 관리하는 것으로 간주하기 때문...\r\n","\r\n","임베딩 레이어의 가중치를 고정하고, 옵티마이저가 해당 매개변수를 사용하지 못하도록 하는 것이 포인트"]},{"cell_type":"code","metadata":{"id":"EtHJn45h43KH"},"source":["from torch import optim\r\n","model.embedding.weight.requires_grad = False\r\n","optimizer = optim.SGD([ param for param in model.parameters() if param.requires_grad ++ True], lr=0.001)\r\n","# requires_grad가 True일 경우에만 매개변수를 옵티마이저에 넘김."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DHvuFQNu5PIc"},"source":["## RNN\r\n","\r\n","RNN은 레이블이 있는 순차 데이터에 이용하는 가장 강력한 모델.\r\n","\r\n","대표적으로 분류, SwiftKey 키보드 등과같은 문장 생성 또는 하나의 시퀀스를 다른 시컨스로 변환하는 언어 번역에 활용 가능\r\n","\r\n","RNN은 한 번에 텍스트 한 단어씩 보면서 사람과 비슷한 방식으로 작동한다. \r\n","\r\n","RNN은 독특한 레이어를 갖는 신경망 모델이다. \r\n","\r\n","기존에 신경망이 하나의 데이터를 한꺼번에 처리하는 방식이었다면, RNN은 하나의 데이터를 순차적이고 반복적으로 처리한다.\r\n","\r\n","RNN은 순서대로 데이터를 처리하기 때문에 길이가 다른 벡터를 사용할 수 있다. 또한 길이가 다른 출력을 생성할 수도 있다. \r\n","\r\n","참고 ( http://karpathy.github.io/2015/05/21.rnn-effectiveness)\r\n"]},{"cell_type":"markdown","metadata":{"id":"NRnmNTNT6Dnw"},"source":["### RNN 작동 방식 이해\r\n","\r\n","토르 영화 후기인 \"the action scenes were top notch ...\"를 입력한다면 첫 단어인 the를 가장 먼저 입력한다. RNN모델은 **상태 벡터**와 **출력 벡터**를 만든다.\r\n","**상태 벡터**는 영화 관람 후기의 다음 단어를 처리할 때 모델에 전달되고, 상태 벡터와 새로운 데이터가 결합해 새로운 상태 벡터와 출력 벡터가 만들어진다. \r\n","\r\n","코드로 이해를 돕는다면 아래와 같다.\r\n","\r\n","    rnn = RNN(input_size, hidden_size, output_size)\r\n","    for i in range(len(thor_review)):\r\n","    output, hidden = rnn(thor_review[i], hidden)\r\n","\r\n","hidden이 상태벡터를 나타내는 것이다. "]},{"cell_type":"code","metadata":{"id":"8Oye4WBN6rcJ"},"source":["import torch.nn as nn\r\n","from torch.autograd import Variable\r\n","\r\n","class RNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size, output_size):\r\n","    ## __init__에서 2개의 선형 레이어를 초기화한다. 출력과 상태 벡터 또는 히든 벡터를 계산한다.\r\n","        super(RNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) # 이게 아마 상태 계산 선형 레이어\r\n","        self.i2o = nn.Linear(input_size + hidden_size, output_size) # 이게 아마 출력 계산 선형 레이어\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        combined = torch.cat((input, hidden), 1)\r\n","        # 입력벡터와 히든 벡터를 cat함수로 결합해 출력 벡터와 숨겨진 상태를 생성하는 두 선형 레이어를 통과시킨다. \r\n","        # 여기서 cat 함수는 텐서를 결합하며 두번째 인자 dim은 결합 방향을 설정.\r\n","        hidden = self.i2h(combined)\r\n","        output = self.i2o(combined)\r\n","        output = self.softmax(output) #출력 레이어는 log_softmax 함수를 적용\r\n","        return output, hidden\r\n","    \r\n","    def initHidden(self):\r\n","    # RNN을 처음 호출 할 경우 상태 벡터를 만드는 기능.\r\n","        return Variable(torch.zeros(1, self.hidden_size))\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1goqXorE8F_X"},"source":["## LSTM \r\n","\r\n","RNN은 언어 번역, 텍스트 분류 등을 하는 알고리즘이다. 그러나 실무에서는 보통 RNN을 그대로 사용하진 않음.(기울기 소멸, 기울기 폭발 등의 문제가 존재)\r\n","\r\n","그래서 RNN 변형 알고리즘인 LSTM 이나 GRU를 주로 사용한다.\r\n","\r\n","\r\n","### 장기 종속성\r\n","RNN은 이롡거으로 다음에 발생할 일에 대한 컨텍스트를 구축하기 위해 과거 데이터에서 필요한 모든 종속성을 학습해야 한다. 문장이 길어지면 컨텍스트 기억이 힘들다. 그래서 LSTM 내부에 다른 신경망을 추가해 이 문제를 해결한다. \r\n","\r\n","\r\n","### LSTM\r\n","LSTM은 장기 의존성을 학습할 수 있다. LSTM에서 가장 중요한 것은 모든 반복에 걸쳐 전달되는 **셀 상태**이다.\r\n","\r\n","가장 먼저 어떤 정보가 셀 상태에서 제거될지를 결정한다. 이 네트워크를 망각 게이트라고 한다. 이 네트워크는 활성 함수로 시그모이드를 사용한다. 셀 상태의 모든 요소는 0과 1 사이 값으로 출력된다.\r\n","\r\n","다음 단계는 셀 상태에 어떤 정보를 추가할 지 결정한다. 여기서 입력게이트라 불리는 시그모이드 레이어는 업데이트 될 값을 결정한다. 셀 상태에 추가할 새 값을 만드는 tanh 레이어가 있다. \r\n","\r\n","다음 단계에서는 입력게이트와 tanh이 만든 값을 결합한다. 망각 게이트와 Ct의 같은 위치 요소끼리의 곱과 입력게이트와 tanh로 활성화된 Ct의 같은 요소끼리의 곱의 합으로 셀 상태를 업데이트 할 수 있다. \r\n","\r\n","마지막으로 출력을 결정한다. 출력은 필터링된 버전의 셀 상태이다. \r\n","\r\n","LSTM 이론 정보 참고\r\n","(http://colah.github.io/posts/2015-08-Understanding-LSTMs)\r\n","(http://brohrer.github.io/how_rnns_lstm_work.html)"]},{"cell_type":"markdown","metadata":{"id":"h7ciIjN5Jrq4"},"source":["### 네트워크로 감성 분류기 만들기 \r\n","1. 데이터 준비\r\n","2. 배치 처리기 만들기\r\n","3. 네트워크 생성\r\n","4. 모델 교육\r\n","\r\n","**데이터 준비하기**\r\n"]},{"cell_type":"code","metadata":{"id":"uG3fkLNMKAXq"},"source":["from torchtext import data, datasets\r\n","\r\n","TEXT = data.Field(lower = True, fix_length=200, batch_first=False)\r\n","LABEL = data.Field(sequential=False,)\r\n","\r\n","train, test = datasets.IMDB.splits(TEXT, LABEL)\r\n","\r\n","TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\r\n","LABEL.build_vocab(train,)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MeZEFX5SK5sN"},"source":["**배치 처리기 생성하기**\r\n","\r\n","배치 처리기 생성할 때 torchtext의BucketIterator를 사용한다."]},{"cell_type":"code","metadata":{"id":"ZL4wW93qLEZy"},"source":["train_iter, test_iter = data.BucketIterator.splits((train,test), batch_size=32)\r\n","train_iter.repeat = False\r\n","test_iter.repeat =  False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tJtX9VZSLZlV"},"source":["**네트워크 생성하기**\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"NrYsXqGOLQEU"},"source":["from torch import nn as nn\r\n","from torch.nn import functional as F\r\n","\r\n","class IMDBRnn(nn.Module):\r\n","\r\n","    def __init__(self, vocab, hidden_size, n_cat, bs=1, nl=2):\r\n","    \r\n","        super().__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.bs = bs\r\n","        self.nl = nl\r\n","        self.e = nn.Embedding(n_vocab, hidden_size) # 생성자인 __init__메서드에서 어휘의 크기와 hidden_size 크기의 임베딩 레이어를 만든다.\r\n","        self.rnn = nn.LSTM(hidden_size, hidden_sizem, nl) \r\n","        self.fc2 = nn.Linear(hidden_size, n_cat)\r\n","        self.softmax = nn.LogSoftmax(dim=-1) #LogSoftmax는 선형 레이어의 결과를 확률로 변환한다.\r\n","\r\n","    def forward(self, inp):\r\n","        bs = inp.size()[1]\r\n","        if bs != self.bs: # bs는 batch_size\r\n","            self.bs = bs\r\n","        e_out = self.e(inp) #임베디드 레이어 통과\r\n","        h0 = c0 = Variable(e_out.data.new(*(self.nl, self.bs, self.hidden_size)).zero())\r\n","        rnn_o,_ = self.rnn(e_out, (h0, c0))\r\n","        rnn_o = rnn_o[-1]\r\n","        fc = F.droput(self.fc2(rnn_o), p=0.8)\r\n","        return self.softmax(fc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HN8GSmY_ND5y"},"source":["forward 메서드는 크기가 [200,32]의 입력 데이터를 임베디드 레이어에 통과시킨다. \r\n","배치의 각 토큰은 임베딩으로 대체되고, 크기는 [200, 32, 100]으로 바뀐다. 여기서 100은 임베딩 차원이다. \r\n","\r\n","LSTM 렝이어는 2개의 hidden 변수와 임베디드 레이어의 출력을 입력받는다. \r\n","여기서 두 hidden 변수는 임베딩 출력과 동일한 유형이어야하며, 크기는 [num_layers, batch_size, hidden_dim] 형상의 출력을 생성한다. LSTM은 시퀀스의 데이터를 처리하고 [Sequence_length, batch_size, hidden_size] 형상의 출력을 생성한다. 여기서 각 시퀀스 인덱스는 해당 시퀀스의 출력을 나타낸다. 이 때, 마지막 시퀀스의 출력을 가져온다. 이 시퀀스의 형상은 [batch_size, hideen_dim]이고, 이 출력을 선형 레이어에 전달해 출력 범주에 대응시킨다. 모델이 과대적합되는 경향이 있으므로 드롭아웃 레이어를 추가한다. 드롭아웃 확률은 모델을 학습시키는 과정에서 조정될 수 있다. "]},{"cell_type":"markdown","metadata":{"id":"KHe3KqcwPg21"},"source":["**모델 학습시키기**"]},{"cell_type":"code","metadata":{"id":"_smiXQOMPScG"},"source":["model = IMDBRnn(n_vocab, n_hidden, 3, bs=32)\r\n","\r\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n","\r\n","def fit(epoch, model, data_loader, phase=\"training\", voatile=False):\r\n","    if phase == 'training':\r\n","        model.train()\r\n","    if phase == 'validation':\r\n","        model.eval()\r\n","        volatile=True\r\n","    \r\n","    running_loss = 0.0\r\n","    running_correct = 0\r\n","    for batch_idx, batch in enumerate(data_loader):\r\n","        text, target = batch.text, batch.label\r\n","        if phase == 'training':\r\n","            optimizer.zero_grad()\r\n","        output = model(text)\r\n","        loss = F.nll_loss(ouput, target)\r\n","\r\n","        running_loss += F.nll_loss(output, target, size_average=False).data[0]\r\n","        preds = output.data.max(dim=1, keepdim=True)[1]\r\n","        running_correct += preds.eq(target.data.view_as(preds)).sum()\r\n","        if phase == 'training':\r\n","            loss.backward()\r\n","            optimizer.step()\r\n","    \r\n","    loss = running_loss / len(data_loader.dataset)\r\n","    accuracy = 100. * running_correct / len(data_loader.dataset)\r\n","\r\n","    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct} / {len(data_loader.dataset)}{accuracy:{10}.{4}}')\r\n","    return loss, accuracy\r\n","\r\n","train_losses, train_accuracy = [], []\r\n","val_losses, val_accuracy = [], []\r\n","\r\n","for epoch in range(1,5):\r\n","    epoch_loss, epoch_accuracy = fit(epoch, model, train_iter, phase='training')\r\n","    val_epoch_loss, val_epoch_accuracy = fit(epoch, model, test_iter, phase='validation')\r\n","    train_losses.append(epoch_loss)\r\n","    train_accuracy.append(epoch_accuracy)\r\n","    val_losses.append(val_epoch_loss)\r\n","    val_accuracy.append(val_epoch_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hZgimtJP8Hn"},"source":["## 시퀀스데이터와 CNN\r\n","\r\n","CNN은 이미지의 피처를 학습하는 컴퓨터 비전에서도 쓰인다. 이미지의 경우 2차원을 컨볼루션하며 동작한다. 같은 방식으로 시간도 컨볼루션 피처에 넣을 수 있다. CNN을 통해 텍스트 분류를 구축해보자!\r\n","\r\n","### 시퀀스 데이터를 위한 1차원 컨볼루션 이해\r\n","\r\n","**네트워크 만들기**\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"j-EF_ivPO79l"},"source":["class IMDBCnn(nn.Module):\r\n","    def __init__(self, vocab, hidden_size, n_cat, bs=1, kernel_size=3, max_len=200):\r\n","        super().__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.bs = bs\r\n","        self.e = nn.Embedding(n_vocab, hidden_size)\r\n","        #LSTM레이어 대신 Conv1d 레이어와 AdqptiveAvgPool1d 레이어를 사용했다.\r\n","        self.cnn = nn.Conv1d(max_len, hidden_size, kernel_size) # 컨볼루션 레이어의 입력데이터는 시퀀스 길이, 출력 크기는 hidden_size, 그리고 커널 크기는 3으로 만들어졌다.\r\n","        self.avg = nn.AdaptiveAvgPool1d(10) # 컨볼루션 레이어의 출력 형상이 변경되면 선형 레이어의 차원을 변경해야하기 때문에 여러 크기의 입력을 받아 고정된 길이의 출력을 만드는 AdaptiveAvg 레이어를 사용한다. \r\n","        self.fc = nn.Linear(1000, n_cat)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, inp):\r\n","        bs = inp.size()[0]\r\n","        if bs != self.bs:\r\n","            self.bs = bs\r\n","        e_out = self.e(inp)\r\n","        cnn_o = self.cnn(e_out)\r\n","        cnn_avg = self.avg(cnn_o)\r\n","        cnn_avg = cnn_avg.view(self.bs -1)\r\n","        fc = F.dropout(self.fc(cnn_avg), p=0.5)\r\n","        return self.softmax(fc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dnmy7U_5bkcq"},"source":["**모델 학습시키기**\r\n","\r\n","    train_losses, train_accuracy = [], []\r\n","    val_losses, val_accuracy = [], []\r\n","\r\n","    train_iter.repeat = False\r\n","    test_iter.repeat = False\r\n","\r\n","\r\n","    for epoch in range(1,10):\r\n","        epoch_loss, epoch_accuracy = fit(epoch, model, train_iter, phase=\"training\")\r\n","        val_epoch_loss, val_epoch_accuracy = fit(epoch, model, test_iter, phase='validation')\r\n","        train_losses.append(epoch_loss)\r\n","        train_accuracy.append(epoch_accuracy)\r\n","        val_losses.append(val_epoch_loss)\r\n","        val_accuracy.append(val_epoch_accuracy)"]},{"cell_type":"code","metadata":{"id":"j5F9PAhqbm7i"},"source":[""],"execution_count":null,"outputs":[]}]}