{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. 회귀.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPYRc+KiuIvjvQQs1y5rmz9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"uu-GqOrp6vP_"},"source":["#4.1 선형회귀\r\n","\r\n","**선형회귀**는 데이터의 경향성을 가장 잘 설명하는 하나의 직선을 예측하는 것\r\n"]},{"cell_type":"code","metadata":{"id":"CBgW698F6-6w"},"source":["#2018년 우리나라의 지역별 인구증가율과 고령인구비율 데이터를 시각화\r\n","import tensorflow as tf\r\n","import matplotlib.pyplot as plt\r\n","\r\n","population_inc = [0.3, -0.78, 1.26, 0.03, 1.11, 15.17, 0.24, -0.24, -0.47, -0.77, -0.37,-0.85, -0.41, -0.27, 0.02, -0.76, 2.66]\r\n","population_old = [12.27, 14.44, 11.87, 18.75, 17.52, 9.29, 16.37, 19.78, 19.51, 12.65, 14.74, 10.72, 21.94, 12.83, 15.51, 17.14, 14.42]\r\n","\r\n","\r\n","plt.plot(population_inc, population_old, 'bo')\r\n","plt.xlabel('Population growth Rate')\r\n","plt.ylabel('Elderly Population Rate')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J8f6gVUG7SDD"},"source":["여기서 오른쪽 아래에 치우친 하나의 점을 '극단치'라고 부른다. 일반적인 경향에서 벗어나는 사례를 칭한다. 데이터의 일반적인 경향을 알아보기 위해서 극단치는 제거하도록 한다. "]},{"cell_type":"code","metadata":{"id":"aDrgtmXo7dOY"},"source":["import tensorflow as tf\r\n","import matplotlib.pyplot as plt\r\n","\r\n","population_inc = [0.3, -0.78, 1.26, 0.03, 1.11, 15.17, 0.24, -0.24, -0.47, -0.77, -0.37,-0.85, -0.41, -0.27, 0.02, -0.76, 2.66]\r\n","population_old = [12.27, 14.44, 11.87, 18.75, 17.52, 9.29, 16.37, 19.78, 19.51, 12.65, 14.74, 10.72, 21.94, 12.83, 15.51, 17.14, 14.42]\r\n","\r\n","population_inc = population_inc[:5] + population_inc[6:]\r\n","population_old = population_old[:5] + population_old[6:]\r\n","plt.plot(population_inc, population_old, 'bo')\r\n","plt.xlabel('Population growth Rate')\r\n","plt.ylabel('Elderly Population Rate')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDBRvpNh7fWH"},"source":["이제 일반적인 데이터를 토대로 선형 회귀를 해본다.\r\n","\r\n","데이터의 경향성을 가장 잘 설명하는 하나의 직선과 각 데이터의 차이를 **잔차**라고 한다.\r\n","\r\n","이 잔차의 제곱을 최소화하는 알고리즘을 **최소제곱법**이라고 한다.\r\n","\r\n","이를 직접 계산해서 해보자면"]},{"cell_type":"code","metadata":{"id":"x0YXeKvm7wJa"},"source":["import numpy as np\r\n","\r\n","X = population_inc\r\n","Y = population_old\r\n","\r\n","#X, Y의 평균을 구한다.\r\n","x_bar = sum(X) / len(X)\r\n","y_bar = sum(Y) / len(Y)\r\n","\r\n","#최소제곱법으로 a,b를 구한다.\r\n","#두 개 이상의 리스트를 하나로 묶는 list(zip(list_1, list_2))를 사용한다.\r\n","a = sum([(y - y_bar) * (x - x_bar) for y,x in list(zip(Y,X))])\r\n","a /= sum([(x - x_bar) ** 2 for x in X])\r\n","b  = y_bar - a * x_bar\r\n","print('a:', a, 'b:', b)\r\n","\r\n","#그래프를 그리기 위해 회귀선의 x, y 데이터를 구한다.\r\n","line_x = np.arange(min(X), max(X), 0.01) #numpy의 arange를 사용하는 이유는 range는 정수로만 구성되기 때문에 실숫값을 사용하기 위해서이다.\r\n","line_y = a * line_x + b\r\n","\r\n","#붉은색 실선으로 회귀선을 그린다\r\n","plt.plot(line_x, line_y, 'r-')\r\n","\r\n","plt.plot(X, Y, 'bo')\r\n","plt.xlabel('Population Growth Rate')\r\n","plt.ylabel('Elderly Population Rate')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FpuDKRMS8g9l"},"source":["위와 같이 복잡한 수식과 최소제곱법을 쓰지 않고도 텐서플로를 이용하면 회귀선을 그릴 수 있다."]},{"cell_type":"code","metadata":{"id":"lbNLddMe8mdQ"},"source":["import tensorflow as tf\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import random\r\n","\r\n","# a,b를 랜덤한 값으로 초기화\r\n","a = tf.Variable(random.random())\r\n","b = tf.Variable(random.random())\r\n","\r\n","# 잔차의 제곱의 평균을 반환하는 함수\r\n","def compute_loss():\r\n","    y_pred = a * X + b\r\n","    # 기대 출력인 Y에서 실제 출력인 pred_y를 빼는데, 이를 잔차라고 부른다.\r\n","    loss = tf.reduce_mean((Y - y_pred) ** 2) #잔차의 제곱 평균을 loss로 반환한다.\r\n","    return loss\r\n","\r\n","optimizer = tf.optimizers.Adam(lr=0.07)\r\n","for i in range(1000):\r\n","    # 잔차의 제곱의 평균을 최소화 한다(minimize)\r\n","    optimizer.minimize(compute_loss, var_list = [a,b])\r\n","\r\n","    if i% 100 == 99:\r\n","        print( i, 'a:', a.numpy(), 'b:', b.numpy(), 'loss:', compute_loss().numpy())\r\n","\r\n","line_x = np.arange(min(X), max(X), 0.01)\r\n","line_y = a * line_x + b\r\n","\r\n","plt.plot(line_x, line_y, 'r-')\r\n","plt.plot(X, Y, 'bo')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uVpGjuBc86EL"},"source":["# 4.2 다항회귀\r\n","\r\n","**비선형회귀**는 선형 회귀로 표현할 수 없는 데이터의 경향성을 설명하기 위한 회귀\r\n","\r\n","직선 ax + b가 아니라 ax^2 + bx + c와 같은 함수로 회귀선을 써보는 것이다.\r\n","\r\n","위의 선형회귀 선을 조금 고쳐서 사용한다."]},{"cell_type":"code","metadata":{"id":"9Zj9uiEF912n"},"source":["#a,b,c를 랜덤한 값으로 초기화한다.\r\n","a = tf.Variable(random.random())\r\n","b = tf.Variable(random.random())\r\n","c = tf.Variable(random.random())\r\n","\r\n","# 잔차의 제곱의 평균을 반환하는 함수\r\n","def compute_loss():\r\n","    y_pred = a * X * X + b * X + c\r\n","    loss = tf.reduce_mean((Y - y_pred) ** 2)\r\n","    return loss\r\n","\r\n","optimizer = tf.optimizers.Adam(lr=0.07)\r\n","for i in range(1000):\r\n","    # 잔차의 제곱의 평균을 최소화 한다(minimize)\r\n","    optimizer.minimize(compute_loss, var_list = [a,b,c])\r\n","\r\n","    if i% 100 == 99:\r\n","        print( i, 'a:', a.numpy(), 'b:', b.numpy(), 'loss:', compute_loss().numpy())\r\n","\r\n","line_x = np.arange(min(X), max(X), 0.01)\r\n","line_y = a * line_x * line_x + b * line_x + c\r\n","\r\n","plt.plot(line_x, line_y, 'r-')\r\n","plt.plot(X, Y, 'bo')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NRCVWb_-ORM"},"source":["ax^3 + bx^2 + cx + d로 바꾸어서 더 복잡한 다항회귀도 가능하다."]},{"cell_type":"code","metadata":{"id":"XP7WU3CY-Old"},"source":["# 3차 다항회귀\r\n","\r\n","#a,b,c를 랜덤한 값으로 초기화한다.\r\n","a = tf.Variable(random.random())\r\n","b = tf.Variable(random.random())\r\n","c = tf.Variable(random.random())\r\n","d = tf.Variable(random.random())\r\n","\r\n","\r\n","# 잔차의 제곱의 평균을 반환하는 함수\r\n","def compute_loss():\r\n","    y_pred = a * X * X * X + b * X * X + c * X + d\r\n","    loss = tf.reduce_mean((Y - y_pred) ** 2)\r\n","    return loss\r\n","\r\n","optimizer = tf.optimizers.Adam(lr=0.07)\r\n","for i in range(1000):\r\n","    # 잔차의 제곱의 평균을 최소화 한다(minimize)\r\n","    optimizer.minimize(compute_loss, var_list = [a,b,c,d])\r\n","\r\n","    if i% 100 == 99:\r\n","        print( i, 'a:', a.numpy(), 'b:', b.numpy(), 'c:', c.numpy(), 'd:', d.numpy(), 'loss:', compute_loss().numpy())\r\n","\r\n","line_x = np.arange(min(X), max(X), 0.01)\r\n","line_y = a * line_x * line_x * line_x + b * line_x * line_x + c * line_x + d\r\n","\r\n","plt.plot(line_x, line_y, 'r-')\r\n","plt.plot(X, Y, 'bo')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pJWFZGQ8_COP"},"source":["# 4.2 딥러닝 네트워크를 이용한 회귀"]},{"cell_type":"code","metadata":{"id":"Iiq6HjBx_HGO"},"source":["import tensorflow as tf\r\n","import numpy as np\r\n","\r\n","\r\n","X = [0.3, -0.78, 1.26, 0.03, 1.11, 0.24, -0.24, -0.47, -0.77, -0.37,-0.85, -0.41, -0.27, 0.02, -0.76, 2.66]\r\n","Y = [12.27, 14.44, 11.87, 18.75, 17.52, 16.37, 19.78, 19.51, 12.65, 14.74, 10.72, 21.94, 12.83, 15.51, 17.14, 14.42]\r\n","\r\n","model = tf.keras.Sequential([\r\n","                             tf.keras.layers.Dense(units=6, activation='tanh', input_shape=(1,)), #첫번째 활성함수로 tanh사용.\r\n","                                                                                                  #뉴런은 6개를 할당. 뉴런은 많을수록 딥러닝의 네트워크 표현력이 좋아지는 건 맞지만 과적합이 일어날 수 있으니 주의\r\n","                             tf.keras.layers.Dense(units=1) # X값 하나에 Y값 하나를 출력해야 하므로 뉴런은 1개 할당\r\n","])\r\n","\r\n","model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1), loss='mse')\r\n","\r\n","model.summary()\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4t-hRkgK_5E4"},"source":["model.fit(X, Y, epochs=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E_jpqMpN_92F"},"source":["X를 입력하면 Y가 정답이 되도록 10회 학습시킨다.\r\n","\r\n","손실에 변화가 없으면 학습이 거의 다 된것을 의미한다."]},{"cell_type":"code","metadata":{"id":"GJJTXyg-AF6_"},"source":["model.predict(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TTGMaIvtAMX-"},"source":["line_x = np.arange(min(X), max(X), 0.01)\r\n","line_y = model.predict(line_x)\r\n","\r\n","plt.plot(line_x, line_y, 'r-')\r\n","plt.plot(X, Y, 'bo')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-Q2n5E9AY-a"},"source":["#4.4 보스턴 주택 가격 데이터 센트\r\n","\r\n","보스턴 주택 가격 데이터 세트를 이용한 주택 가격예측 네트워크를 만든다.\r\n","\r\n","훈련데이터는 학습 과정에 사용되는 데이터이고, 테스트 데이터는 학습 결과를 평가하기 위한 데이터이다.\r\n","\r\n","학습할 때는 훈련 데이터만 사용하고, 테스트 데이터는 볼 수 없다.\r\n","\r\n","훈련 데이터로 학습할 때 일부 데이터를 떼어내 검증데이터로 만들 수 있다.\r\n","\r\n","이는 학습이 잘 되고 있는지 검증하는 용도로 쓰이며, 성적이 잘 나오지 않는다면 학습을 중단할 수 있다.\r\n","\r\n","딥러닝 네트워크 가중치에 영향을 주는 데이터는 훈련데이터 뿐이다."]},{"cell_type":"code","metadata":{"id":"IM4BEeQ2Ahb3"},"source":["from tensorflow.keras.datasets import boston_housing\r\n","(train_X, train_Y), (test_X, test_Y) = boston_housing.load_data()\r\n","\r\n","print(len(train_X), len(test_X))\r\n","print(train_X[0])\r\n","print(train_Y[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B1EG4o1rBOm8"},"source":["딥러닝에서는 데이터를 전처리해서 **정규화**해야 학습 효율이 좋다.\r\n","\r\n","데이터를 정규화하려면 각 데이터에서 평균값을 뺀 다음 표준편차로 나눈다.\r\n","\r\n","이는 데이터의 분포를 정규분포로 옮기는 역할을 한다."]},{"cell_type":"code","metadata":{"id":"LF7m4ckNBbcK"},"source":["x_mean = train_X.mean()\r\n","x_std = train_X.std()\r\n","#정규화\r\n","train_X -= x_mean\r\n","train_X /= x_std\r\n","test_X -= x_mean\r\n","test_X /= x_std\r\n","\r\n","y_mean = train_Y.mean()\r\n","y_std = train_Y.std()\r\n","#정규화\r\n","train_Y -= y_mean\r\n","train_Y /= y_std\r\n","test_Y -= y_mean\r\n","test_Y /= y_std\r\n","\r\n","print(len(train_X))\r\n","print(train_Y[0])\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-QNR35ZBlp0"},"source":["import tensorflow as tf\r\n","model = tf.keras.Sequential([\r\n","                             tf.keras.layers.Dense(units=52, activation='relu', input_shape=(13,)),#위에서보다 레이어에 들어가는 뉴런의 수가 증가함.\r\n","                             tf.keras.layers.Dense(units=39, activation='relu'),                   #레이어의 수와 은닉층의 뉴런 수를 늘리면 모델의 표현력이 좋아진다.  \r\n","                             tf.keras.layers.Dense(units=26, activation='relu'),\r\n","                             tf.keras.layers.Dense(units=1)\r\n","])\r\n","#ReLU의 경우 지금처럼 여러개의 레이어를 겹쳐서 사용할 때 시그모이드 함수나 tanh보다 좋은 결과를 얻을 수 있다.\r\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07), loss='mse')\r\n","\r\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4H3C5ZaBm4R"},"source":["#model.fit함수로 회귀모델 학습\r\n","#epochs = 학습 횟수, batch_size = 한번에 학습시키는 데이터의 수, validation_split = 훈련데이터 중 검증데이터로 사용하는 비율\r\n","history = model.fit(train_X, train_Y, epochs=25, batch_size = 32, validation_split=0.25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2iVllwy4CQps"},"source":["import matplotlib.pyplot as plt\r\n","\r\n","plt.plot(history.history['loss'], 'b-', label='loss')\r\n","plt.plot(history.history['val_loss'], 'r--', label='val_loss')\r\n","plt.legend()\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lEpXlGafCVAm"},"source":["파란색이 데이터의 손실, 붉은 색이 검증 데이터의 손실이다. \r\n","\r\n","데이터의 손실은 감소하지만 검증 데이터의 손실은 줄지 않고 유지하거나 증가한다. "]},{"cell_type":"code","metadata":{"id":"FhH1t3IiCeoc"},"source":["model.evaluate(test_X, test_Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXr_ficUCtpb"},"source":["pred_Y = model.predict(test_X)\r\n","\r\n","plt.figure(figsize=(5,5))\r\n","plt.plot(test_Y, pred_Y, 'b.')\r\n","plt.axis([min(test_Y), max(test_Y), min(test_Y), max(test_Y)])\r\n","\r\n","#y=x에 해당하는 대각선\r\n","plt.plot([min(test_Y), max(test_Y)], [min(test_Y), max(test_Y)], ls=\"--\", c=\".3\")\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BS_J595mC0Gp"},"source":["실제 주택 가격 (test_Y)에 대해 예측 주택 가격(pred_Y)이 일정 값에 머물러 있는 것 같다. 이상적이라면 그래프를 가로지르는 대각선에 모든 점이 위치해야한다.\r\n","\r\n","검증 데이터에 대한 성적이 좋아지면 테스트 데이터에 대한 성적도 좋아질 것이다. 검증 데이터에 대한 성적이 좋아지려면 val_loss가 높아지지 않도록, 즉 네트워크가 훈련 데이터에 과적합 되지 않도록 학습 도중에 끼어들어 학습을 멈춰야한다."]},{"cell_type":"code","metadata":{"id":"VnoH4zn0DRje"},"source":["model = tf.keras.Sequential([\r\n","                             tf.keras.layers.Dense(units=52, activation='relu', input_shape=(13,)),\r\n","                             tf.keras.layers.Dense(units=39, activation='relu'),\r\n","                             tf.keras.layers.Dense(units=26, activation='relu'),\r\n","                             tf.keras.layers.Dense(units=1)\r\n","])\r\n","\r\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07), loss='mse')\r\n","\r\n","history = model.fit(train_X, train_Y, epochs=25, batch_size=32, validation_split=0.25, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss')])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1JBIttHXDb7u"},"source":["위 함수에 들어간 tf.keras.callbacks.EarlyStopping은 patience는 몇번의 에포크를 기준으로 삼을 것인지, monitor는 어떤 값을 지켜볼 것인디에 대한 인수\r\n","\r\n","val_loss가 3회의 에포크를 수행하는 동안 최고 기록을 갱신하지 못하면 학습을 멈추게 한다."]},{"cell_type":"code","metadata":{"id":"bEaDPBp_D4wK"},"source":["import matplotlib.pyplot as plt\r\n","plt.plot(history.history['loss'], 'b-', label='loss')\r\n","plt.plot(history.history['val_loss'], 'r--', label='val_loss')\r\n","plt.legend()\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"miQC58l5D_-6"},"source":["model.evaluate(test_X, test_Y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cTx0LybJEE0_"},"source":["0.6668정도로 낮은 수치가 나왔다.\r\n","\r\n","실제 주택 가격과 예측 주택 가격을 1:1로 시각화 해본다면"]},{"cell_type":"code","metadata":{"id":"EemqWEYCEMzn"},"source":["pred_Y = model.predict(test_X)\r\n","\r\n","plt.figure(figsize=(5,5))\r\n","plt.plot(test_Y, pred_Y, 'b.')\r\n","plt.axis([min(test_Y), max(test_Y), min(test_Y), max(test_Y)])\r\n","\r\n","plt.plot([min(test_Y), max(test_Y)],[min(test_Y), max(test_Y)], ls=\"--\", c=\".3\")\r\n","plt.show()"],"execution_count":null,"outputs":[]}]}