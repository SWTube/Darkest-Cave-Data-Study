{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DNN 의 수많은 어플리케이션\n",
    " - 페이스북의 DeepFace\n",
    " - 바이두의 DeepSpeech\n",
    " - 구글번역\n",
    " - 신약 개발, 독성 예측\n",
    " - 피부암 진단 어플리케이션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단일층 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaline\n",
    "- stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- feedforward\n",
    "- multilayer perceptron, MLP\n",
    "- forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watermark in c:\\users\\a\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\a\\anaconda3\\lib\\site-packages (from watermark) (7.19.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.17.1)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.4.4)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (5.0.5)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (3.0.8)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (50.3.1.post20201107)\n",
      "Requirement already satisfied: pygments in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (2.7.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\a\\anaconda3\\lib\\site-packages (from ipython->watermark) (4.4.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\a\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython->watermark) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\a\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->watermark) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\a\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if (sys.version_info > (3, 0)):\n",
    "    writemode = 'wb'\n",
    "else:\n",
    "    writemode = 'w'\n",
    "\n",
    "zipped_mnist = [f for f in os.listdir('./') if f.endswith('ubyte.gz')]\n",
    "for z in zipped_mnist:\n",
    "    with gzip.GzipFile(z, mode='rb') as decompressed, open(z[:-3], writemode) as outfile:\n",
    "        outfile.write(decompressed.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"path  에서 MNIST 불러오기\"\"\"\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "        \n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', lbpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images/255.) - .5) * 2\n",
    "        \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "read of closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-fd8c81f6459e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'행 : %d, 열: %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-7990792f0b04>\u001b[0m in \u001b[0;36mload_mnist\u001b[1;34m(path, kind)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mmagic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>IIII'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: read of closed file"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('', kind='train')\n",
    "print('행 : %d, 열: %d' % (X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\"피드포워드 신경망 / 다층 퍼셉트론 분류기\n",
    "\n",
    "    매개변수\n",
    "\n",
    "    ------------\n",
    "    n_hidden : int (기본값: 30)\n",
    "        은닉 유닛 개수\n",
    "    l2 : float (기본값: 0.)\n",
    "        L2 규제의 람다 값\n",
    "        l2=0이면 규제 없음. (기본값)\n",
    "    epochs : int (기본값: 100)\n",
    "        훈련 세트를 반복할 횟수\n",
    "    eta : float (기본값: 0.001)\n",
    "        학습률\n",
    "    shuffle : bool (기본값: True)\n",
    "        에포크마다 훈련 세트를 섞을지 여부\n",
    "        True이면 데이터를 섞어 순서를 바꿉니다\n",
    "    minibatch_size : int (기본값: 1)\n",
    "        미니 배치의 훈련 샘플 개수\n",
    "    seed : int (기본값: None)\n",
    "        가중치와 데이터 셔플링을 위한 난수 초깃값\n",
    "\n",
    "    속성\n",
    "    -----------\n",
    "    eval_ : dict\n",
    "      훈련 에포크마다 비용, 훈련 정확도, 검증 정확도를 수집하기 위한 딕셔너리\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 l2=0., epochs=100, eta=0.001,\n",
    "                 shuffle=True, minibatch_size=1, seed=None):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "\n",
    "    def _onehot(self, y, n_classes):\n",
    "        \"\"\"레이블을 원-핫 방식으로 인코딩합니다\n",
    "\n",
    "        매개변수\n",
    "        ------------\n",
    "        y : 배열, 크기 = [n_samples]\n",
    "            타깃 값.\n",
    "\n",
    "        반환값\n",
    "        -----------\n",
    "        onehot : 배열, 크기 = (n_samples, n_labels)\n",
    "\n",
    "        \"\"\"\n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.\n",
    "        return onehot.T\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"로지스틱 함수(시그모이드)를 계산합니다\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"정방향 계산을 수행합니다\"\"\"\n",
    "\n",
    "        # 단계 1: 은닉층의 최종 입력\n",
    "        # [n_samples, n_features] dot [n_features, n_hidden]\n",
    "        # -> [n_samples, n_hidden]\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "\n",
    "        # 단계 2: 은닉층의 활성화 출력\n",
    "        a_h = self._sigmoid(z_h)\n",
    "\n",
    "        # 단계 3: 출력층의 최종 입력\n",
    "        # [n_samples, n_hidden] dot [n_hidden, n_classlabels]\n",
    "        # -> [n_samples, n_classlabels]\n",
    "\n",
    "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
    "\n",
    "        # 단계 4: 출력층의 활성화 출력\n",
    "        a_out = self._sigmoid(z_out)\n",
    "\n",
    "        return z_h, a_h, z_out, a_out\n",
    "\n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"비용 함수를 계산합니다\n",
    "\n",
    "        매개변수\n",
    "        ----------\n",
    "        y_enc : 배열, 크기 = (n_samples, n_labels)\n",
    "            원-핫 인코딩된 클래스 레이블\n",
    "        output : 배열, 크기 = [n_samples, n_output_units]\n",
    "            출력층의 활성화 출력 (정방향 계산)\n",
    "\n",
    "        반환값\n",
    "        ---------\n",
    "        cost : float\n",
    "            규제가 포함된 비용\n",
    "\n",
    "        \"\"\"\n",
    "        L2_term = (self.l2 *\n",
    "                   (np.sum(self.w_h ** 2.) +\n",
    "                    np.sum(self.w_out ** 2.)))\n",
    "\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1. - y_enc) * np.log(1. - output)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        \n",
    "        # 다른 데이터셋에서는 극단적인 (0 또는 1에 가까운) 활성화 값이 나올 수 있습니다.\n",
    "        # 파이썬과 넘파이의 수치 연산이 불안정하기 때문에 \"ZeroDivisionError\"가 발생할 수 있습니다.\n",
    "        # 즉, log(0)을 평가하는 경우입니다.\n",
    "        # 이 문제를 해결하기 위해 로그 함수에 전달되는 활성화 값에 작은 상수를 더합니다.\n",
    "        #\n",
    "        # 예를 들어:\n",
    "        #\n",
    "        # term1 = -y_enc * (np.log(output + 1e-5))\n",
    "        # term2 = (1. - y_enc) * np.log(1. - output + 1e-5)\n",
    "        \n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"클래스 레이블을 예측합니다\n",
    "\n",
    "        매개변수\n",
    "        -----------\n",
    "        X : 배열, 크기 = [n_samples, n_features]\n",
    "            원본 특성의 입력층\n",
    "\n",
    "        반환값:\n",
    "        ----------\n",
    "        y_pred : 배열, 크기 = [n_samples]\n",
    "            예측된 클래스 레이블\n",
    "\n",
    "        \"\"\"\n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\"훈련 데이터에서 가중치를 학습합니다\n",
    "\n",
    "        매개변수\n",
    "        -----------\n",
    "        X_train : 배열, 크기 = [n_samples, n_features]\n",
    "            원본 특성의 입력층\n",
    "        y_train : 배열, 크기 = [n_samples]\n",
    "            타깃 클래스 레이블\n",
    "        X_valid : 배열, 크기 = [n_samples, n_features]\n",
    "            훈련하는 동안 검증에 사용할 샘플 특성\n",
    "        y_valid : 배열, 크기 = [n_samples]\n",
    "            훈련하는 동안 검증에 사용할 샘플 레이블\n",
    "\n",
    "        반환값:\n",
    "        ----------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        n_output = np.unique(y_train).shape[0]  # number of class labels\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "        ########################\n",
    "        # 가중치 초기화\n",
    "        ########################\n",
    "\n",
    "        # 입력층 -> 은닉층 사이의 가중치\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                      size=(n_features, self.n_hidden))\n",
    "\n",
    "        # 은닉층 -> 출력층 사이의 가중치\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                        size=(self.n_hidden, n_output))\n",
    "\n",
    "        epoch_strlen = len(str(self.epochs))  # 출력 포맷을 위해\n",
    "        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "\n",
    "        # 훈련 에포크를 반복합니다\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # 미니 배치로 반복합니다\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n",
    "                                   1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                # 정방향 계산\n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "\n",
    "                ##################\n",
    "                # 역전파\n",
    "                ##################\n",
    "\n",
    "                # [n_samples, n_classlabels]\n",
    "                sigma_out = a_out - y_train_enc[batch_idx]\n",
    "\n",
    "                # [n_samples, n_hidden]\n",
    "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
    "\n",
    "                # [n_samples, n_classlabels] dot [n_classlabels, n_hidden]\n",
    "                # -> [n_samples, n_hidden]\n",
    "                sigma_h = (np.dot(sigma_out, self.w_out.T) *\n",
    "                           sigmoid_derivative_h)\n",
    "\n",
    "                # [n_features, n_samples] dot [n_samples, n_hidden]\n",
    "                # -> [n_features, n_hidden]\n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
    "                grad_b_h = np.sum(sigma_h, axis=0)\n",
    "\n",
    "                # [n_hidden, n_samples] dot [n_samples, n_classlabels]\n",
    "                # -> [n_hidden, n_classlabels]\n",
    "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
    "                grad_b_out = np.sum(sigma_out, axis=0)\n",
    "\n",
    "                # 규제와 가중치 업데이트\n",
    "                delta_w_h = (grad_w_h + self.l2*self.w_h)\n",
    "                delta_b_h = grad_b_h # 편향은 규제하지 않습니다\n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "\n",
    "                delta_w_out = (grad_w_out + self.l2*self.w_out)\n",
    "                delta_b_out = grad_b_out  # 편향은 규제하지 않습니다\n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "\n",
    "            #############\n",
    "            # 평가\n",
    "            #############\n",
    "\n",
    "            # 훈련하는 동안 에포크마다 평가합니다\n",
    "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "            \n",
    "            cost = self._compute_cost(y_enc=y_train_enc,\n",
    "                                      output=a_out)\n",
    "\n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "\n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) /\n",
    "                         X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) /\n",
    "                         X_valid.shape[0])\n",
    "\n",
    "            sys.stderr.write('\\r%0*d/%d | 비용: %.2f '\n",
    "                             '| 훈련/검증 정확도: %.2f%%/%.2f%% ' %\n",
    "                             (epoch_strlen, i+1, self.epochs, cost,\n",
    "                              train_acc*100, valid_acc*100))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-62db764b5613>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                   seed=1)\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m nn.fit(X_train=X_train[:55000], \n\u001b[0m\u001b[0;32m     10\u001b[0m        \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m55000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m        \u001b[0mX_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m55000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetMLP(n_hidden=100, \n",
    "                  l2=0.01, \n",
    "                  epochs=n_epochs, \n",
    "                  eta=0.0005,\n",
    "                  minibatch_size=100, \n",
    "                  shuffle=True,\n",
    "                  seed=1)\n",
    "\n",
    "nn.fit(X_train=X_train[:55000], \n",
    "       y_train=y_train[:55000],\n",
    "       X_valid=X_train[55000:],\n",
    "       y_valid=y_train[55000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetMLP' object has no attribute 'eval_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-97ca7f874f4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cost'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cost'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuralNetMLP' object has no attribute 'eval_'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(nn.epochs), nn.eval_['cost'])\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(nn.epochs), nn.eval_['train_acc'], \n",
    "         label='training')\n",
    "plt.plot(range(nn.epochs), nn.eval_['valid_acc'], \n",
    "         label='validation', linestyle='--')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = nn.predict(X_test)\n",
    "acc = (np.sum(y_test == y_test_pred)\n",
    "       .astype(np.float) / X_test.shape[0])\n",
    "\n",
    "print('테스트 정확도: %.2f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscl_img = X_test[y_test != y_test_pred][:25]\n",
    "correct_lab = y_test[y_test != y_test_pred][:25]\n",
    "miscl_lab = y_test_pred[y_test != y_test_pred][:25]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "for i in range(25):\n",
    "    img = miscl_img[i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "    ax[i].set_title('%d) t: %d p: %d' % (i+1, correct_lab[i], miscl_lab[i]))\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
