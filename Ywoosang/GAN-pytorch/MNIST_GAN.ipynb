{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-nirvana",
   "metadata": {},
   "source": [
    "### 개념 참고 링크\n",
    "  \n",
    "선형 레이어와 비선형 레이어  \n",
    "https://go-hard.tistory.com/14  \n",
    "배치사이즈(batch size),에포크(epoch),반복(iteration) 차이  \n",
    "https://losskatsu.github.io/machine-learning/epoch-batch/# \n",
    "\n",
    "기본 연산 복습  \n",
    "https://tutorials.pytorch.kr/beginner/blitz/tensor_tutorial.html   \n",
    "학습률(Learning rate)  \n",
    "https://bioinformaticsandme.tistory.com/130  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-corrections",
   "metadata": {},
   "source": [
    "### Pytorch docs  \n",
    " \n",
    "\n",
    "torch.nn.Sequential(*args)  \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html  \n",
    "torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)  \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html?highlight=nn%20leakyrelu#torch.nn.LeakyReLU  \n",
    "torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)  \n",
    "https://pytorch.org/docs/stable/optim.html?highlight=optim%20adam#torch.optim.Adam  \n",
    "torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')  \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu 사용여부: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Descriminator 가 이미지가 진짜인지 가짜인지 판별 \n",
    "# nn.Module 상속 \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            # 0.1 : 하이퍼 파라미터의 일종 \n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "              # linear layer 256 to image dimension\n",
    "            nn.Linear(256, img_dim), # mnist 이미지가 28x28x1사이즈 -> 786 \n",
    "            # 픽셀 출력값들이 -1 에서 1 사이의 값임을 보장하기 위해 \n",
    "            # mnist 데이터셋으로부터 입력을 정규화 \n",
    "            # 입력값을 [-1,1] 로 하면 출력값도 [-1,1] \n",
    "            # 탄젠트 함수임\n",
    "            nn.Tanh(),  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "# Hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('gpu 사용여부:',device)\n",
    "\n",
    "# learning rate 설정\n",
    "# \n",
    "lr = 3e-4\n",
    "\n",
    "# dimention : 64 로 설정  \n",
    "# 입력 파라미터임 128,256 으로도 설정 가능 \n",
    "z_dim = 64\n",
    "\n",
    "# Gan 은 Hyperparameter 에 민감함 \n",
    "# replication the original gan paper in a way \n",
    "image_dim = 28 * 28 * 1  # 784\n",
    "\n",
    "# 배치사이즈를 32 로 설정 \n",
    "batch_size = 32\n",
    "\n",
    "# 에포크 50 번 돌림\n",
    "num_epochs = 50\n",
    "\n",
    "# discriminator 초기화 (init) \n",
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(z_dim, image_dim).to(device)\n",
    "\n",
    "\n",
    "# noise 설정 \n",
    "# 설정하는 이유 : 에포크마다 어떻게 변하는지 보기 위해 \n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "\n",
    "# the actual mean standard deviation for the mnist data set \n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)),]\n",
    ")\n",
    "\n",
    "\n",
    "# MNIST 실습을 위해 파이토치로 데이터셋을 다운로드  \n",
    "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
    "\n",
    "# 데이터 로더 생성 \n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 옵티마이저 정의 \n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "# 제너레\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "# \n",
    "criterion = nn.BCELoss()\n",
    "writer_fake = SummaryWriter(f\"logs/GAN_MNIST_fake\")\n",
    "writer_real = SummaryWriter(f\"logs/GAN_MNIST_real\")\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # loader : 데이터 로더 \n",
    "    # batch_idx ,real \n",
    "    print(loader) \n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        # real \n",
    "        real = real.view(-1, 784).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        # criterion : loss func \n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        # where the second option of maximizing doesn't suffer from\n",
    "        # saturating gradients\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step += 1\n",
    "                \n",
    "%tensorboard --logdir logs/fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stone-moldova",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
