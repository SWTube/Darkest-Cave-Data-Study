{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. tensor와 rank\n",
    "2. tensorflow의 변수 선언\n",
    "3. tensorflow methods (변수 다루기)\n",
    "4. 선형 회귀 모델 구현\n",
    "5. tf.keras API를 이용한 신경망 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. tensor와 rank\n",
    "- 텐서(tensor) : 스칼라, 벡터, 행렬이 일반화된 것\n",
    "- 랭크(rank) : 텐서의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "3\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
      "[1 2 3 4]\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "랭크: 0 1 2\n",
      "크기: () (4,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# t1, t2, t3 텐서(변하지 않음) 정의\n",
    "t1 = tf.constant(3)\n",
    "t2 = tf.constant([1,2,3,4])\n",
    "t3 = tf.constant([[1,2], [3,4]])\n",
    "\n",
    "# 랭크 구하기\n",
    "r1 = tf.rank(t1)\n",
    "r2 = tf.rank(t2)\n",
    "r3 = tf.rank(t3)\n",
    "\n",
    "# 크기 구하기 n * m\n",
    "s1 = t1.get_shape()\n",
    "s2 = t2.get_shape()\n",
    "s3 = t3.get_shape()\n",
    "\n",
    "print(type(t1))\n",
    "print(t1.numpy())\n",
    "print(t2)\n",
    "print(t2.numpy()) # numpy()는 tf.Tensor의 첫 번째 element 또는 tf.Variable의 numpy 매개변수를 꺼낼 때 사용\n",
    "print(type(r1))\n",
    "print(r1)\n",
    "print('랭크:', r1.numpy(), r2.numpy(), r3.numpy())\n",
    "print('크기:', s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.  2.  3.  3.5]\n",
      " [4.  5.  6.  6.5]\n",
      " [7.  8.  9.  9.5]], shape=(3, 4), dtype=float64)\n",
      "\n",
      " <class 'tensorflow.python.framework.tensor_shape.TensorShape'>\n",
      "t1의 크기 :  (3, 4)\n",
      "\n",
      " <class 'tensorflow.python.framework.tensor_shape.TensorShape'>\n",
      "t1의 크기 :  (3, 4)\n",
      "\n",
      " <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float64, numpy=\n",
      "array([[ 0.01368775, -0.64371324,  0.07459327,  0.03886867],\n",
      "       [ 1.38113735, -1.10343232,  1.19633345,  0.92566879],\n",
      "       [ 0.00213338, -1.46271726,  0.26427025,  0.25825512]])>\n",
      "\n",
      " [-0.71630322 -0.58920561  0.49321725]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1., 2., 3., 3.5],\n",
    "               [4., 5., 6., 6.5],\n",
    "               [7., 8., 9., 9.5]])\n",
    "t1 = tf.constant(arr)\n",
    "print(t1)\n",
    "s = t1.get_shape()\n",
    "\n",
    "print('\\n', type(s))\n",
    "print('t1의 크기 : ', s)\n",
    "print('\\n', type(t1.shape))\n",
    "print('t1의 크기 : ', t1.shape)\n",
    "\n",
    "t2 = tf.Variable(np.random.normal(size=s))\n",
    "print('\\n', type(t2))\n",
    "print(t2)                        # s = (3, 4)\n",
    "t3 = tf.Variable(np.random.normal(size=s[0])) # shqpe나 get_shape()의 반환값을 인덱스로 접근 가능\n",
    "print('\\n', t3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. tensorflow의 변수 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서플로우에서 변수는 특별한 종류의 텐서 객체이다. \n",
    "- 훈련 과정 동안 모델 파라미터를 저장하고 업데이트할 수 있다.\n",
    "- 변수를 정의할 때 초기 텐서 값을 지정해 주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(2, 4) dtype=int32, numpy=\n",
      "array([[1, 2, 3, 4],\n",
      "       [5, 6, 7, 8]])>\n"
     ]
    }
   ],
   "source": [
    "# 변수 정의 방법\n",
    "# tf.Variable( <initial-value> , name=<optional-name> )\n",
    "w = tf.Variable(np.array([[1, 2, 3, 4], \n",
    "                          [5, 6, 7, 8]]), name='w')\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[False False]\n",
      " [False False]], shape=(2, 2), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "# 이름은 같지만 element들이 다르다\n",
    "a = tf.Variable(my_tensor, name=\"Mark\")\n",
    "b = tf.Variable(my_tensor + 1, name=\"Mark\")\n",
    "\n",
    "print(a == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf.constant([1,2])는 상수 // tf.Variable([1,2])는 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. tensorflow methods (변수 다루기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 0~17 범위의 숫자를 랭크 3 텐서, 즉 3차원 배열(3 * 2 * 3)에 할당 \n",
    "arr = np.arange(18).reshape(3,2,3)\n",
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 tf.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [12 13 14]\n",
      " [15 16 17]], shape=(6, 3), dtype=int32)\n",
      "\n",
      " tf.Tensor(\n",
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]\n",
      "  [16 17]]], shape=(3, 3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서 크기를 바꿈  ** tf.reshape의 반환 타입은 tf.constant(상수)이다 **  \n",
    "new_arr = tf.reshape(arr, shape=(6, -1))\n",
    "print(type(new_arr))\n",
    "print(new_arr)\n",
    "# new_arr1 대신에 new_arr쓰면 오류 뜸\n",
    "new_arr1 = tf.reshape(arr, shape=(3,3,2))\n",
    "print('\\n', new_arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 tf.transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]]\n",
      "\n",
      " [[15 16 17 18 19]\n",
      "  [20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 0 15]\n",
      "  [ 5 20]\n",
      "  [10 25]]\n",
      "\n",
      " [[ 1 16]\n",
      "  [ 6 21]\n",
      "  [11 26]]\n",
      "\n",
      " [[ 2 17]\n",
      "  [ 7 22]\n",
      "  [12 27]]\n",
      "\n",
      " [[ 3 18]\n",
      "  [ 8 23]\n",
      "  [13 28]]\n",
      "\n",
      " [[ 4 19]\n",
      "  [ 9 24]\n",
      "  [14 29]]], shape=(5, 3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# transpose\n",
    "before_transpose = tf.constant(np.arange(30).reshape(2,3,5))\n",
    "print(before_transpose)\n",
    "after_transpose = tf.transpose(before_transpose, perm=[2, 1, 0]) #  reshape(5, 3, 2) -> 숫자 위치는 바꿔도 숫자 자체는 못바꿈\n",
    "print(after_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 tf.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 3, 5), dtype=int32, numpy=\n",
      "array([[[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]]])>, <tf.Tensor: shape=(1, 3, 5), dtype=int32, numpy=\n",
      "array([[[15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29]]])>]\n",
      "\n",
      " [<tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "array([[[ 0,  1],\n",
      "        [ 5,  6],\n",
      "        [10, 11]],\n",
      "\n",
      "       [[15, 16],\n",
      "        [20, 21],\n",
      "        [25, 26]]])>, <tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=\n",
      "array([[[ 2,  3,  4],\n",
      "        [ 7,  8,  9],\n",
      "        [12, 13, 14]],\n",
      "\n",
      "       [[17, 18, 19],\n",
      "        [22, 23, 24],\n",
      "        [27, 28, 29]]])>]\n",
      "\n",
      " tf.Tensor(\n",
      "[[[ 0  1]\n",
      "  [ 5  6]\n",
      "  [10 11]]\n",
      "\n",
      " [[15 16]\n",
      "  [20 21]\n",
      "  [25 26]]], shape=(2, 3, 2), dtype=int32)\n",
      "\n",
      " tf.Tensor(\n",
      "[[[ 2  3  4]\n",
      "  [ 7  8  9]\n",
      "  [12 13 14]]\n",
      "\n",
      " [[17 18 19]\n",
      "  [22 23 24]\n",
      "  [27 28 29]]], shape=(2, 3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "before_split = tf.constant(np.arange(30).reshape(2,3,5))\n",
    "after_split1 = tf.split(before_split, num_or_size_splits=2, axis=0) # 2 * 3 * 5 를 1 * 3 * 5의 동일한 크기 두 개로 나눔\n",
    "after_split2 = tf.split(before_split, num_or_size_splits=[2, 3], axis=2) # 2 * 3 * 5 를 2*3*2, 2*3*3 로 나눔\n",
    "print(after_split1)\n",
    "print('\\n', after_split2)\n",
    "print('\\n', after_split2[0])\n",
    "print('\\n', after_split2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 tf.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(10, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# concat\n",
    "t1 = tf.ones(shape=(5,1), dtype=tf.float32)\n",
    "t2 = tf.zeros(shape=(5,1), dtype=tf.float32)\n",
    "after_concat1 = tf.concat([t1,t2], axis=0)\n",
    "after_concat2 = tf.concat([t1,t2], axis=1)\n",
    "print(after_concat1)\n",
    "print(after_concat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 사칙 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]])\n",
    "\n",
    "print(tf.add(a, b), \"\\n\")\n",
    "print(tf.multiply(a, b), \"\\n\")\n",
    "print(tf.matmul(a, b), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a + b, \"\\n\")  \n",
    "print(a * b, \"\\n\")  \n",
    "print(a @ b, \"\\n\") # 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(153, shape=(), dtype=int32)\n",
      "\n",
      "입력 크기:  (3, 2, 3)\n",
      "크기가 변경된 입력:\n",
      " [[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [12 13 14]\n",
      " [15 16 17]]\n",
      "열의 합:\n",
      "  [45 51 57]\n",
      "행의 합:\n",
      " [ 3 12 21 30 39 48]\n",
      "열의 평균:\n",
      " [7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# 각 열의 합을 계산\n",
    "sum_col = tf.reduce_sum(new_arr, axis=0) # axis: 축소될 차원을 지정 \n",
    "print('\\n', type(sum_col))\n",
    "# 각 행의 합을 계산\n",
    "sum_row = tf.reduce_sum(new_arr, axis=1)\n",
    "# 각 열의 평균을 계산\n",
    "mean_col = tf.reduce_mean(new_arr, axis=0)\n",
    "\n",
    "a = tf.reduce_sum(new_arr) # axis 매개변수의 기본값은 None으로, 모든 차원을 축소해 스칼라(rank 0인 텐서)를 반환\n",
    "print(a)\n",
    "\n",
    "print('\\n입력 크기: ', arr.shape)\n",
    "print('크기가 변경된 입력:\\n', new_arr.numpy())\n",
    "print('열의 합:\\n ', sum_col.numpy())\n",
    "print('행의 합:\\n', sum_row.numpy())\n",
    "print('열의 평균:\\n', mean_col.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 2, 3])\n",
    "y = tf.constant(2)\n",
    "z = tf.constant([2, 2, 2])\n",
    "\n",
    "# 모두 같은 계산\n",
    "print(tf.multiply(x, 2))\n",
    "print(x * y)\n",
    "print(x * z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32) \n",
      "\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 3x1 1x5의 행렬곱 (확장, 브로드캐스팅)\n",
    "x = tf.reshape(x,[3,1])\n",
    "y = tf.range(1, 5)\n",
    "print(x, \"\\n\")\n",
    "print(y, \"\\n\")\n",
    "print(tf.multiply(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 같은 크기 행렬의 곱\n",
    "x_stretch = tf.constant([[1, 1, 1, 1],\n",
    "                         [2, 2, 2, 2],\n",
    "                         [3, 3, 3, 3]])\n",
    "\n",
    "y_stretch = tf.constant([[1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4]])\n",
    "\n",
    "print(x_stretch * y_stretch)\n",
    "print(tf.multiply(x_stretch, y_stretch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 기타"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105860e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# 가장 큰 값 찾음\n",
    "print(tf.reduce_max(c))\n",
    "# 가장 큰 값의 인덱스 찾음\n",
    "print(tf.argmax(c))\n",
    "# Softmax는 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수\n",
    "# Softmax 연산 수행\n",
    "print(tf.nn.softmax(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[[ 1  2]\n",
      "  [ 3  4]\n",
      "  [ 5  6]]\n",
      "\n",
      " [[ 7  8]\n",
      "  [ 9 10]\n",
      "  [11 12]]\n",
      "\n",
      " [[13 14]\n",
      "  [15 16]\n",
      "  [17 18]]], shape=(3, 3, 2), dtype=int32)\n",
      "<tf.Variable 'Variable:0' shape=(3, 3, 2) dtype=int32, numpy=\n",
      "array([[[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6]],\n",
      "\n",
      "       [[ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]],\n",
      "\n",
      "       [[13, 14],\n",
      "        [15, 16],\n",
      "        [17, 18]]])>\n",
      "assign 이용 :  <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
      "tf.Tensor(\n",
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]\n",
      "  [16 17]]], shape=(3, 3, 2), dtype=int32)\n",
      "assign 이용X :  <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# tf.constant 배열 자료형과 숫자 더하기 연산 가능\n",
    "new_arr2 = new_arr1 + 1 # new_arr2 의 type도 tf.constant\n",
    "print('\\n', type(new_arr2))\n",
    "print(new_arr2)\n",
    "\n",
    "#tf.variable 자료형의 데이터를 바꿀 때 assign()을 이용\n",
    "new_arr3 = tf.Variable(new_arr1)\n",
    "new_arr3.assign(new_arr3 + 1)\n",
    "print(new_arr3)\n",
    "print('assign 이용 : ', type(new_arr3))\n",
    "\n",
    "# assign을 이용하지 않는 경우 tf,constant 자료형이 됨\n",
    "new_arr3 = new_arr3 - 1\n",
    "print(new_arr3)\n",
    "print('assign 이용X : ',type(new_arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second row: [3. 4.]\n",
      "Second column: [2. 4. 6.]\n",
      "Last row: [5. 6.]\n",
      "First item in last column: 2.0\n",
      "Skip the first row:\n",
      "[[3. 4.]\n",
      " [5. 6.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "# : 를 이용해 원하는 정보 추출 가능\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n",
      "(4, None)\n"
     ]
    }
   ],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)\n",
    "print(ragged_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Gray wolf', shape=(), dtype=string)\n",
      "tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)\n",
      "tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)\n",
      "<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>\n"
     ]
    }
   ],
   "source": [
    "scalar_string_tensor = tf.constant(\"Gray wolf\")\n",
    "print(scalar_string_tensor)\n",
    "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
    "                                 \"Quick brown fox\",\n",
    "                                 \"Lazy dog\"])\n",
    "print(tensor_of_strings)\n",
    "print(tf.strings.split(scalar_string_tensor, sep=\" \"))\n",
    "print(tf.strings.split(tensor_of_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "text = tf.constant(\"1 10 100\")\n",
    "print(tf.strings.to_number(tf.strings.split(text, \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)\n",
      "Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "byte_strings = tf.strings.bytes_split(tf.constant(\"Duck\"))\n",
    "byte_ints = tf.io.decode_raw(tf.constant(\"Duck\"), tf.uint8)\n",
    "print(\"Byte strings:\", byte_strings)\n",
    "print(\"Bytes:\", byte_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Sparse tensor는 메모리 효율적으로 데이터를 저장한다.\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "print(sparse_tensor, \"\\n\")\n",
    "\n",
    "# spaerse tensor를 dense tensor로 변환\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 선형 회귀 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 x에서 출력 y를 예측하는 선형 회귀 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# 훈련 샘플 10개인 1차원 데이터셋\n",
    "x_train = np.arange(10).reshape((10,1))\n",
    "y_train = np.array([1.0, 1.3, 3.1, 2.0, 5.0, 6.3, 6.6, 7.4, 8.0, 9.0])\n",
    "w = tf.Variable(tf.zeros(shape=(1,)))\n",
    "print(w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 정의\n",
    "class TfLinreg(object):\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        ## 가중치와 절편을 정의\n",
    "        self.w = tf.Variable(tf.zeros(shape=(1))) # 0으로 채워진 크기가 (1,)인 배열 [0.]로 w를 초기화\n",
    "        self.b = tf.Variable(tf.zeros(shape=(1)))\n",
    "        # Stochastic Gradient Descent(확률적 경사 하강법)을 통해 가중치 업데이트\n",
    "        self.optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
    "    \n",
    "    def fit(self, x, y, num_epoches=10):\n",
    "        # lose / cost function의 값을 저장하기 위한 리스트 정의\n",
    "        training_costs = []\n",
    "        for step in range(num_epoches):\n",
    "            # train 가능한 변수들을 추적해 기록 남김\n",
    "            with tf.GradientTape() as tape:\n",
    "                z_net = self.w * x + self.b\n",
    "                z_net = tf.reshape(z_net, [-1])\n",
    "                \n",
    "                # Ordinary Least Squares(최소 제곱법)\n",
    "                sqr_errors = tf.square(y-z_net)\n",
    "                mean_cost = tf.reduce_mean(sqr_errors)\n",
    "            \n",
    "            # lose / cost function에 대한 가중치의 gradient를 계산\n",
    "            grads = tape.gradient(mean_cost, [self.w, self.b]) # gradient(<미분대상>, <변수 리스트>)\n",
    "            # optimizer에 gradient를 반영\n",
    "            self.optimizer.apply_gradients(zip(grads, [self.w, self.b])) \n",
    "            # apply_gradients 메소드는 gradient와 변수를 쌍으로 하는 튜플을 입력 받기에 python의 zip()활용\n",
    "            training_costs.append(mean_cost.numpy())\n",
    "        return training_costs\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.w * x + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrmodel = TfLinreg()\n",
    "training_costs = lrmodel.fit(x_train, y_train)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(training_costs) + 1), training_costs)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAscElEQVR4nO3deVBc55ku8OejaXbUQiAbGSQjJGtDIMCtDYRYmr2ZTDnlzMQ1SbyMx/Ey44x9Y2eSqsT2lFP3psrlsp3xOKPE8TL2OIljJ2Opmx1hsLAWJGRaAm0WWEJoxQjETsN3/0Bqc8QihOg+p7uf31/Wew593nQkPTrLez4hpQQREZHW+KjdABER0WQYUEREpEkMKCIi0iQGFBERaRIDioiINMlX7QbGi4iIkDExMWq3QURELrR///5LUsqF19c1FVAxMTGor69Xuw0iInIhIcRXk9V5iY+IiDSJAUVERJrEgCIiIk3S1D2oyQwPD6OtrQ0DAwNqt0JXBQQEIDo6Gnq9Xu1WiMiDaT6g2traEBoaipiYGAgh1G7H60kp0dHRgba2NixdulTtdojIg2n+Et/AwADCw8MZThohhEB4eDjPaInI6TR/BgWA4aQx/P+DyLvZbDZUVlaiq6sLBoMBJpMJ8fHxc34ctwgoIiLSBpvNhu3bt2N4eBgA0NXVhe3btwPAnIeU5i/xaUFISMiE2m9+8xu8++670/5cdXU1DAYDkpKSsGrVKvz4xz+ek36qq6shhMCbb77pqDU0NEAIgZdeemnGn9Pa2oq1a9fe8j5E5D0qKioc4XTN8PAwKisr5/xYHncG5apTz0cffXRG+6WlpWHHjh3o7+9HUlIS7rnnHqSmpt7y8ePj4/HHP/4R//iP/wgA+MMf/oB169bd8ucSEU1GSokDBw6gu7t70u1dXV1zfkyPOoO6dup57Yu6dupps9nm/FjPP/+842wlIyMDP/nJT7BhwwasWLECtbW1E/YPDAxEYmIizpw5AwAoKyvD5s2bkZycjO985zvo6ekBAFitVqxatQpbtmzBk08+iaKiokmPv2TJEgwMDOD8+fOQUqKkpAQFBQWO7QcPHsSmTZuQkJCAe+65B52dnQCA/fv3Y926ddi8eTNef/11x/4jIyN45plnsH79eiQkJOC//uu/5uaLIiK3d+7cOfz+97/Hjh07ptzHYDDM+XHd6gzqhRdeuOmfGR4exscff4yPP/542v2ee+652bYFALDb7di7dy+sViteeOEFVFRUKLZ3dnbi+PHj2Lp1Ky5duoQXX3wRFRUVCA4Oxq9+9Su8/PLLePbZZ/HDH/4QNTU1WLp0Ke67775pj3nvvffiww8/RFJSEpKTk+Hv7+/Y9oMf/AC//vWvkZ6ejl/84hd44YUX8Morr+DBBx901J955hnH/m+++SYMBgP27duHwcFBpKamIjc3lw9EEHmxwcFBVFdXY8+ePZBSTrmfXq+HyWSa8+N71BmUmr797W8DAO6++260trY66rW1tUhISEBkZCSKiooQGRmJ3bt3o6mpCampqUhMTMQ777yDr776CkeOHEFsbKxjvuhGAfV3f/d3+PDDD/HBBx8o9u3q6sLly5eRnp4OALj//vtRU1Mzof7973/f8TNlZWV49913kZiYiI0bN6KjowPHjx+fk++GiNyLlBJNTU14/fXXsXv3bkc4+fj4IC0tDd/61rccZ0wGgwF/8zd/w6f4tOza2YtOp4PdbnfUr92DOnbsGLZs2YJ77rkHUkrk5OTggw8+UHxGQ0PDTR0zMjISer0e5eXlePXVV1FXVzft/lLKKc+IpJT49a9/jby8PEV9fNgSkefr7OyE1WrFiRMnFPWYmBiYzWZEREQAAJKSkpzei1sF1I0uw13/+CMwdurprHS/GStWrMBPf/pT/OpXv8Jrr72GJ554AidOnMDy5cvR19eHtrY2rFq1CidPnkRraytiYmLwxz/+8Yaf++///u+4cOECdDqdo2YwGBAWFoba2lqkpaXhv//7v5Geno758+fDYDDgs88+w5YtW/D+++87fiYvLw9vvPEGsrKyoNfrcezYMURFRTnluyAi7bHb7airq0Ntba3iH9nBwcHIzc1FfHy8yy/5u1VA3ci1EJrrp/j6+voQHR3t+PXTTz89q8959NFH8dJLL6Gnpwdvv/027rvvPgwODgIAXnzxRaxYsQL/+Z//ifz8fERERGDDhg03/MyUlJRJ6++88w4effRR9PX1ITY2Fm+99RYA4K233sJDDz2EoKAgxdnSww8/jNbWViQnJ0NKiYULF+Kvf/3rrP53EpF7aWlpgcViQUdHh6JuNBqRlZWFwMBAAEDccyXoHRyZ8nOC/XU4/EL+nPUlprvx5WpGo1Fev2Bhc3MzVq9erVJHrtfT04OQkBBIKfHEE0/grrvuwlNPPaV2WxN42/8vRJ6op6cH5eXlaGxsVNSv3TO//ipKzL9ZbviZrf/PfNN9CCH2SymN19c96gzKE/z2t7/FO++8g6GhISQlJeGHP/yh2i0RkYeRUmL//v2orKxUvFfTz88PWVlZWL9+PXx81H+GjgGlMU899ZQmz5iIyDOcPXsWFovFMZN5TVxcHPLy8hAaGqpSZxMxoIiIvMDg4CB27tyJvXv3KmaawsLCYDabsWzZMhW7mxwDiojIg12baSotLcWVK1ccdZ1Oh9TUVGzZskWzi48yoIiIPNTXX38Nq9WKL7/8UlGPjY1FYWEhwsPDVepsZhhQREQexm63Y9euXaitrcXIyDePhYeEhCAvLw9xcXFu8Roz9R/T0LCOjg4kJiYiMTERkZGRiIqKcvx6aGho2p+tr6/Hk08+ecNjTDXHdKsyMjJw/SP713vllVfQ19fnlOMTkTpOnjyJ3/zmN6iurlaE0/r16/HEE09g7dq1sw6nYH/dLW2/WR5zBuWMAbLw8HAcPHgQwNjby0NCQhRrOtntdvj6Tv4VGo1GGI0THuuf4EavJ3KmV155Bd/73vcQFBSkWg9ENDd6enpQVlY2YfWGRYsWoaioCHfcccctH2Muh3BnwmPOoKYLp5lsn6kHHngATz/9NDIzM/GTn/wEe/fuRUpKCpKSkpCSkoKjR48CGFtU8NpSGc8//zweeughZGRkIDY2Fq+99prj864thlhdXY2MjAzce++9WLVqFf7hH/7B8aTNTJbg6O/vx3e/+10kJCTg7//+79Hf3+/Y9thjj8FoNCIuLs7xuqjXXnsN7e3tyMzMRGZm5pT7EZG2jY6OYu/evfiP//gPRTj5+/ujoKAADz/88JyEkxo85gzKlY4dO4aKigrodDp0d3ejpqYGvr6+qKiowM9+9jN89NFHE37myJEj2LlzJ65cuYKVK1fisccem/DkTENDAw4fPow77rgDqamp2LVrF4xG44yW4HjjjTcQFBSExsZGNDY2Ijk52bHtl7/8JRYsWICRkRGYTCY0NjbiySefxMsvv4ydO3c6Xv442X4JCQlz+M0R0Vxqb2+HxWJBe3u7or527Vrk5uZqaqZpNhhQs/Cd73zH8XLWrq4u3H///Th+/DiEEBOWQr7GbDbD398f/v7+uO2223D+/HnF+/0AYMOGDY5aYmIiWltbERISMmEJjm3btk34/JqaGsc9r4SEBEWw/OlPf8K2bdtgt9tx9uxZNDU1TRo8M92PiNQ1MDCAqqoq1NfXK2aaFixYALPZjNjYWBW7mzsMqFkIDg52/PfPf/5zZGZm4i9/+QtaW1uRkZEx6c+MX0zw+iU5ptvnZt6VONmNz5aWFrz00kvYt28fwsLC8MADDyhebXKz+xGReqSUOHz4MEpLSx2rcANjf1+kpaUhNTV1yvvi7shj7kGppaury/FCxbfffnvOP3/8EhwAplyCY+vWrY7lMw4dOuR4+WN3dzeCg4NhMBhw/vx5FBcXO34mNDTUMbg33X5EpL6Ojg689957+OijjxThtGzZMjz++ONIT0/3qHACeAZ1y5599lncf//9ePnll5GVlTXnnx8YGDijJTgee+wxPPjgg0hISEBiYqJjv3Xr1iEpKQlxcXGIjY1Famqq42ceeeQRFBQUYNGiRdi5c+eU+xGROmw2GyoqKtDd3T1hW0hICPLz87FmzRq3mGmaDY9ZbsNZr4HXAi0uwcHlNoicy2az4X//938Vs0zXbNy4EZmZmYrbAu5squU2POYSn6sHyFzpt7/9LRITExEXF4euri4uwUHk4a5cuYLt27dPGk7Xzpw8JZym4zGX+Fw9QOZKXIKDyDuMjo5i3759qKqqmvKJ4PH3nzydWwSUlNJjr7G6Iy1dFibyFGfOnIHFYsHZs2en3c9gMLioI/VpPqACAgLQ0dGB8PBwhpQGSCnR0dGBgIAAtVsh8ggDAwOorKyc8O7M4OBgDAwMKC7z6fV6mEwmV7eoGs0HVHR0NNra2nDx4kW1W6GrAgICJgwZE9HNkVLCZrOhrKwMvb29jrqvry/S0tKQkpKC5uZmVFZWoqurCwaDASaTCfHx8Sp27VqaDyi9Xu94iwIRkSe4dOkSrFYrWlpaFPXly5ejsLAQYWFhAID4+HivCqTraT6giIg8xfDwMGpra1FXV6e4dBcaGor8/HysXr0aQginrM7gjpwaUEKIpwA8DEACsAF4UErJ9+cQkdc5ceIErFYrOjs7HTUhBDZu3IiMjAzFY+OuWp1B65wWUEKIKABPAlgjpewXQvwJwHcBvO2sYxIRaU13dzdKS0vR1NSkqEdHR8NsNiMyMlKlzrTP2Zf4fAEECiGGAQQBaL/B/kREHuHaOk07d+5UrMAdEBCA7OxsJCcn88nkG3BaQEkpzwghXgJwCkA/gDIpZdn1+wkhHgHwCAAsWbLEWe0QEblMW1sbLBYLzp07p6ivW7cOOTk5ihURaGrOvMQXBuBvASwFcBnAh0KI70kp3xu/n5RyG4BtwNi7+JzVDxGRs/X396OyshL79+9X1CMiImA2mxETE6NOY27KmZf4sgG0SCkvAoAQ4mMAKQDem/aniIjcjJQSjY2NKCsrQ19fn6Pu6+uL9PR0bN682bHIKc2cMwPqFIBNQoggjF3iMwGon/5HiIjcy8WLF2G1Wh1rtl2zYsUK5OfnO2aa6OY58x7UHiHEnwEcAGAH0ICrl/KIiNzd8PAwampqUFdXh9HRUUd93rx5KCgowMqVK2f9EESwv+6Gc1DeQPPrQRERac2xY8dQXFyMy5cvO2pCCGzatAkZGRnw8/NTrzk3NNV6UHyTBBHRDHV3d6OkpATNzc2K+uLFi2E2m3H77ber1JlnYkAREd3A6Ogo9uzZg507dyrWaQoMDER2djaSkpI40+QEDCgiommcPn0aFosF58+fV9QTExORk5ODoKAglTrzfAwoIqJJ9PX1oaKiAg0NDYr6woULYTabceedd6rUmfdgQBGRV5r6jeESy3UdWK9vQ4CwO6p6vR7p6enYtGkTZ5pchAFFRF5psnCaL/qxWf8VInU9ivrKlSuRn5+P+fPnu6g7AhhQROTlluo6YPRtQ7AYe/hh/LMOBoPBMdNErseAIiKvtVTXgTR9K3RCOQ86KoFD9kh88PiDnGlSkY/aDRARqSFYDGLLJOEEAANSj/32aIaTyngGRUReZWRkBLt378Y9/ofhO0k4AUCgGJ60Tq7FgCIir3Hq1ClYLBZcuHAB+mnmanslz5y0gAFFRB6vr68P5eXlOHjwoKLeM6pHgLArzqTs0gf19igXd0iTYUARkceSUqKhoQEVFRXo7+931PV6PfYNLsLBwQjE6Dph9D2DYDGEXumHensUWkbCveaN4VrGgCIij3T+/HlYLBacPn1aUV+1ahXy8/NhMBhU6oxmigFFRB5laGgI1dXV2L17N8YvJzR//nwUFBRgxYoVKnZHN4MBRUQeQUqJo0ePori4GN3d3Y66j48PUlJSsHXrVuj1ehU7pJvFgCIit3f58mUUFxfj2LFjivqdd94Js9mMhQsXqtQZ3QoGFBG5rZGREXz++ef49NNPYbd/82LXoKAg5ObmIiEhges0uTEGFBG5pdbWVlitVly8eFFRv/vuu2EymRAYGKhSZzRXGFBE5FZ6e3tRXl6OL774QlG//fbbUVRUhOjoaJU6o7nGgCIityClxIEDB1BRUYGBgQFH3c/PD5mZmdiwYQN8fPh6UU/CgCIizTt37hwsFgva2toU9TVr1iAvLw/z5s1TqTNyJgYUEWnW4OAgqqursWfPHsVMU1hYGAoKCnDXXXep2B05GwOKiJxm6mXVxwT763D4hfwJdSklmpubUVJSgitXrjjqPj4+SE1NRVpaGmeavAADioicZrpwmmp7Z2cniouLcfz4cUU9JiYGZrMZERERc9ojaRcDiog0wW63o66uDrW1tYqZpuDgYOTm5iI+Pp4zTV6GAUVEqmtpaYHFYkFHR4eibjQakZWVxZkmL8WAIiLVBGAYf/nLX9DY2KioR0ZGoqioCFFRXJfJmzGgiEgFEit1F3G3/gwaG7+5D+Xn54esrCysX7+eM03EgCIi51uq63AsCtgvfWGHD+b5DCn2iYuLQ15eHkJDQ1XqkrSGAUXk5mb7KLerLNV1YIv+K/iKUQBAkLArtoeFhcFsNmPZsmVqtEcaxoAicnOzeZTbVYL9dTDijCOcxpMSaEIU/ufxB+Dry7+KaCJe5CUip6n90QaEXHcp7xohgD89/zDDiabE3xlENOfsdjt27dqF2traKfcxGAwu7IjcEQOKiObUyZMnYbVaJ8w0jafX62EymVzYFbkjBhQRzYmenh6Ulpbi0KFDivqiRYuwatUqHDhwAF1dXTAYDDCZTIiPj1epU3IXDCgiuiWjo6Oor69HVVUVBgcHHXV/f39kZWXBaDTCx8cHW7duVbFLckcMKCKatfb2dlgsFrS3tyvqa9euRW5uLmea6JY4NaCEEPMB/A7AWgASwENSys+deUwibxPsr7vhHNRcGxgYQFVVFerr6xXrNIWHh6OwsBCxsbFzfkzyPs4+g3oVQImU8l4hhB+AICcfj8jruHIIV0qJw4cPo7S0FD09PY66TqdDWloaUlNT+dg4zRmn/U4SQswDsBXAAwAgpRwCMPlABBFpXkdHB6xWK06ePKmoL1u2DIWFhViwYIFKnZGncuY/dWIBXATwlhBiHYD9AH4kpewdv5MQ4hEAjwDAkiVLnNgOEc2G3W7HZ599hs8++wwjI99cSgwJCUF+fj7WrFnDdZrIKcT468dz+sFCGAHsBpAqpdwjhHgVQLeU8udT/YzRaJT19fVO6YeIbt6XX34Jq9WKr7/+2lETQmDDhg3IzMyEv7+/it2RpxBC7JdSGq+vO/MMqg1Am5Ryz9Vf/xnAvznxeEQ0R65cuYLS0lIcPnxYUY+KioLZbMaiRYtU6oy8idMCSkp5TghxWgixUkp5FIAJQJOzjkdEt250dBT79u1DVVUVhoa+uWUcEBAAk8mE5ORkrtNELuPsx23+BcD7V5/gOwngQScfj4hm6cyZM7BYLDh79qyinpCQgJycHISEhKjUGXkrpwaUlPIggAnXFYlIOwYGBlBZWYnr7/+Gh4fDbDZj6dKlKnVG3o4DC0ReSkoJm82GsrIy9PZ+83Ctr68v0tLSkJKSwpkmUhV/9xF5oUuXLsFqtaKlpUVRX758OQoLCxEWFqZSZ0TfYEAReZHh4WHU1tairq5OMdMUGhqK/Px8rF69mjNNpBkMKCIvceLECVitVnR2djpqQghs3LgRGRkZnGkizWFAEXm47u5ulJaWoqlJOeURHR0Ns9mMyMhIlTojmh4DishDjY6OYu/evdi5c+eEmabs7GwkJyfzch5pGgOKyEPYbDZUVlaiq6sLwcHB0Ol06O7uVuyzbt065OTkIDg4WKUuiWaOAUXkAWw2G7Zv347h4WEAUDw2DgAREREwm82IiYlRoTui2WFAEXmAyspKRzhdz2QyYfPmzdDp5n7hQiJnYkARubmLFy+iq6tryu1btmxxYTdEc4cBReSmhoeHUVNTg7q6uin3MRgMLuyIaG4xoIjc0LFjx1BcXIzLly9PuY9er4fJZHJdU0RzjAFF5Ea6urpQWlqK5uZmRX3x4sVYsWIF6uvr0dXVBYPBAJPJhPj4eJU6Jbp1DCiiGYp7rgS9gyNTbg/21+HwC/lOOfbIyAj27NmD6upqxcMQgYGByM7ORlJSEoQQvN9EHoUBRTRD04XTTLbP1unTp7Fjxw5cuHBBUU9MTEROTg6CgoKcclwitTGgiDSqr68PFRUVaGhoUNQXLlyIoqIiLFmyRKXOiFyDAUWkMVJKfPHFFygvL0dfX5+jrtfrkZ6ejk2bNnGmibwCA4pIQy5cuACLxYJTp04p6itXrkR+fj7mz5+vTmNEKmBAEWnA0NAQampq8Pnnn2N0dNRRNxgMKCgowMqVK1XsjkgdDCgilR09ehTFxcWKt0H4+Phg8+bN2Lp1K/z8/FTsjkg9NwwoIcQ/A3hfStl5o32JaOa6urpQXFyMo0ePKupLliyB2WzGbbfdplJnRNowkzOoSAD7hBAHAPweQKmUUjq3LSLtCfbX3XAOaiZGRkawe/dufPrpp4qZpqCgIOTk5GDdunVcp4kIgJhJ1oixPy25AB4EYATwJwBvSim/nMtmjEajrK+vn8uPJNKUU6dOwWKxTJhpSkpKQnZ2NmeayCsJIfZLKY3X12d0D0pKKYUQ5wCcA2AHEAbgz0KIcinls3PbKpHn6evrQ3l5OQ4ePKio33bbbSgqKsLixYvVaYxIw2ZyD+pJAPcDuATgdwCekVIOCyF8ABwHwIAimoKUEg0NDaioqEB/f7+jrtfrkZGRgY0bN3KmiWgKMzmDigDwbSnlV+OLUspRIUSRc9oicn/nz5+HxWLB6dOnFfXVq1cjLy+PS2EQ3cANA0pK+YtptjVPtY3IWw0NDaG6uhq7d+/G+Hu88+fPR0FBAVasWKFid0Tug3NQRHNESokjR46gpKQE3d3djrqPjw9SUlKwdetW6PV6FTskci8MKKI5cPnyZRQXF+PYsWOK+p133gmz2YyFCxeq1BmR+2JAEd2CkZER1NXVoaamBna73VEPCgpCbm4uEhISONNENEsMKKKbZLPZUFlZia6uLvj4+CjenQcAd999N0wmEwIDA1XqkMgzMKCIboLNZsMnn3ziOFsaH06RkZEwm82Ijo5Wqz0ij8KAIpohKSWKi4sVl/KuCQgIwD/90z/Bx8dHhc6IPBMDimgGzp07B4vFohi2HW9gYIDhRDTHGFBE0xgcHER1dTX27NmD6d5byaFbornHgCKahJQSzc3NKCkpwZUrVxTbrn8wQq/Xw2QyubpFIo/HgCK6TmdnJ6xWK06cOKGoL126FIWFhTh79qzjKT6DwQCTyYT4+HiVuiXyXE4PKCGEDkA9gDNSSr67jzTLbrejrq4OtbW1igchgoODkZubi/j4eAghEBERwUAicgFXnEH9CEAzgHkuOBbRrLS0tMBisaCjo0NRNxqNMJlMCAgIUKkzIu/l1IASQkQDMAP4JYCnnXksotno6elBeXk5GhsbFfVFixbBbDYjKipKpc6IyNlnUK9gbL2o0Kl2EEI8AuARAFiyZImT2yEaMzo6iv3796OqqgoDAwOOup+fH7KysrB+/Xo+Nk6kMqcF1NW1oi5IKfcLITKm2k9KuQ3ANmBsyXdn9UN0zdmzZ2GxWHDmzBlFPS4uDnl5eQgNnfLfU0TkQs48g0oF8C0hRCGAAADzhBDvSSm/58RjEk1pcHAQVVVV2Ldvn2KmacGCBSgsLMSyZctU7I6Irue0gJJS/hTATwHg6hnUjxlOpAYpJZqamlBSUoKenh5HXafTYcuWLdiyZQt8fTlxQaQ1/FNJHu3rr7+G1WrFl19+qajHxsaisLAQ4eHhKnVGRDfikoCSUlYDqHbFsYiAsZmmXbt2oba2FiMjI456SEgI8vLyEBcXx3WaiDSOZ1DkcU6ePAmr1aqYaRJCwGg0IisrizNNRG6CAUUeo6enB6WlpTh06JCifscdd8BsNuOOO+5QqTMimg0GFLm90dFR1NfXo6qqCoODg466v78/srKyYDQaOdNE5IYYUOTW2tvbYbFY0N7erqjHx8cjNzcXISEhKnVGRLeKAUVuaWBgAFVVVaivr1fMNIWHh6OwsBCxsbEqdkdEc4EBRW5FSolDhw6hrKxswkxTWloaUlNTOdNE5CH4J5ncRkdHB6xWK06ePKmoL1u2DIWFhViwYIFKnRGRMzCgSPPsdjtqa2uxa9euCTNN+fn5WLNmDWeaiDwQA4o0yWazOVatvX6JdSEENmzYgMzMTPj7+6vYJRE5EwOKNMdms+GTTz5xrGo7PpyioqJgNpuxaNEitdojIhdhQJGmjI6Owmq1KpZcvyYwMBAPPfQQZ5qIvAQDygvFPVeC3sGRKbcH++tw+IV8F3Y05syZM7BYLIoFBMfr7+9nOBF5EQaUF5ounGayfa4NDAygsrIS9fX10+5nMBhc1BERaQEDilQjpYTNZkNZWRl6e3sddSEEhBCKe096vR4mk0mNNolIJQwoUsWlS5dgtVrR0tKiqC9fvhyFhYVoa2tzPMVnMBhgMpkQHx+vUrdEpAYGFLnU8PCwY6Zp/BlSaGgo8vPzsXr1agghEBYWxkAi8nIMKHKZ48ePo7i4GJ2dnY6aEAIbN25ERkYGZ5qISIEBRU7X3d2N0tJSNDU1KerR0dEwm82IjIxUqTMi0jIGFDnN6Ogo9uzZg+rqagwNDTnqAQEByM7ORnJyMl9RRERTYkB5oWB/3Q3noG5VW1sbduzYgfPnzyvq69atQ05ODoKDg2/5GETk2RhQXsiZQ7j9/f2oqKjAgQMHFPWIiAiYzWbExMQ47dhE5FkYUDQnpJRobGxEWVkZ+vr6HHVfX1+kp6dj8+bN0Olu/cyMiLwHA4pu2cWLF2GxWPDVV18p6itWrEBBQQHmz5+vTmNE5NYYUDRrw8PDqKmpQV1dnWKmad68eSgoKMDKlSv5EAQRzRoDimbl2LFjKC4uxuXLlx01IQQ2bdqEjIwM+Pn5qdccEXkEBhTdlK6uLpSUlODIkSOK+uLFi2E2m3H77ber1BkReRoGFM3IyMiIY6ZpeHjYUQ8MDER2djaSkpJ4OY+I5hQDim7o9OnT2LFjBy5cuKCoJyYmIicnB0FBQSp1RkSejAFFU+rr60NFRQUaGhoU9YULF6KoqAhLlixRqTMi8gYMKJpASomDBw+ivLwc/f39jrper0d6ejo2bdrEmSYicjoGFClcuHABFosFp06dUtRXrlyJ/Px8zjQRkcswoAgAMDQ0hE8//RS7d+9WzDQZDAbHTBMRkSsxoLyYzWZzrForhICU0rHNx8cHmzdvxtatWznTRESqYEB5KZvNhk8++QR2ux0AFOG0ZMkSmM1m3HbbbWq1R0TEgPJGIyMjsFqtjnAaLzAwEA888ABnmohIdQwoL/PVV1/BYrFgYGBg0u39/f0MJyLSBAaUl+jr60N5eTkOHjw47X4Gg8E1DU0h7rmSGy6m6Mz1rIhIO5wWUEKIxQDeBRAJYBTANinlq846Hk1OSomGhgZUVFQoZpp8fHwAQPHEnl6vh8lkcnmP400XTjPZTkSew5lnUHYA/0dKeUAIEQpgvxCiXErZ5MRj0jjnz5+HxWLB6dOnFfVVq1YhPz8fp06dcjzFZzAYYDKZEB8fr1K3RERKTgsoKeVZAGev/vcVIUQzgCgADCgnGxoaQnV1NXbv3q14Om/+/PkoKCjAihUrAADx8fEMJCLSLJfcgxJCxABIArBnkm2PAHgEAN/tdouklDhy5AhKSkrQ3d3tqPv4+CAlJQVbt26FXq9XsUMioplzekAJIUIAfATgX6WU3ddvl1JuA7ANAIxGo7x+O81MZ2cniouLcfz4cUX9zjvvhNlsxsKFC1XqjIhodpwaUEIIPcbC6X0p5cfOPJa3GhkZQV1dHWpqahRzTUFBQcjNzUVCQgIfGycit+TMp/gEgDcBNEspX3bWcbxZa2srLBYLLl26pKgnJycjOzsbgYGBKnVGRHTrnHkGlQrg+wBsQoiDV2s/k1JanXhMr9Db24vy8nJ88cUXivrtt9+OoqIiREdHq9TZrQv2191wDoqIvIMzn+L7DACvLc0hKSUOHDiAiooKxZsg/Pz8kJGRgY0bNzrmm9wVh3CJ6Bq+ScJNnDt3DhaLBW1tbYr6mjVrkJeXh3nz5qnUGRGRczCgNG5wcBDV1dXYs2fPhJmmwsJC3HXXXSp2R0TkPAwojZJSorm5GSUlJbhy5Yqj7uPjg9TUVKSlpXGmiYg8GgNKgzo7O2G1WnHixAlFPSYmBmazGRERESp1RkTkOgwoDbHb7airq0Ntba1ipik4OBi5ubmIj4/nTBMReQ0GlEa0tLTAYrGgo6NDUTcajcjKyuJMExF5HQaUynp6elBeXo7GxkZFPTIyEkVFRYiKilKpMyIidTGgnGi6xfcEJOL9O5AadG7CTFNWVhbWr1/v9jNNRES3ggHlRFOFU7joxWa/U1jo04vxK6/HxcUhLy8PoaGhLuqQiEi7GFAusFTXAaPvGQSLIQzDB74Yhc+4Zx3CwsJgNpuxbNky9ZokItIYBpSTLdV1YIu+Fb5ibMjWD98ssT4iBTLT07BlyxbONBERXYc3OZxsvW+bI5zGs0uBvw7GITMzk+FERDQJBpST2O12rPNtR5AYnnS7DhLdMsDFXRERuQ+3v8Q33ZNywNjyDK5+Q/bJkydhsViQrP96yn16pZ8LOyIicj9uH1DThdNMts+lnp4elJaW4tChQ4q6lMD4F0DYpQ/q7ZxvIiKajtsHlBaMjo6ivr4eVVVVGBwcdNSHpA77h6MwBB/c7duOYDGEXumHensUWkbCufgeEdE0GFC3qL29HRaLBe3t7Yr62rVrkZuby5kmIqJZYkDN0sDAAKqqqrBv3z5FfcGCBTCbzYiNjVWpMyIiz8CAuklSShw6dAhlZWXo6elx1HU6HdLS0pCamgpfX36tRES3in+T3oSOjg5YrVacPHlSUV+2bBkKCwuxYMEClTojIvI8DKgZsNvtqK2txa5duzAy8s1TgSEhIcjPz8eaNWu4ThMR0Rxz+4AK9tfdcA7qVnz55ZewWq34+utvZpqEEFi/fj2ysrLg7+9/S59PRESTc/uActYQ7pUrV1BaWorDhw8r6lFRUTCbzVi0aJFTjktERGPcPqDm2ujoKPbt24eqqioMDQ056v7+/sjOzkZycjLXaSIicgEG1DhnzpyBxWLB2bNnFfWEhATk5OQgJCREpc6IiLwPAwpjM02VlZWor69X1MPDw2E2m7F06VKVOiMi8l5eHVBSSthsNpSVlaG3t9dR9/X1RVpaGlJSUjjTRESkEq/92/fSpUuwWq1oaWlR1JcvX47CwkKEhYWp1BkREQFeGFDDw8Oora1FXV2dYqYpNDQU+fn5WL16NWeaiIg0wKsC6sSJE7Barejs7HTUhBDYuHEjMjIyONNERKQhXhFQ3d3dKC0tRVNTk6IeHR0Ns9mMyMhIlTojIqKpeHRAjY6OYu/evdi5c6dipikgIMAx08TLeURE2uSxAdXW1gaLxYJz584p6uvWrUNOTg6Cg4NV6oyIiGbCYwLKZrOhsrISXV1d8PPzU5wxAUBERATMZjNiYmLUaZCIiG6KRwSUzWbD9u3bMTw8DACKcPL19UV6ejo2b94MnY5LrBMRuQuPCKjKykpHOI3n6+uLxx9/nDNNRERuyCPeetrV1TVp3W63M5yIiNyUUwNKCJEvhDgqhDghhPg3Zx3HYDDcVJ2IiLTPaQElhNABeB1AAYA1AO4TQqxxxrFMJhP0er2iptfrYTKZnHE4IiJyAWfeg9oA4ISU8iQACCH+AOBvATRN+1OzEB8fDwCOp/gMBgNMJpOjTkRE7seZARUF4PS4X7cB2Oisg8XHxzOQiIg8iDPvQU32igY5YSchHhFC1Ash6i9evOjEdoiIyJ04M6DaACwe9+toAO3X7ySl3CalNEopjQsXLnRiO0RE5E6cGVD7ANwlhFgqhPAD8F0AnzjxeERE5EGcdg9KSmkXQvwzgFIAOgC/l1IedtbxiIjIszj1TRJSSisAqzOPQUREnskj3iRBRESeR0g54cE61QghLgL46hY/JgLApTlox5vwO5sdfm83j9/Z7Hj693anlHLCU3KaCqi5IISol1Ia1e7DnfA7mx1+bzeP39nseOv3xkt8RESkSQwoIiLSJE8MqG1qN+CG+J3NDr+3m8fvbHa88nvzuHtQRETkGTzxDIqIiDwAA4qIiDTJYwLKVav3ehIhxGIhxE4hRLMQ4rAQ4kdq9+QuhBA6IUSDEGKH2r24CyHEfCHEn4UQR67+ntusdk9aJ4R46uqfzUNCiA+EEAFq9+RKHhFQrly918PYAfwfKeVqAJsAPMHvbcZ+BKBZ7SbczKsASqSUqwCsA7+/aQkhogA8CcAopVyLsXeaflfdrlzLIwIK41bvlVIOAbi2ei9NQ0p5Vkp54Op/X8HYXxhR6nalfUKIaABmAL9Tuxd3IYSYB2ArgDcBQEo5JKW8rGpT7sEXQKAQwhdAECZZssiTeUpATbZ6L/+ivQlCiBgASQD2qNyKO3gFwLMARlXuw53EArgI4K2rl0Z/J4QIVrspLZNSngHwEoBTAM4C6JJSlqnblWt5SkDNaPVempwQIgTARwD+VUrZrXY/WiaEKAJwQUq5X+1e3IwvgGQAb0gpkwD0AuC94mkIIcIwdiVoKYA7AAQLIb6nbleu5SkBNaPVe2kiIYQeY+H0vpTyY7X7cQOpAL4lhGjF2KXkLCHEe+q25BbaALRJKa+dof8ZY4FFU8sG0CKlvCilHAbwMYAUlXtyKU8JKK7eOwtCCIGxewLNUsqX1e7HHUgpfyqljJZSxmDs91mVlNKr/lU7G1LKcwBOCyFWXi2ZADSp2JI7OAVgkxAi6OqfVRO87MESpy5Y6CpcvXfWUgF8H4BNCHHwau1nVxeaJJpr/wLg/av/iDwJ4EGV+9E0KeUeIcSfARzA2BO3DfCyVx7xVUdERKRJnnKJj4iIPAwDioiINIkBRUREmsSAIiIiTWJAERGRJjGgiIhIkxhQRESkSQwoIpUIIdYLIRqFEAFCiOCr6/6sVbsvIq3goC6RioQQLwIIABCIsXfV/V+VWyLSDAYUkYquvvZnH4ABAClSyhGVWyLSDF7iI1LXAgAhAEIxdiZFRFfxDIpIRUKITzC2bMdSAIuklP+scktEmuERbzMnckdCiB8AsEsp/0cIoQNQJ4TIklJWqd0bkRbwDIqIiDSJ96CIiEiTGFBERKRJDCgiItIkBhQREWkSA4qIiDSJAUVERJrEgCIiIk36/7+LNlQhYChAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train, y_train, marker='s', s=50, label='Training data')\n",
    "plt.plot(range(x_train.shape[0]), lrmodel.predict(x_train),\n",
    "         color='gray', marker='o', markersize=6, linewidth=3, label='LinReg Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. tf.keras API를 이용한 신경망 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Sequential 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# 샘플 데이터 생성\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=2, size=200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0, scale=(0.5+t*t/3), size=None)\n",
    "        y.append(r)\n",
    "    return x, 1.726*x - 0.84 + np.array(y)\n",
    "\n",
    "x, y = make_random_data()\n",
    "\n",
    "#training data 150개, test data 50개\n",
    "x_train, y_train = x[:150], y[:150]\n",
    "x_test, y_test = x[150:], y[150:]\n",
    "\n",
    "# 샘플 데이터 확인\n",
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델 뼈대 생성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 10.4438 - val_loss: 6.1589\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 8.5597 - val_loss: 5.1149\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.0280 - val_loss: 4.3026\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.8355 - val_loss: 3.6349\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8330 - val_loss: 3.0884\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.0304 - val_loss: 2.6403\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.3578 - val_loss: 2.2913\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.8383 - val_loss: 2.0245\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.4464 - val_loss: 1.8257\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.1429 - val_loss: 1.6528\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8751 - val_loss: 1.4995\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6477 - val_loss: 1.3903\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4790 - val_loss: 1.2996\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3398 - val_loss: 1.2341\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2338 - val_loss: 1.1697\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1376 - val_loss: 1.1269\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0661 - val_loss: 1.0882\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0060 - val_loss: 1.0599\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9568 - val_loss: 1.0365\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9151 - val_loss: 1.0172\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8830 - val_loss: 1.0038\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8602 - val_loss: 0.9927\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8386 - val_loss: 0.9843\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8219 - val_loss: 0.9751\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8074 - val_loss: 0.9678\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7959 - val_loss: 0.9621\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7859 - val_loss: 0.9616\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7792 - val_loss: 0.9574\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7729 - val_loss: 0.9522\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7661 - val_loss: 0.9517\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7620 - val_loss: 0.9491\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7587 - val_loss: 0.9497\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7569 - val_loss: 0.9493\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7544 - val_loss: 0.9492\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7526 - val_loss: 0.9488\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7508 - val_loss: 0.9490\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7507 - val_loss: 0.9500\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7494 - val_loss: 0.9495\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7503 - val_loss: 0.9509\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7493 - val_loss: 0.9502\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7478 - val_loss: 0.9506\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7479 - val_loss: 0.9510\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7477 - val_loss: 0.9511\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9519\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9521\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7469 - val_loss: 0.9522\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7463 - val_loss: 0.9523\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7468 - val_loss: 0.9512\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7480 - val_loss: 0.9510\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7475 - val_loss: 0.9508\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9499\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9505\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9503\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9512\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7468 - val_loss: 0.9509\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7459 - val_loss: 0.9506\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9497\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9503\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9495\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7477 - val_loss: 0.9499\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9519\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9520\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.9516\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7462 - val_loss: 0.9543\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9531\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9532\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7458 - val_loss: 0.9534\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7474 - val_loss: 0.9535\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9555\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7472 - val_loss: 0.9553\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9553\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7473 - val_loss: 0.9546\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7459 - val_loss: 0.9546\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9528\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7458 - val_loss: 0.9524\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9516\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9514\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7476 - val_loss: 0.9518\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7473 - val_loss: 0.9522\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7473 - val_loss: 0.9523\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7469 - val_loss: 0.9515\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7470 - val_loss: 0.9528\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7463 - val_loss: 0.9534\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7462 - val_loss: 0.9544\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7457 - val_loss: 0.9548\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9547\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7461 - val_loss: 0.9529\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7480 - val_loss: 0.9524\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9523\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9546\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.9553\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9566\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9553\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9542\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9545\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7478 - val_loss: 0.9534\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9528\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7463 - val_loss: 0.9539\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7464 - val_loss: 0.9529\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7468 - val_loss: 0.9537\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7463 - val_loss: 0.9538\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7465 - val_loss: 0.9530\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7480 - val_loss: 0.9523\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7460 - val_loss: 0.9522\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7468 - val_loss: 0.9518\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9523\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9524\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9540\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7478 - val_loss: 0.9530\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7481 - val_loss: 0.9534\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9559\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7474 - val_loss: 0.9547\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7482 - val_loss: 0.9542\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9544\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7463 - val_loss: 0.9530\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9513\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9507\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9504\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9497\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7464 - val_loss: 0.9502\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9518\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9532\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9518\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9520\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9519\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9519\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9517\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7466 - val_loss: 0.9522\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7472 - val_loss: 0.9510\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.9526\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9534\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9544\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9537\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9538\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9541\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9551\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9545\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9548\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9544\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7481 - val_loss: 0.9555\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9572\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9582\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9574\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9585\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9573\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9565\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9556\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9546\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9526\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9519\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9515\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9517\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9519\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9521\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9525\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9525\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9530\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9544\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7484 - val_loss: 0.9537\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.9529\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9534\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9551\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9567\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9553\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9564\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9567\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9584\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9577\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9576\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9582\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9575\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9559\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9561\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9566\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9554\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9560\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9560\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9578\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9571\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9578\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7482 - val_loss: 0.9593\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9584\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9567\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9578\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.550 - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9591\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9595\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9590\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9610\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9612\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9600\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7477 - val_loss: 0.9597\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9592\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9588\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9593\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9586\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9592\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9608\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9602\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9619\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9616\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9605\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9600\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9607\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7468 - val_loss: 0.9624\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9612\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9600\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9603\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9609\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9632\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9624\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9593\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9593\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9592\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9595\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9590\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9586\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9607\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9593\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9602\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9599\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9600\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9584\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9577\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9592\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9611\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9611\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9603\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7476 - val_loss: 0.9592\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9589\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7462 - val_loss: 0.9587\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7467 - val_loss: 0.9588\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7471 - val_loss: 0.9582\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9580\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9582\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9571\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9581\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9583\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9585\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9580\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9592\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9587\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9576\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9573\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9576\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9578\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7482 - val_loss: 0.9578\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9577\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9567\n",
      "Epoch 249/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9562\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9565\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9578\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9559\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9571\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9561\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9562\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9570\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9557\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9555\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9550\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9559\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9566\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9556\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9549\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9543\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9551\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9554\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9563\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9558\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9555\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9549\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9532\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9540\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9540\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9536\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9538\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9553\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9525\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7478 - val_loss: 0.9537\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9533\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9539\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9536\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7483 - val_loss: 0.9521\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9531\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9539\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9533\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9531\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9541\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9534\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9541\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9550\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9546\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9551\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9553\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9556\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9557\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9555\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9553\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9556\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9568\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9571\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9577\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7484 - val_loss: 0.9551\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.9546\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9568\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9572\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9573\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9567\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9557\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7482 - val_loss: 0.9565\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9561\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9555\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9551\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9547\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9551\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9543\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9550\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9533\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9536\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9541\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9531\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9542\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9555\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9544\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.9576\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9574\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9573\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9561\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9548\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9558\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7472 - val_loss: 0.9554\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7459 - val_loss: 0.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9549\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9549\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9541\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7488 - val_loss: 0.9534\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9528\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9520\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9517\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9522\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9525\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7488 - val_loss: 0.9519\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9523\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9539\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9549\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9541\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9547\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9550\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9552\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7486 - val_loss: 0.9541\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9531\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9544\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9551\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9566\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7478 - val_loss: 0.9565\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9551\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9533\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9531\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9515\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7486 - val_loss: 0.9507\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7474 - val_loss: 0.9509\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7466 - val_loss: 0.9521\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7492 - val_loss: 0.9529\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9520\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7476 - val_loss: 0.9521\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9529\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9527\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9527\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9521\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9538\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7478 - val_loss: 0.9553\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9561\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9565\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7481 - val_loss: 0.9566\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9556\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9539\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9528\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9526\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9529\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9520\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9521\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9544\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9540\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9536\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9549\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9560\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9566\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9578\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9560\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9563\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9562\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9556\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9550\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9542\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9533\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9530\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9518\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9514\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9520\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7484 - val_loss: 0.9529\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9525\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9517\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9514\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9530\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9541\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9535\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9548\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9554\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9555\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9565\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9555\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9544\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9534\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9532\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9523\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9528\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9518\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9526\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9522\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9532\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9533\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9520\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9523\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9545\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9556\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9571\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9551\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9540\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9545\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9549\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7481 - val_loss: 0.9544\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9532\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9529\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9528\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9514\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9520\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9533\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9543\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9538\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9547\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9553\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9556\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9554\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7474 - val_loss: 0.9552\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9539\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9535\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7476 - val_loss: 0.9534\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9532\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7476 - val_loss: 0.9548\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9536\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9519\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9529\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9533\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9529\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9545\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9549\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9550\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7478 - val_loss: 0.9568\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9566\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7458 - val_loss: 0.9568\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7464 - val_loss: 0.9573\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7482 - val_loss: 0.9577\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9576\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9576\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9565\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7463 - val_loss: 0.9569\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7461 - val_loss: 0.9556\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7476 - val_loss: 0.9565\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9564\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9564\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7479 - val_loss: 0.9562\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9563\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9554\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7486 - val_loss: 0.9562\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9556\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9550\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9558\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9581\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7473 - val_loss: 0.9579\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7463 - val_loss: 0.9572\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7473 - val_loss: 0.9564\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7461 - val_loss: 0.9564\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7475 - val_loss: 0.9552\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7466 - val_loss: 0.9556\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7471 - val_loss: 0.9563\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.369 - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9570\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9572\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9569\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9569\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9575\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9565\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9566\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9552\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9548\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9557\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9555\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9560\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9552\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7457 - val_loss: 0.9555\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.9543\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9546\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "model.compile(optimizer='sgd', loss='mse') # mean squared error(평균제곱오차) 손실함수\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, 500 + 1)\n",
    "# fit method에서 반환되는 데이터는 History 객체의 history 딕셔너리\n",
    "# history 딕셔너리에는 epoch마다 계산한 손실함수 값이 저장됨\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 함수형 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수형 API에서는 입력과 출력 사이 원하는 층을 자유롭게 조합할 수 있다,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.Input(shape=(1,))\n",
    "output = tf.keras.layers.Dense(1)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(1)\n",
    "#output = dense.__call__(input)\n",
    "output = dense(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 9.8417WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 9.8159 - val_loss: 5.7733\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.0416 - val_loss: 4.7937\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.5946 - val_loss: 4.0631\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5.5118 - val_loss: 3.4603\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.6125 - val_loss: 2.9641\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.8702 - val_loss: 2.5453\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2565 - val_loss: 2.2221\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.7656 - val_loss: 1.9500\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3604 - val_loss: 1.7551\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0615 - val_loss: 1.6035\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8252 - val_loss: 1.4743\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.6228 - val_loss: 1.3637\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4565 - val_loss: 1.2696\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3141 - val_loss: 1.2074\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2134 - val_loss: 1.1477\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1182 - val_loss: 1.1076\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0504 - val_loss: 1.0700\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9879 - val_loss: 1.0418\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9419 - val_loss: 1.0203\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9055 - val_loss: 0.9999\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8724 - val_loss: 0.9861\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8464 - val_loss: 0.9749\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8283 - val_loss: 0.9693\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8148 - val_loss: 0.9631\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8036 - val_loss: 0.9563\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7930 - val_loss: 0.9523\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7837 - val_loss: 0.9511\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7774 - val_loss: 0.9494\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7723 - val_loss: 0.9488\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7682 - val_loss: 0.9449\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7623 - val_loss: 0.9436\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7606 - val_loss: 0.9441\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7582 - val_loss: 0.9448\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7555 - val_loss: 0.9442\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7544 - val_loss: 0.9453\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7534 - val_loss: 0.9456\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7518 - val_loss: 0.9463\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7504 - val_loss: 0.9456\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7495 - val_loss: 0.9476\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7494 - val_loss: 0.9462\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7496 - val_loss: 0.9469\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7481 - val_loss: 0.9472\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7482 - val_loss: 0.9471\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7476 - val_loss: 0.9486\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7479 - val_loss: 0.9515\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9511\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7475 - val_loss: 0.9517\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.9506\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7484 - val_loss: 0.9531\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7485 - val_loss: 0.9524\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7471 - val_loss: 0.9524\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.9542\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9532\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.9546\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7477 - val_loss: 0.9546\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9551\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9555\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9561\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7469 - val_loss: 0.9562\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7467 - val_loss: 0.9548\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9538\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9552\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7472 - val_loss: 0.9573\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9570\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.9598\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7463 - val_loss: 0.9591\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7459 - val_loss: 0.9589\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9578\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.9599\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9589\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9596\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9588\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7476 - val_loss: 0.9570\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9578\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9569\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9560\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9541\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7462 - val_loss: 0.9528\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7464 - val_loss: 0.9533\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7461 - val_loss: 0.9538\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7463 - val_loss: 0.9535\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7464 - val_loss: 0.9538\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7464 - val_loss: 0.9559\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7463 - val_loss: 0.9555\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9562\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9558\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9546\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9558\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9552\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9555\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9573\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9582\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7472 - val_loss: 0.9591\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7459 - val_loss: 0.9586\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9594\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9611\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9603\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9587\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9587\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9564\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9566\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9554\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7489 - val_loss: 0.9552\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9532\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7467 - val_loss: 0.9517\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7461 - val_loss: 0.9520\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7469 - val_loss: 0.9518\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7467 - val_loss: 0.9534\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9540\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7459 - val_loss: 0.9545\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9559\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9561\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9561\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9575\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9579\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7485 - val_loss: 0.9573\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9575\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9564\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.9573\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9567\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9554\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9554\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9552\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9547\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9564\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9549\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9538\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9549\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9551\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9551\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7481 - val_loss: 0.9557\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9552\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7477 - val_loss: 0.9562\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9567\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7483 - val_loss: 0.9570\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9581\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9573\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9584\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9582\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9595\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9585\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9573\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9562\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9571\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9557\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9577\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9594\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9603\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9625\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7487 - val_loss: 0.9616\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9610\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9618\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9603\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9599\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9599\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9581\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9573\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9591\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9582\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9583\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9585\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9575\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9580\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9580\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9567\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9587\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9588\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9575\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9568\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9549\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7457 - val_loss: 0.9552\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.802 - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9547\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9545\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9546\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9543\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7457 - val_loss: 0.9543\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9550\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9559\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7484 - val_loss: 0.9564\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9549\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9546\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9528\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9512\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9529\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9536\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9548\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9551\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9551\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9563\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9555\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9554\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9569\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7481 - val_loss: 0.9572\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9561\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9573\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9568\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9570\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9568\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9557\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9551\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9549\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7483 - val_loss: 0.9548\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9551\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7473 - val_loss: 0.9539\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7471 - val_loss: 0.9545\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7468 - val_loss: 0.9544\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9543\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9532\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7466 - val_loss: 0.9512\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9520\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9523\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9525\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9518\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9521\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9516\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9511\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7459 - val_loss: 0.9529\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9521\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9525\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7489 - val_loss: 0.9527\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9538\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9533\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7472 - val_loss: 0.9539\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.9542\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9533\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9529\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9523\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9535\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9528\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9536\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9552\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9562\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9559\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9553\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9558\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9551\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7457 - val_loss: 0.9552\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9559\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9576\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9595\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9589\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9596\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9603\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7485 - val_loss: 0.9599\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9608\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9598\n",
      "Epoch 247/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9597\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9596\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9580\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9580\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9578\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9573\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9574\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9592\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9570\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9570\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9577\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9567\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9561\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9568\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9598\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9585\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9583\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9578\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9583\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9586\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9576\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9571\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9572\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9556\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9536\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9529\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9528\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9531\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9526\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9540\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9540\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9529\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9528\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9551\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9546\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9528\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9520\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9518\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.9523\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9558\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9551\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9559\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9569\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9573\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9572\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9575\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9585\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9583\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9589\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9612\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9618\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9612\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9607\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9612\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9600\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9571\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9576\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9576\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9580\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9557\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9546\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9541\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9551\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9567\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9579\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9581\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9566\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9587\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9585\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9578\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9568\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9553\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7479 - val_loss: 0.9546\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9551\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9555\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9544\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9565\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9568\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9573\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9593\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9593\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9593\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9627\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9609\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7480 - val_loss: 0.9613\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7476 - val_loss: 0.9595\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7464 - val_loss: 0.9590\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.9591\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9583\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7458 - val_loss: 0.9577\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7460 - val_loss: 0.9565\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9567\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9569\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9565\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9567\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9568\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9566\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7476 - val_loss: 0.9560\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9552\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9546\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9558\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9544\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9531\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9536\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9539\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9529\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9520\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9511\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9518\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9513\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9508\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9509\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9507\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9528\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9535\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9524\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9531\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9539\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7485 - val_loss: 0.9536\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9525\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7479 - val_loss: 0.9525\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9543\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9541\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9554\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9553\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9539\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9529\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9518\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9499\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9499\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9503\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9500\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9510\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9524\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9499\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9501\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 0.9525\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9538\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9543\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9538\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9545\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9532\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9532\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7481 - val_loss: 0.9529\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9526\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9535\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9542\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9536\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7485 - val_loss: 0.9529\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9536\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9533\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9526\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9528\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9531\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9515\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9507\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9522\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9537\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9538\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7485 - val_loss: 0.9567\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7474 - val_loss: 0.9579\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9563\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9561\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7464 - val_loss: 0.9569\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9583\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9570\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9547\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9522\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.9515\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9521\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9515\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7487 - val_loss: 0.9530\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9543\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9557\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9566\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9564\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9566\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7473 - val_loss: 0.9558\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9551\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9534\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7483 - val_loss: 0.9535\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9534\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9536\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9551\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9535\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9538\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9536\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9552\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9567\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9546\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9566\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.9553\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9539\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9528\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.9532\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7477 - val_loss: 0.9518\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7468 - val_loss: 0.9528\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7458 - val_loss: 0.9525\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9558\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9543\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9535\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9534\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9536\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9538\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9545\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7462 - val_loss: 0.9537\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9535\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7476 - val_loss: 0.9525\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9515\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9524\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9518\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7465 - val_loss: 0.9518\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7470 - val_loss: 0.9520\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7460 - val_loss: 0.9519\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7472 - val_loss: 0.9517\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9509\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9504\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.9524\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 0.9511\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7486 - val_loss: 0.9514\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9524\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9528\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9527\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9532\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 0.9536\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9527\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.9516\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9506\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.9517\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9538\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9537\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9526\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.9519\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7462 - val_loss: 0.9509\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9506\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9512\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9513\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9516\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9531\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9541\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9531\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.9539\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7469 - val_loss: 0.9543\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9548\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7460 - val_loss: 0.9547\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9556\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 0.9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.9539\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.9537\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 0.9541\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - val_loss: 0.9545\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.9551\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9560\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 tf.keras 모델의 저장과 복원 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "model.save_weights('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "# 모델을 훈련시키지 않고 이전에 학습한 가중치 이용\n",
    "model.load_weights('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 993us/step - loss: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9523122906684875"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3935 - val_loss: 2.0020\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.8895 - val_loss: 1.7795\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.4962 - val_loss: 1.6006\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.1732 - val_loss: 1.4525\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9050 - val_loss: 1.3371\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.6921 - val_loss: 1.2465\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5196 - val_loss: 1.1714\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3765 - val_loss: 1.1200\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2717 - val_loss: 1.0733\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1756 - val_loss: 1.0401\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0989 - val_loss: 1.0112\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0380 - val_loss: 0.9869\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9828 - val_loss: 0.9729\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9452 - val_loss: 0.9582\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9089 - val_loss: 0.9487\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8821 - val_loss: 0.9402\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8589 - val_loss: 0.9349\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8389 - val_loss: 0.9289\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8222 - val_loss: 0.9262\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8074 - val_loss: 0.9247\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7952 - val_loss: 0.9242\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7881 - val_loss: 0.9250\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7809 - val_loss: 0.9240\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7750 - val_loss: 0.9250\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7713 - val_loss: 0.9249\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7673 - val_loss: 0.9255\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7624 - val_loss: 0.9265\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7604 - val_loss: 0.9284\n"
     ]
    }
   ],
   "source": [
    "# ModelCheckPoint 콜백, EarlyStopping 콜백 사용 -> 가장 적합한 가중치 저장\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "callback_list = [tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5', monitor='val_loss'\n",
    "                                                    , save_best_only = True), \n",
    "                tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.25, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, len(history.history['loss'])+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9710167050361633"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "#model.load_weights('my_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
